{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "232d0a2b-5e31-43c0-b400-c7cb9fb690e7",
   "metadata": {},
   "source": [
    "# Full Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2df043-385c-4c22-9a90-7b38f69bb9cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c6d2d2-e6c1-4a3a-b442-f88f2265eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, TimeDistributed, ConvLSTM2D, concatenate, Dropout, BatchNormalization, Embedding, Reshape, Flatten\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, Callback\n",
    "from tensorflow.keras.optimizers import Adam, AdamW, RMSprop\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pretty_midi\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79232e5-42c6-454c-8d07-e84ef4219e88",
   "metadata": {},
   "source": [
    "### Set Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd9f062-1ad5-40fe-983f-7b44d3193579",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548bc31-f4b4-4f17-8f30-ee4fe79085f2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load MIDI Data & Create Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c7cce-e146-428d-8f8d-4c96689f03bf",
   "metadata": {},
   "source": [
    "We want to use the Cymatics dataset, which has 424 midi files. Each file has some chord progression played for 8 or 16 seconds, along with a top melody.\n",
    "\n",
    "There are 128 possible notes. At 8 frames per second, we account for each 1/16th note in the sequence. This should capture all the data effectively, as the melodies don't have anything less than 1/16th notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e1db4b8-f9be-49c3-9a1e-2ee511f77e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading cymatics-midi/Cymatics - Essential MIDI 26 - F Min - Vol 7.mid: MIDI file has a largest tick of 4294968753, it is likely corrupt\n",
      "Total sequences created: 663\n"
     ]
    }
   ],
   "source": [
    "def load_midi_files(folder_path):\n",
    "    \"\"\"Load all MIDI files from the given folder.\"\"\"\n",
    "    midi_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.mid') or file.endswith('.midi'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                midi_files.append(file_path)\n",
    "    return midi_files\n",
    "\n",
    "def midi_to_piano_roll(midi_file, fs=8):\n",
    "    \"\"\"Convert a MIDI file to a transposed and binarized piano roll representation.\"\"\"\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "        piano_roll = midi_data.get_piano_roll(fs=fs)\n",
    "        piano_roll = (piano_roll.T > 0).astype(int)\n",
    "        return piano_roll\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {midi_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return piano_roll\n",
    "\n",
    "def create_sequences(piano_roll, input_length=48, output_length=16, fs=8):\n",
    "    \"\"\"Create input-output sequences from a piano roll.\"\"\"\n",
    "    if piano_roll is None:\n",
    "        return []\n",
    "\n",
    "    total_length = input_length + output_length\n",
    "    sequences = []\n",
    "\n",
    "    num_steps = piano_roll.shape[0] // total_length\n",
    "    for i in range(num_steps):\n",
    "        start = i * total_length\n",
    "        end_input = start + input_length\n",
    "        end_output = end_input + output_length\n",
    "\n",
    "        input_seq = piano_roll[start:end_input, :]\n",
    "        output_seq = piano_roll[end_input:end_output, :]\n",
    "\n",
    "        if input_seq.shape[0] == input_length and output_seq.shape[0] == output_length:\n",
    "            sequences.append((input_seq, output_seq))\n",
    "\n",
    "    return sequences\n",
    "\n",
    "def process_folder(folder_path, fs=8, input_length=48, output_length=16):\n",
    "    \"\"\"Process all MIDI files in a folder and create input-output sequences.\"\"\"\n",
    "    midi_files = load_midi_files(folder_path)\n",
    "    all_sequences = []\n",
    "\n",
    "    for midi_file in midi_files:\n",
    "        piano_roll = midi_to_piano_roll(midi_file, fs=fs)\n",
    "        sequences = create_sequences(piano_roll, input_length=input_length, output_length=output_length, fs=fs)\n",
    "        all_sequences.extend(sequences)\n",
    "\n",
    "    return all_sequences\n",
    "\n",
    "folder_path = 'cymatics-midi'\n",
    "sequences = process_folder(folder_path)\n",
    "\n",
    "print(f\"Total sequences created: {len(sequences)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57aede-7b45-4023-8f90-b86245090b53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Split Sequences and Trim for 4 and 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fef178ff-8939-4dd2-a339-28815853a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "def split_sequences(sequences, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"Split sequences into train, validation, and test sets.\"\"\"\n",
    "    np.random.shuffle(sequences)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    total_len = len(sequences)\n",
    "    train_end = int(train_ratio * total_len)\n",
    "    val_end = train_end + int(val_ratio * total_len)\n",
    "\n",
    "    train_sequences = sequences[:train_end]\n",
    "    val_sequences = sequences[train_end:val_end]\n",
    "    test_sequences = sequences[val_end:]\n",
    "\n",
    "    return train_sequences, val_sequences, test_sequences\n",
    "\n",
    "def save_sequences_to_pkl(sequences, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(sequences, f)\n",
    "\n",
    "train_sequences, val_sequences, test_sequences = split_sequences(sequences)\n",
    "\n",
    "print(len(train_sequences))\n",
    "print(len(val_sequences))\n",
    "print(len(test_sequences))\n",
    "\n",
    "save_sequences_to_pkl(train_sequences, '62sec_train_sequences.pkl')\n",
    "save_sequences_to_pkl(val_sequences, '62sec_val_sequences.pkl')\n",
    "save_sequences_to_pkl(test_sequences, '62sec_test_sequences.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "343c9d2e-85a2-49af-9318-d32f7fb96dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_sequences(sequences, new_input_length, output_length=16):\n",
    "    \"\"\"Trim sequences to new input lengths.\"\"\"\n",
    "    new_sequences = []\n",
    "\n",
    "    for input_seq, output_seq in sequences:\n",
    "        if input_seq.shape[0] >= new_input_length:\n",
    "            trimmed_input_seq = input_seq[-new_input_length:, :]\n",
    "            new_sequences.append((trimmed_input_seq, output_seq))\n",
    "\n",
    "    return new_sequences\n",
    "\n",
    "\n",
    "def save_trimmed_splits(train_sequences, val_sequences, test_sequences, input_length, output_length, prefix):\n",
    "    train_sequences_trimmed = trim_sequences(train_sequences, new_input_length=input_length, output_length=output_length)\n",
    "    val_sequences_trimmed = trim_sequences(val_sequences, new_input_length=input_length, output_length=output_length)\n",
    "    test_sequences_trimmed = trim_sequences(test_sequences, new_input_length=input_length, output_length=output_length)\n",
    "    \n",
    "    with open(f'{prefix}_train_sequences.pkl', 'wb') as f:\n",
    "        pickle.dump(train_sequences_trimmed, f)\n",
    "    with open(f'{prefix}_val_sequences.pkl', 'wb') as f:\n",
    "        pickle.dump(val_sequences_trimmed, f)\n",
    "    with open(f'{prefix}_test_sequences.pkl', 'wb') as f:\n",
    "        pickle.dump(test_sequences_trimmed, f)\n",
    "\n",
    "# Create and save new splits with 4 seconds input, 2 seconds output\n",
    "input_length_4sec = 32  # 4 seconds * 8 FS\n",
    "save_trimmed_splits(train_sequences, val_sequences, test_sequences, input_length=input_length_4sec, output_length=16, prefix='42sec')\n",
    "\n",
    "# Create and save new splits with 2 seconds input, 2 seconds output\n",
    "input_length_2sec = 16  # 2 seconds * 8 FS\n",
    "save_trimmed_splits(train_sequences, val_sequences, test_sequences, input_length=input_length_2sec, output_length=16, prefix='22sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae7cc3-9177-4ea0-b8ed-ad8837d4e380",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e0bcac-2d5e-4527-9a51-c2badac4d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Removed Notes after model has been trained and saved\n",
    "def restore_removed_notes(predicted_sequences, played_notes, total_notes=128):\n",
    "    restored_sequences = []\n",
    "    for sequence in predicted_sequences:\n",
    "        restored_sequence = np.zeros((sequence.shape[0], total_notes))\n",
    "        restored_sequence[:, played_notes] = sequence\n",
    "        restored_sequences.append(restored_sequence)\n",
    "    return restored_sequences\n",
    "\n",
    "# Generate predictions\n",
    "# predictions = model.predict([test_data_prepared[0], test_data_prepared[1]])\n",
    "\n",
    "# Restore removed notes in the predictions\n",
    "# predictions_restored = restore_removed_notes(predictions, played_notes)\n",
    "\n",
    "# After this, we can access elements from predictions_restored to generate MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40698e2-d4e1-4f41-95a6-f5b547d2bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_played_notes(dataset):\n",
    "    played_notes = set()\n",
    "    for sequence in dataset:\n",
    "        input_seq, output_seq = sequence\n",
    "        # Add notes that are played in input and output sequences\n",
    "        played_notes.update(np.where(input_seq.any(axis=0))[0])\n",
    "        played_notes.update(np.where(output_seq.any(axis=0))[0])\n",
    "    return played_notes\n",
    "\n",
    "# Function to filter dataset using the comprehensive set of played notes\n",
    "def filter_dataset(dataset, played_notes):\n",
    "    filtered_dataset = []\n",
    "    for sequence in dataset:\n",
    "        input_seq, output_seq = sequence\n",
    "        # Keep only the columns corresponding to played notes\n",
    "        input_seq_filtered = input_seq[:, played_notes]\n",
    "        output_seq_filtered = output_seq[:, played_notes]\n",
    "        filtered_dataset.append((input_seq_filtered, output_seq_filtered))\n",
    "    return filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7073fcb-e671-4603-8935-75e195b0f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import .pkl files\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# Function to prepare data for encoder-decoder model\n",
    "def prepare_data(data):\n",
    "    encoder_input_data = np.array([item[0] for item in data])\n",
    "    decoder_target_data = np.array([item[1] for item in data])\n",
    "    \n",
    "    # Prepare decoder input data\n",
    "    decoder_input_data = np.zeros_like(decoder_target_data)\n",
    "    decoder_input_data[:, 1:, :] = decoder_target_data[:, :-1, :]\n",
    "    \n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e2e34e-30e2-4059-96cf-7250d8cec696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_all_sequences():\n",
    "    # Define the sequence lengths and file paths\n",
    "    sequence_lengths = [62, 42, 22]\n",
    "    datasets = [\n",
    "        ('Splits/62sec_train_sequences.pkl', 'Splits/62sec_val_sequences.pkl', 'Splits/62sec_test_sequences.pkl'),\n",
    "        ('Splits/42sec_train_sequences.pkl', 'Splits/42sec_val_sequences.pkl', 'Splits/42sec_test_sequences.pkl'),\n",
    "        ('Splits/22sec_train_sequences.pkl', 'Splits/22sec_val_sequences.pkl', 'Splits/22sec_test_sequences.pkl')\n",
    "    ]\n",
    "    \n",
    "    # Step 1: Identify the largest set of played notes across all datasets\n",
    "    all_played_notes = set()\n",
    "    \n",
    "    for _, (train_path, val_path, test_path) in zip(sequence_lengths, datasets):\n",
    "        # Load the data\n",
    "        train_data = load_data(train_path)\n",
    "        val_data = load_data(val_path)\n",
    "        test_data = load_data(test_path)\n",
    "        \n",
    "        # Identify played notes in each dataset\n",
    "        all_played_notes.update(identify_played_notes(train_data))\n",
    "        all_played_notes.update(identify_played_notes(val_data))\n",
    "        all_played_notes.update(identify_played_notes(test_data))\n",
    "    \n",
    "    # Convert played_notes to a sorted list for consistent indexing\n",
    "    all_played_notes = sorted(list(all_played_notes))\n",
    "    \n",
    "    # Step 2: Filter and prepare each dataset\n",
    "    all_data = {}\n",
    "    \n",
    "    for seq_len, (train_path, val_path, test_path) in zip(sequence_lengths, datasets):\n",
    "        # Load the data\n",
    "        train_data = load_data(train_path)\n",
    "        val_data = load_data(val_path)\n",
    "        test_data = load_data(test_path)\n",
    "        \n",
    "        # Filter the datasets using the comprehensive set of played notes\n",
    "        train_data_filtered = filter_dataset(train_data, all_played_notes)\n",
    "        val_data_filtered = filter_dataset(val_data, all_played_notes)\n",
    "        test_data_filtered = filter_dataset(test_data, all_played_notes)\n",
    "        \n",
    "        # Prepare the data\n",
    "        encoder_input_data_train, decoder_input_data_train, decoder_target_data_train = prepare_data(train_data_filtered)\n",
    "        encoder_input_data_val, decoder_input_data_val, decoder_target_data_val = prepare_data(val_data_filtered)\n",
    "        encoder_input_data_test, decoder_input_data_test, decoder_target_data_test = prepare_data(test_data_filtered)\n",
    "        \n",
    "        # Store the data in a dictionary\n",
    "        all_data[seq_len] = {\n",
    "            'encoder_input_data_train': encoder_input_data_train,\n",
    "            'decoder_input_data_train': decoder_input_data_train,\n",
    "            'decoder_target_data_train': decoder_target_data_train,\n",
    "            'encoder_input_data_val': encoder_input_data_val,\n",
    "            'decoder_input_data_val': decoder_input_data_val,\n",
    "            'decoder_target_data_val': decoder_target_data_val,\n",
    "            'encoder_input_data_test': encoder_input_data_test,\n",
    "            'decoder_input_data_test': decoder_input_data_test,\n",
    "            'decoder_target_data_test': decoder_target_data_test,\n",
    "            'played_notes': all_played_notes\n",
    "        }\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "all_data = load_and_prepare_all_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6111843-0990-42a2-b71d-ff38fff89697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data[22]['played_notes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fc4d0-57c2-4eeb-9c82-36bbf0dcf0dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "738c050c-ce23-41fa-8053-2eca548f43b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 62\n",
      "Train Encoder Input Shape: (464, 48, 82)\n",
      "Train Decoder Input Shape: (464, 16, 82)\n",
      "Train Decoder Target Shape: (464, 16, 82)\n",
      "Validation Encoder Input Shape: (99, 48, 82)\n",
      "Validation Decoder Input Shape: (99, 16, 82)\n",
      "Validation Decoder Target Shape: (99, 16, 82)\n",
      "Test Encoder Input Shape: (100, 48, 82)\n",
      "Test Decoder Input Shape: (100, 16, 82)\n",
      "Test Decoder Target Shape: (100, 16, 82)\n",
      "\n",
      "\n",
      "Sequence Length: 42\n",
      "Train Encoder Input Shape: (464, 32, 82)\n",
      "Train Decoder Input Shape: (464, 16, 82)\n",
      "Train Decoder Target Shape: (464, 16, 82)\n",
      "Validation Encoder Input Shape: (99, 32, 82)\n",
      "Validation Decoder Input Shape: (99, 16, 82)\n",
      "Validation Decoder Target Shape: (99, 16, 82)\n",
      "Test Encoder Input Shape: (100, 32, 82)\n",
      "Test Decoder Input Shape: (100, 16, 82)\n",
      "Test Decoder Target Shape: (100, 16, 82)\n",
      "\n",
      "\n",
      "Sequence Length: 22\n",
      "Train Encoder Input Shape: (464, 16, 82)\n",
      "Train Decoder Input Shape: (464, 16, 82)\n",
      "Train Decoder Target Shape: (464, 16, 82)\n",
      "Validation Encoder Input Shape: (99, 16, 82)\n",
      "Validation Decoder Input Shape: (99, 16, 82)\n",
      "Validation Decoder Target Shape: (99, 16, 82)\n",
      "Test Encoder Input Shape: (100, 16, 82)\n",
      "Test Decoder Input Shape: (100, 16, 82)\n",
      "Test Decoder Target Shape: (100, 16, 82)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze data shape and structure\n",
    "def analyze_data_shape(data):\n",
    "    for seq_len, data_dict in data.items():\n",
    "        print(f\"Sequence Length: {seq_len}\")\n",
    "        print(f\"Train Encoder Input Shape: {data_dict['encoder_input_data_train'].shape}\")\n",
    "        print(f\"Train Decoder Input Shape: {data_dict['decoder_input_data_train'].shape}\")\n",
    "        print(f\"Train Decoder Target Shape: {data_dict['decoder_target_data_train'].shape}\")\n",
    "        print(f\"Validation Encoder Input Shape: {data_dict['encoder_input_data_val'].shape}\")\n",
    "        print(f\"Validation Decoder Input Shape: {data_dict['decoder_input_data_val'].shape}\")\n",
    "        print(f\"Validation Decoder Target Shape: {data_dict['decoder_target_data_val'].shape}\")\n",
    "        print(f\"Test Encoder Input Shape: {data_dict['encoder_input_data_test'].shape}\")\n",
    "        print(f\"Test Decoder Input Shape: {data_dict['decoder_input_data_test'].shape}\")\n",
    "        print(f\"Test Decoder Target Shape: {data_dict['decoder_target_data_test'].shape}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Analyze data shape\n",
    "analyze_data_shape(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da38d513-9a82-4113-8b96-84e14e920847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 62\n",
      "Sequence Length: 42\n",
      "Sequence Length: 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map MIDI note number to octave\n",
    "def note_to_octave(note):\n",
    "    return (note // 12) - 1\n",
    "\n",
    "# Function to analyze note frequency by octave as percentages\n",
    "def analyze_note_frequency_by_octave(data, y_limit):\n",
    "    all_octave_data = []\n",
    "\n",
    "    for seq_len, data_dict in data.items():\n",
    "        print(f\"Sequence Length: {seq_len}\")\n",
    "        \n",
    "        # Sum the notes played across all timesteps and sequences separately for each dataset\n",
    "        note_counts_encoder = np.sum(data_dict['encoder_input_data_train'], axis=(0, 1))\n",
    "        note_counts_decoder_input = np.sum(data_dict['decoder_input_data_train'], axis=(0, 1))\n",
    "        note_counts_decoder_target = np.sum(data_dict['decoder_target_data_train'], axis=(0, 1))\n",
    "        \n",
    "        # Combine note counts\n",
    "        total_note_counts = note_counts_encoder + note_counts_decoder_input + note_counts_decoder_target\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_notes = np.sum(total_note_counts)\n",
    "        note_percentages = (total_note_counts / total_notes) * 100\n",
    "        \n",
    "        # Create a DataFrame with note and octave information\n",
    "        octaves = [note_to_octave(i) for i in range(len(total_note_counts))]\n",
    "        octave_df = pd.DataFrame({'Octave': octaves, 'Percentage': note_percentages, 'Sequence Length': seq_len})\n",
    "        \n",
    "        # Group by octave and sum the percentages\n",
    "        octave_df_grouped = octave_df.groupby('Octave')['Percentage'].sum().reset_index()\n",
    "        octave_df_grouped['Sequence Length'] = seq_len\n",
    "        \n",
    "        # Append to all_octave_data\n",
    "        all_octave_data.append(octave_df_grouped)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_octave_data)\n",
    "    \n",
    "    # Plot the combined octave distribution as percentages\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x='Octave', y='Percentage', hue='Sequence Length', data=combined_data)\n",
    "    \n",
    "    # Annotate bars with percentage values\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}%', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline', \n",
    "                    fontsize=10, color='black', xytext=(0, 5), \n",
    "                    textcoords='offset points')\n",
    "    \n",
    "    plt.title('Note Frequency Distribution by Octave for Different Sequence Lengths on Training Data')\n",
    "    plt.xlabel('Octave')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.ylim(0, y_limit)  # Set y-axis limit to keep it consistent\n",
    "    plt.legend(title='Sequence Length')\n",
    "    plt.savefig('FrequencyDistributionbySeqLen_train')\n",
    "    plt.show()\n",
    "\n",
    "# Analyze note frequency by octave as percentages with a consistent y-axis limit\n",
    "analyze_note_frequency_by_octave(all_data, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be72832d-c6e0-4bc5-a4dd-a1d54d5018ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 62\n",
      "Sequence Length: 42\n",
      "Sequence Length: 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map MIDI note number to octave\n",
    "def note_to_octave(note):\n",
    "    return (note // 12) - 1\n",
    "\n",
    "# Function to analyze note frequency by octave as percentages\n",
    "def analyze_note_frequency_by_octave(data, y_limit):\n",
    "    all_octave_data = []\n",
    "\n",
    "    for seq_len, data_dict in data.items():\n",
    "        print(f\"Sequence Length: {seq_len}\")\n",
    "        \n",
    "        # Sum the notes played across all timesteps and sequences separately for each dataset\n",
    "        note_counts_encoder = np.sum(data_dict['encoder_input_data_val'], axis=(0, 1))\n",
    "        note_counts_decoder_input = np.sum(data_dict['decoder_input_data_val'], axis=(0, 1))\n",
    "        note_counts_decoder_target = np.sum(data_dict['decoder_target_data_val'], axis=(0, 1))\n",
    "        \n",
    "        # Combine note counts\n",
    "        total_note_counts = note_counts_encoder + note_counts_decoder_input + note_counts_decoder_target\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_notes = np.sum(total_note_counts)\n",
    "        note_percentages = (total_note_counts / total_notes) * 100\n",
    "        \n",
    "        # Create a DataFrame with note and octave information\n",
    "        octaves = [note_to_octave(i) for i in range(len(total_note_counts))]\n",
    "        octave_df = pd.DataFrame({'Octave': octaves, 'Percentage': note_percentages, 'Sequence Length': seq_len})\n",
    "        \n",
    "        # Group by octave and sum the percentages\n",
    "        octave_df_grouped = octave_df.groupby('Octave')['Percentage'].sum().reset_index()\n",
    "        octave_df_grouped['Sequence Length'] = seq_len\n",
    "        \n",
    "        # Append to all_octave_data\n",
    "        all_octave_data.append(octave_df_grouped)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_octave_data)\n",
    "    \n",
    "    # Plot the combined octave distribution as percentages\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x='Octave', y='Percentage', hue='Sequence Length', data=combined_data)\n",
    "    \n",
    "    # Annotate bars with percentage values\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}%', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline', \n",
    "                    fontsize=10, color='black', xytext=(0, 5), \n",
    "                    textcoords='offset points')\n",
    "    \n",
    "    plt.title('Note Frequency Distribution by Octave for Different Sequence Lengths on Validation Data')\n",
    "    plt.xlabel('Octave')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.ylim(0, y_limit)  # Set y-axis limit to keep it consistent\n",
    "    plt.legend(title='Sequence Length')\n",
    "    plt.savefig('FrequencyDistributionbySeqLen_validation')\n",
    "    plt.show()\n",
    "\n",
    "# Analyze note frequency by octave as percentages with a consistent y-axis limit\n",
    "analyze_note_frequency_by_octave(all_data, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0da6ad66-e701-413b-92be-6d43fd284d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 62\n",
      "Sequence Length: 42\n",
      "Sequence Length: 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to map MIDI note number to octave\n",
    "def note_to_octave(note):\n",
    "    return (note // 12) - 1\n",
    "\n",
    "# Function to analyze note frequency by octave as percentages\n",
    "def analyze_note_frequency_by_octave(data, y_limit):\n",
    "    all_octave_data = []\n",
    "\n",
    "    for seq_len, data_dict in data.items():\n",
    "        print(f\"Sequence Length: {seq_len}\")\n",
    "        \n",
    "        # Sum the notes played across all timesteps and sequences separately for each dataset\n",
    "        note_counts_encoder = np.sum(data_dict['encoder_input_data_test'], axis=(0, 1))\n",
    "        note_counts_decoder_input = np.sum(data_dict['decoder_input_data_test'], axis=(0, 1))\n",
    "        note_counts_decoder_target = np.sum(data_dict['decoder_target_data_test'], axis=(0, 1))\n",
    "        \n",
    "        # Combine note counts\n",
    "        total_note_counts = note_counts_encoder + note_counts_decoder_input + note_counts_decoder_target\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_notes = np.sum(total_note_counts)\n",
    "        note_percentages = (total_note_counts / total_notes) * 100\n",
    "        \n",
    "        # Create a DataFrame with note and octave information\n",
    "        octaves = [note_to_octave(i) for i in range(len(total_note_counts))]\n",
    "        octave_df = pd.DataFrame({'Octave': octaves, 'Percentage': note_percentages, 'Sequence Length': seq_len})\n",
    "        \n",
    "        # Group by octave and sum the percentages\n",
    "        octave_df_grouped = octave_df.groupby('Octave')['Percentage'].sum().reset_index()\n",
    "        octave_df_grouped['Sequence Length'] = seq_len\n",
    "        \n",
    "        # Append to all_octave_data\n",
    "        all_octave_data.append(octave_df_grouped)\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_data = pd.concat(all_octave_data)\n",
    "    \n",
    "    # Plot the combined octave distribution as percentages\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.barplot(x='Octave', y='Percentage', hue='Sequence Length', data=combined_data)\n",
    "    \n",
    "    # Annotate bars with percentage values\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}%', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='baseline', \n",
    "                    fontsize=10, color='black', xytext=(0, 5), \n",
    "                    textcoords='offset points')\n",
    "    \n",
    "    plt.title('Note Frequency Distribution by Octave for Different Sequence Lengths on Test Data')\n",
    "    plt.xlabel('Octave')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "    plt.ylim(0, y_limit)  # Set y-axis limit to keep it consistent\n",
    "    plt.legend(title='Sequence Length')\n",
    "    plt.savefig('FrequencyDistributionbySeqLen_test')\n",
    "    plt.show()\n",
    "\n",
    "# Analyze note frequency by octave as percentages with a consistent y-axis limit\n",
    "analyze_note_frequency_by_octave(all_data, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2001bea2-c976-4cf1-bffd-c325dd2c6035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 62\n",
      "Train-Val Cosine Similarity: 0.9811\n",
      "Val-Test Cosine Similarity: 0.9718\n",
      "Train-Test Cosine Similarity: 0.9883\n",
      "\n",
      "Sequence Length: 42\n",
      "Train-Val Cosine Similarity: 0.9752\n",
      "Val-Test Cosine Similarity: 0.9651\n",
      "Train-Test Cosine Similarity: 0.9852\n",
      "\n",
      "Sequence Length: 22\n",
      "Train-Val Cosine Similarity: 0.9626\n",
      "Val-Test Cosine Similarity: 0.9443\n",
      "Train-Test Cosine Similarity: 0.9809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_cosine_similarity(frequencies1, frequencies2):\n",
    "    # Use only the notes that appear in at least one dataset\n",
    "    mask = (frequencies1 + frequencies2) > 0\n",
    "    frequencies1_non_zero = frequencies1[mask]\n",
    "    frequencies2_non_zero = frequencies2[mask]\n",
    "\n",
    "    cosine_sim = 1 - cosine(frequencies1_non_zero, frequencies2_non_zero)\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "def compute_and_print_cosine_similarities(all_data):\n",
    "    for seq_len, data_dict in all_data.items():\n",
    "        # Combine all training data sequences (encoder input, decoder input, decoder target) along the feature axis\n",
    "        all_train_sequences = np.concatenate([\n",
    "            data_dict['encoder_input_data_train'],\n",
    "            data_dict['decoder_input_data_train'],\n",
    "            data_dict['decoder_target_data_train']\n",
    "        ], axis=1)\n",
    "\n",
    "        all_val_sequences = np.concatenate([\n",
    "            data_dict['encoder_input_data_val'],\n",
    "            data_dict['decoder_input_data_val'],\n",
    "            data_dict['decoder_target_data_val']\n",
    "        ], axis=1)\n",
    "\n",
    "        all_test_sequences = np.concatenate([\n",
    "            data_dict['encoder_input_data_test'],\n",
    "            data_dict['decoder_input_data_test'],\n",
    "            data_dict['decoder_target_data_test']\n",
    "        ], axis=1)\n",
    "\n",
    "        # Sum the notes played across all timesteps and sequences\n",
    "        train_note_frequencies = np.sum(all_train_sequences, axis=(0, 1))\n",
    "        val_note_frequencies = np.sum(all_val_sequences, axis=(0, 1))\n",
    "        test_note_frequencies = np.sum(all_test_sequences, axis=(0, 1))\n",
    "\n",
    "        # Compute cosine similarities\n",
    "        train_val_cosine = compute_cosine_similarity(train_note_frequencies, val_note_frequencies)\n",
    "        val_test_cosine = compute_cosine_similarity(val_note_frequencies, test_note_frequencies)\n",
    "        train_test_cosine = compute_cosine_similarity(train_note_frequencies, test_note_frequencies)\n",
    "\n",
    "        print(f\"Sequence Length: {seq_len}\")\n",
    "        print(f\"Train-Val Cosine Similarity: {train_val_cosine:.4f}\")\n",
    "        print(f\"Val-Test Cosine Similarity: {val_test_cosine:.4f}\")\n",
    "        print(f\"Train-Test Cosine Similarity: {train_test_cosine:.4f}\")\n",
    "        print()\n",
    "\n",
    "# Assuming all_data is already loaded and prepared\n",
    "compute_and_print_cosine_similarities(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfd867-b2e9-4b57-aa0d-738728cdbdf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Build Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ac914-e907-462f-b332-24d8a53c7f81",
   "metadata": {},
   "source": [
    "In this section, I would like to build 2 baseline models that will be used for comparison with my final encoder-decoder model.\n",
    "\n",
    "1. **Repeat model** - this model will simply repeat the previous 2 seconds from the sequence as the predicted output.\n",
    "2. **Repeat model** - this model will simply repeat the first 2 seconds from the sequence as the predicted output.\n",
    "3. **Repeat with noise**\n",
    "4. **Feedforward Neural Network** - This model will be used to show a neural network's ability to predict without the recurrent layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e9ee9-376a-4fee-8f21-1512d81a248e",
   "metadata": {},
   "source": [
    "### Repeat Model (Last 2 Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0b1a2d5-99cc-4f69-b0be-0664a576a4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Precision for 62 seconds: 0.3510, Baseline Recall for 62 seconds: 0.3510\n",
      "Baseline Precision for 42 seconds: 0.3510, Baseline Recall for 42 seconds: 0.3510\n",
      "Baseline Precision for 22 seconds: 0.3510, Baseline Recall for 22 seconds: 0.3510\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate precision and recall given true and predicted values\n",
    "def calculate_precision_recall(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_thresholded = (y_pred >= threshold).astype(int)\n",
    "    precision = precision_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    recall = recall_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    return precision, recall\n",
    "\n",
    "# Function to calculate baseline precision and recall by repeating the last part of the input sequence\n",
    "def baseline_repeat_input(encoder_input_data_test, decoder_target_data_test, threshold=0.5):\n",
    "    y_pred = encoder_input_data_test[:, -decoder_target_data_test.shape[1]:, :]\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    for y_true, y_pred_single in zip(decoder_target_data_test, y_pred):\n",
    "        precision, recall = calculate_precision_recall(y_true, y_pred_single, threshold)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "# Evaluate baseline for each sequence length in the dataset\n",
    "for seq_len, data_dict in all_data.items():\n",
    "    encoder_input_data_test = data_dict['encoder_input_data_test']\n",
    "    decoder_target_data_test = data_dict['decoder_target_data_test']\n",
    "    \n",
    "    precision, recall = baseline_repeat_input(encoder_input_data_test, decoder_target_data_test)\n",
    "    print(f\"Baseline Precision for {seq_len} seconds: {precision:.4f}, Baseline Recall for {seq_len} seconds: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510297f4-0c7c-4586-bb35-c34c9c5453b3",
   "metadata": {},
   "source": [
    "### Repeat Model (First 2 Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d453884-3109-4350-b032-3ee376a4b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Precision for first two seconds of 62 seconds: 0.2504, Baseline Recall for first two seconds of 62 seconds: 0.2459\n",
      "0.2481130136159003\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate precision and recall given true and predicted values\n",
    "def calculate_precision_recall(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_thresholded = (y_pred >= threshold).astype(int)\n",
    "    precision = precision_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    recall = recall_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    return precision, recall\n",
    "\n",
    "# Function to calculate baseline precision and recall by using the first part of the input sequence\n",
    "def baseline_first_two_seconds(encoder_input_data_test, decoder_target_data_test, threshold=0.5):\n",
    "    # Assume each second is represented by a certain number of timesteps. Adjust this number accordingly.\n",
    "    timesteps_per_second = encoder_input_data_test.shape[1] // 6  # Example: 6 seconds of input data\n",
    "    num_timesteps = 2 * timesteps_per_second  # First 2 seconds\n",
    "\n",
    "    y_pred = encoder_input_data_test[:, :num_timesteps, :]\n",
    "\n",
    "    precisions, recalls = [], []\n",
    "    for y_true, y_pred_single in zip(decoder_target_data_test, y_pred):\n",
    "        precision, recall = calculate_precision_recall(y_true, y_pred_single, threshold)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "# Evaluate baseline for each sequence length in the dataset\n",
    "for seq_len, data_dict in all_data.items():\n",
    "    if seq_len != 62:  # Only apply to the 62-second sequence length\n",
    "        continue\n",
    "\n",
    "    encoder_input_data_test = data_dict['encoder_input_data_test']\n",
    "    decoder_target_data_test = data_dict['decoder_target_data_test']\n",
    "\n",
    "    precision, recall = baseline_first_two_seconds(encoder_input_data_test, decoder_target_data_test)\n",
    "    print(f\"Baseline Precision for first two seconds of {seq_len} seconds: {precision:.4f}, Baseline Recall for first two seconds of {seq_len} seconds: {recall:.4f}\")\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e275b18-cbb8-4cf4-a72e-627bebca9145",
   "metadata": {},
   "source": [
    "### Repeat with noise (Last 2 Seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be298685-5614-48bf-9394-10d6ff296dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with Noise (Level=0.3) Precision for 62 seconds: 0.1852, Baseline Recall for 62 seconds: 0.3652\n",
      "Baseline with Noise (Level=0.3) Precision for 42 seconds: 0.1880, Baseline Recall for 42 seconds: 0.3686\n",
      "Baseline with Noise (Level=0.3) Precision for 22 seconds: 0.1868, Baseline Recall for 22 seconds: 0.3672\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_recall(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_thresholded = (y_pred >= threshold).astype(int)\n",
    "    precision = precision_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    recall = recall_score(y_true.flatten(), y_pred_thresholded.flatten(), zero_division=1)\n",
    "    return precision, recall\n",
    "\n",
    "# Function to calculate baseline precision and recall by repeating the last part of the input sequence\n",
    "def baseline_repeat_input_with_noise(encoder_input_data_test, decoder_target_data_test, noise_level=0.1, threshold=0.5):\n",
    "    y_pred = encoder_input_data_test[:, -decoder_target_data_test.shape[1]:, :]\n",
    "    \n",
    "    precisions, recalls = [], []\n",
    "    for y_true, y_pred_single in zip(decoder_target_data_test, y_pred):\n",
    "        # Add Gaussian noise to the prediction\n",
    "        noisy_pred = y_pred_single + np.random.normal(0, noise_level, y_pred_single.shape)\n",
    "        precision, recall = calculate_precision_recall(y_true, noisy_pred, threshold)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "# Evaluate baseline with noise for each sequence length in the dataset\n",
    "noise_level = 0.3  # Adjust the noise level as needed\n",
    "for seq_len, data_dict in all_data.items():\n",
    "    encoder_input_data_test = data_dict['encoder_input_data_test']\n",
    "    decoder_target_data_test = data_dict['decoder_target_data_test']\n",
    "    \n",
    "    precision, recall = baseline_repeat_input_with_noise(encoder_input_data_test, decoder_target_data_test, noise_level=noise_level)\n",
    "    print(f\"Baseline with Noise (Level={noise_level}) Precision for {seq_len} seconds: {precision:.4f}, Baseline Recall for {seq_len} seconds: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed799f-1ac3-43df-8aa8-1db70d98400f",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629c92a9-e1eb-48d1-8db7-7db465a5028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the feedforward neural network model\n",
    "def build_ffnn_model(input_dim, output_dim, layers=3, units=2048, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(output_dim, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "    return model\n",
    "\n",
    "def train_ffnn_model(model, train_data, val_data, epochs=200, batch_size=32, model_name='model'):\n",
    "    input_data_train, target_data_train = train_data\n",
    "    input_data_val, target_data_val = val_data\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    csv_logger = CSVLogger(f'{model_name}_log.csv', append=True, separator=',')\n",
    "    \n",
    "    history = model.fit(\n",
    "        input_data_train, target_data_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(input_data_val, target_data_val),\n",
    "        callbacks=[checkpoint, early_stopping, csv_logger]\n",
    "    )\n",
    "    \n",
    "    epochs_taken = len(history.history['loss'])\n",
    "    \n",
    "    return history, epochs_taken\n",
    "\n",
    "\n",
    "def evaluate_ffnn_model(model, data):\n",
    "    input_data, target_data = data\n",
    "    results = model.evaluate(input_data, target_data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15aa92a-f2bf-4d62-aaef-ca33db9ff5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5949 - precision: 0.0493 - recall: 0.2708  \n",
      "Epoch 1: val_loss improved from inf to 0.24873, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5780 - precision: 0.0492 - recall: 0.2529 - val_loss: 0.2487 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2607 - precision: 0.1172 - recall: 0.0013         \n",
      "Epoch 2: val_loss improved from 0.24873 to 0.21105, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2572 - precision: 0.1344 - recall: 0.0024 - val_loss: 0.2110 - val_precision: 0.1429 - val_recall: 3.3151e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2159 - precision: 0.2276 - recall: 0.0142 \n",
      "Epoch 3: val_loss improved from 0.21105 to 0.19856, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2149 - precision: 0.2295 - recall: 0.0135 - val_loss: 0.1986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1935 - precision: 0.4657 - recall: 0.0036     \n",
      "Epoch 4: val_loss improved from 0.19856 to 0.18508, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1926 - precision: 0.4719 - recall: 0.0043 - val_loss: 0.1851 - val_precision: 0.5882 - val_recall: 0.0017\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1720 - precision: 0.5226 - recall: 0.0359 \n",
      "Epoch 5: val_loss improved from 0.18508 to 0.17341, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1709 - precision: 0.5266 - recall: 0.0377 - val_loss: 0.1734 - val_precision: 0.6129 - val_recall: 0.0126\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1552 - precision: 0.5996 - recall: 0.0638 \n",
      "Epoch 6: val_loss improved from 0.17341 to 0.16496, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1542 - precision: 0.6046 - recall: 0.0664 - val_loss: 0.1650 - val_precision: 0.5589 - val_recall: 0.0338\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1405 - precision: 0.6587 - recall: 0.1136 \n",
      "Epoch 7: val_loss improved from 0.16496 to 0.15875, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1397 - precision: 0.6607 - recall: 0.1162 - val_loss: 0.1588 - val_precision: 0.5894 - val_recall: 0.0552\n",
      "Epoch 8/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1291 - precision: 0.7297 - recall: 0.1531 \n",
      "Epoch 8: val_loss improved from 0.15875 to 0.15321, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1280 - precision: 0.7300 - recall: 0.1577 - val_loss: 0.1532 - val_precision: 0.6118 - val_recall: 0.0844\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1203 - precision: 0.7511 - recall: 0.2088 \n",
      "Epoch 9: val_loss improved from 0.15321 to 0.14805, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1188 - precision: 0.7572 - recall: 0.2136 - val_loss: 0.1481 - val_precision: 0.6506 - val_recall: 0.1121\n",
      "Epoch 10/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1108 - precision: 0.7926 - recall: 0.2616 \n",
      "Epoch 10: val_loss improved from 0.14805 to 0.14368, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1094 - precision: 0.7949 - recall: 0.2682 - val_loss: 0.1437 - val_precision: 0.6730 - val_recall: 0.1416\n",
      "Epoch 11/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1032 - precision: 0.8127 - recall: 0.3272 \n",
      "Epoch 11: val_loss improved from 0.14368 to 0.13961, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1016 - precision: 0.8160 - recall: 0.3290 - val_loss: 0.1396 - val_precision: 0.6979 - val_recall: 0.1827\n",
      "Epoch 12/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0953 - precision: 0.8421 - recall: 0.3827 \n",
      "Epoch 12: val_loss improved from 0.13961 to 0.13585, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0938 - precision: 0.8466 - recall: 0.3853 - val_loss: 0.1358 - val_precision: 0.7110 - val_recall: 0.2084\n",
      "Epoch 13/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0887 - precision: 0.8558 - recall: 0.4376 \n",
      "Epoch 13: val_loss improved from 0.13585 to 0.13224, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0877 - precision: 0.8561 - recall: 0.4422 - val_loss: 0.1322 - val_precision: 0.7281 - val_recall: 0.2241\n",
      "Epoch 14/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0824 - precision: 0.8759 - recall: 0.4742 \n",
      "Epoch 14: val_loss improved from 0.13224 to 0.12846, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0815 - precision: 0.8774 - recall: 0.4755 - val_loss: 0.1285 - val_precision: 0.7427 - val_recall: 0.2775\n",
      "Epoch 15/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0764 - precision: 0.8873 - recall: 0.5340 \n",
      "Epoch 15: val_loss improved from 0.12846 to 0.12630, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - precision: 0.8872 - recall: 0.5357 - val_loss: 0.1263 - val_precision: 0.7557 - val_recall: 0.2912\n",
      "Epoch 16/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0728 - precision: 0.8973 - recall: 0.5640 \n",
      "Epoch 16: val_loss improved from 0.12630 to 0.12289, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0720 - precision: 0.8966 - recall: 0.5662 - val_loss: 0.1229 - val_precision: 0.7646 - val_recall: 0.3241\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0669 - precision: 0.8967 - recall: 0.6108 \n",
      "Epoch 17: val_loss improved from 0.12289 to 0.12058, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0664 - precision: 0.8979 - recall: 0.6099 - val_loss: 0.1206 - val_precision: 0.7749 - val_recall: 0.3423\n",
      "Epoch 18/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0640 - precision: 0.9033 - recall: 0.6288 \n",
      "Epoch 18: val_loss improved from 0.12058 to 0.11834, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0633 - precision: 0.9041 - recall: 0.6305 - val_loss: 0.1183 - val_precision: 0.7842 - val_recall: 0.3698\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0601 - precision: 0.9063 - recall: 0.6766 \n",
      "Epoch 19: val_loss improved from 0.11834 to 0.11693, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0593 - precision: 0.9082 - recall: 0.6712 - val_loss: 0.1169 - val_precision: 0.7864 - val_recall: 0.3832\n",
      "Epoch 20/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0572 - precision: 0.9124 - recall: 0.6876 \n",
      "Epoch 20: val_loss improved from 0.11693 to 0.11633, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0564 - precision: 0.9107 - recall: 0.6892 - val_loss: 0.1163 - val_precision: 0.7985 - val_recall: 0.3975\n",
      "Epoch 21/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0538 - precision: 0.9278 - recall: 0.6963 \n",
      "Epoch 21: val_loss improved from 0.11633 to 0.11307, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0533 - precision: 0.9258 - recall: 0.6987 - val_loss: 0.1131 - val_precision: 0.7929 - val_recall: 0.4247\n",
      "Epoch 22/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0513 - precision: 0.9170 - recall: 0.7385 \n",
      "Epoch 22: val_loss improved from 0.11307 to 0.11285, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0509 - precision: 0.9191 - recall: 0.7337 - val_loss: 0.1128 - val_precision: 0.8036 - val_recall: 0.4383\n",
      "Epoch 23/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0489 - precision: 0.9203 - recall: 0.7473 \n",
      "Epoch 23: val_loss improved from 0.11285 to 0.11209, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0484 - precision: 0.9208 - recall: 0.7483 - val_loss: 0.1121 - val_precision: 0.8117 - val_recall: 0.4422\n",
      "Epoch 24/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0457 - precision: 0.9409 - recall: 0.7468 \n",
      "Epoch 24: val_loss improved from 0.11209 to 0.11062, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0453 - precision: 0.9393 - recall: 0.7484 - val_loss: 0.1106 - val_precision: 0.7986 - val_recall: 0.4785\n",
      "Epoch 25/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0454 - precision: 0.9204 - recall: 0.7782 \n",
      "Epoch 25: val_loss did not improve from 0.11062\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0444 - precision: 0.9240 - recall: 0.7777 - val_loss: 0.1116 - val_precision: 0.8013 - val_recall: 0.4774\n",
      "Epoch 26/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0424 - precision: 0.9334 - recall: 0.7821 \n",
      "Epoch 26: val_loss improved from 0.11062 to 0.11014, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0419 - precision: 0.9334 - recall: 0.7822 - val_loss: 0.1101 - val_precision: 0.7957 - val_recall: 0.4971\n",
      "Epoch 27/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0405 - precision: 0.9311 - recall: 0.8097 \n",
      "Epoch 27: val_loss did not improve from 0.11014\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0400 - precision: 0.9327 - recall: 0.8068 - val_loss: 0.1106 - val_precision: 0.8136 - val_recall: 0.4832\n",
      "Epoch 28/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - precision: 0.9397 - recall: 0.8046 \n",
      "Epoch 28: val_loss improved from 0.11014 to 0.10945, saving model to 62sec_1layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0385 - precision: 0.9392 - recall: 0.8071 - val_loss: 0.1094 - val_precision: 0.8139 - val_recall: 0.5016\n",
      "Epoch 29/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - precision: 0.9397 - recall: 0.8220 \n",
      "Epoch 29: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0364 - precision: 0.9411 - recall: 0.8204 - val_loss: 0.1100 - val_precision: 0.8142 - val_recall: 0.5090\n",
      "Epoch 30/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - precision: 0.9420 - recall: 0.8307 \n",
      "Epoch 30: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0350 - precision: 0.9415 - recall: 0.8297 - val_loss: 0.1098 - val_precision: 0.8136 - val_recall: 0.5167\n",
      "Epoch 31/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0340 - precision: 0.9506 - recall: 0.8296 \n",
      "Epoch 31: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0334 - precision: 0.9497 - recall: 0.8313 - val_loss: 0.1095 - val_precision: 0.8034 - val_recall: 0.5339\n",
      "Epoch 32/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - precision: 0.9425 - recall: 0.8540 \n",
      "Epoch 32: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0326 - precision: 0.9432 - recall: 0.8530 - val_loss: 0.1111 - val_precision: 0.8119 - val_recall: 0.5258\n",
      "Epoch 33/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - precision: 0.9487 - recall: 0.8418 \n",
      "Epoch 33: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0310 - precision: 0.9484 - recall: 0.8457 - val_loss: 0.1098 - val_precision: 0.8118 - val_recall: 0.5407\n",
      "Epoch 34/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0298 - precision: 0.9496 - recall: 0.8633 \n",
      "Epoch 34: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0297 - precision: 0.9495 - recall: 0.8613 - val_loss: 0.1101 - val_precision: 0.8138 - val_recall: 0.5477\n",
      "Epoch 35/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0293 - precision: 0.9488 - recall: 0.8675 \n",
      "Epoch 35: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0291 - precision: 0.9475 - recall: 0.8668 - val_loss: 0.1111 - val_precision: 0.8236 - val_recall: 0.5472\n",
      "Epoch 36/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0279 - precision: 0.9511 - recall: 0.8793 \n",
      "Epoch 36: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0276 - precision: 0.9510 - recall: 0.8779 - val_loss: 0.1119 - val_precision: 0.8290 - val_recall: 0.5496\n",
      "Epoch 37/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - precision: 0.9562 - recall: 0.8710 \n",
      "Epoch 37: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0273 - precision: 0.9565 - recall: 0.8711 - val_loss: 0.1110 - val_precision: 0.8201 - val_recall: 0.5667\n",
      "Epoch 38/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0263 - precision: 0.9528 - recall: 0.8927 \n",
      "Epoch 38: val_loss did not improve from 0.10945\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0259 - precision: 0.9538 - recall: 0.8910 - val_loss: 0.1128 - val_precision: 0.8240 - val_recall: 0.5535\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0263 - precision: 0.9848 - recall: 0.8713 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1104 - precision: 0.8016 - recall: 0.4929 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1256 - precision: 0.8034 - recall: 0.4543\n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6047 - precision_1: 0.0498 - recall_1: 0.2830  \n",
      "Epoch 1: val_loss improved from inf to 0.24691, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5783 - precision_1: 0.0498 - recall_1: 0.2549 - val_loss: 0.2469 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2613 - precision_1: 0.1038 - recall_1: 0.0013         \n",
      "Epoch 2: val_loss improved from 0.24691 to 0.21176, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2582 - precision_1: 0.1206 - recall_1: 0.0026 - val_loss: 0.2118 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2208 - precision_1: 0.2017 - recall_1: 0.0228 \n",
      "Epoch 3: val_loss improved from 0.21176 to 0.19991, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2191 - precision_1: 0.2038 - recall_1: 0.0214 - val_loss: 0.1999 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1974 - precision_1: 0.4406 - recall_1: 0.0042 \n",
      "Epoch 4: val_loss improved from 0.19991 to 0.18671, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1961 - precision_1: 0.4404 - recall_1: 0.0048 - val_loss: 0.1867 - val_precision_1: 0.6000 - val_recall_1: 4.9727e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1755 - precision_1: 0.5015 - recall_1: 0.0322 \n",
      "Epoch 5: val_loss improved from 0.18671 to 0.17410, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1743 - precision_1: 0.5067 - recall_1: 0.0343 - val_loss: 0.1741 - val_precision_1: 0.5476 - val_recall_1: 0.0076\n",
      "Epoch 6/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1572 - precision_1: 0.5938 - recall_1: 0.0696 \n",
      "Epoch 6: val_loss improved from 0.17410 to 0.16552, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1566 - precision_1: 0.5955 - recall_1: 0.0708 - val_loss: 0.1655 - val_precision_1: 0.5578 - val_recall_1: 0.0280\n",
      "Epoch 7/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1443 - precision_1: 0.6485 - recall_1: 0.1075 \n",
      "Epoch 7: val_loss improved from 0.16552 to 0.15866, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1430 - precision_1: 0.6518 - recall_1: 0.1115 - val_loss: 0.1587 - val_precision_1: 0.5731 - val_recall_1: 0.0481\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1338 - precision_1: 0.6885 - recall_1: 0.1569 \n",
      "Epoch 8: val_loss improved from 0.15866 to 0.15296, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1320 - precision_1: 0.6912 - recall_1: 0.1595 - val_loss: 0.1530 - val_precision_1: 0.6024 - val_recall_1: 0.0678\n",
      "Epoch 9/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1247 - precision_1: 0.7348 - recall_1: 0.1717 \n",
      "Epoch 9: val_loss improved from 0.15296 to 0.14833, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1226 - precision_1: 0.7406 - recall_1: 0.1827 - val_loss: 0.1483 - val_precision_1: 0.6482 - val_recall_1: 0.0971\n",
      "Epoch 10/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1157 - precision_1: 0.7715 - recall_1: 0.2521 \n",
      "Epoch 10: val_loss improved from 0.14833 to 0.14405, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1138 - precision_1: 0.7738 - recall_1: 0.2557 - val_loss: 0.1440 - val_precision_1: 0.6786 - val_recall_1: 0.1225\n",
      "Epoch 11/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1077 - precision_1: 0.7908 - recall_1: 0.2996 \n",
      "Epoch 11: val_loss improved from 0.14405 to 0.14005, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1060 - precision_1: 0.7936 - recall_1: 0.3045 - val_loss: 0.1400 - val_precision_1: 0.7130 - val_recall_1: 0.1479\n",
      "Epoch 12/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1023 - precision_1: 0.8103 - recall_1: 0.3267 \n",
      "Epoch 12: val_loss improved from 0.14005 to 0.13607, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1005 - precision_1: 0.8117 - recall_1: 0.3354 - val_loss: 0.1361 - val_precision_1: 0.7198 - val_recall_1: 0.1767\n",
      "Epoch 13/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0957 - precision_1: 0.8323 - recall_1: 0.3825 \n",
      "Epoch 13: val_loss improved from 0.13607 to 0.13219, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0942 - precision_1: 0.8358 - recall_1: 0.3856 - val_loss: 0.1322 - val_precision_1: 0.7381 - val_recall_1: 0.2186\n",
      "Epoch 14/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0891 - precision_1: 0.8504 - recall_1: 0.4360 \n",
      "Epoch 14: val_loss improved from 0.13219 to 0.12935, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0880 - precision_1: 0.8508 - recall_1: 0.4363 - val_loss: 0.1293 - val_precision_1: 0.7508 - val_recall_1: 0.2437\n",
      "Epoch 15/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0838 - precision_1: 0.8563 - recall_1: 0.4708 \n",
      "Epoch 15: val_loss improved from 0.12935 to 0.12608, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - precision_1: 0.8591 - recall_1: 0.4737 - val_loss: 0.1261 - val_precision_1: 0.7465 - val_recall_1: 0.2665\n",
      "Epoch 16/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0792 - precision_1: 0.8675 - recall_1: 0.5140 \n",
      "Epoch 16: val_loss improved from 0.12608 to 0.12394, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - precision_1: 0.8666 - recall_1: 0.5130 - val_loss: 0.1239 - val_precision_1: 0.7523 - val_recall_1: 0.2960\n",
      "Epoch 17/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0758 - precision_1: 0.8619 - recall_1: 0.5555 \n",
      "Epoch 17: val_loss improved from 0.12394 to 0.12116, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0747 - precision_1: 0.8639 - recall_1: 0.5548 - val_loss: 0.1212 - val_precision_1: 0.7633 - val_recall_1: 0.3126\n",
      "Epoch 18/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0712 - precision_1: 0.8857 - recall_1: 0.5781 \n",
      "Epoch 18: val_loss improved from 0.12116 to 0.11903, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0702 - precision_1: 0.8847 - recall_1: 0.5774 - val_loss: 0.1190 - val_precision_1: 0.7667 - val_recall_1: 0.3459\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0679 - precision_1: 0.8868 - recall_1: 0.6053 \n",
      "Epoch 19: val_loss improved from 0.11903 to 0.11699, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0669 - precision_1: 0.8875 - recall_1: 0.6056 - val_loss: 0.1170 - val_precision_1: 0.7748 - val_recall_1: 0.3531\n",
      "Epoch 20/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0645 - precision_1: 0.8963 - recall_1: 0.6343 \n",
      "Epoch 20: val_loss improved from 0.11699 to 0.11583, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0635 - precision_1: 0.8953 - recall_1: 0.6346 - val_loss: 0.1158 - val_precision_1: 0.7744 - val_recall_1: 0.3761\n",
      "Epoch 21/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0612 - precision_1: 0.8960 - recall_1: 0.6608 \n",
      "Epoch 21: val_loss improved from 0.11583 to 0.11543, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0604 - precision_1: 0.8937 - recall_1: 0.6594 - val_loss: 0.1154 - val_precision_1: 0.7891 - val_recall_1: 0.3721\n",
      "Epoch 22/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0586 - precision_1: 0.9018 - recall_1: 0.6790 \n",
      "Epoch 22: val_loss improved from 0.11543 to 0.11378, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0580 - precision_1: 0.9009 - recall_1: 0.6750 - val_loss: 0.1138 - val_precision_1: 0.7952 - val_recall_1: 0.3952\n",
      "Epoch 23/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0569 - precision_1: 0.9101 - recall_1: 0.6729 \n",
      "Epoch 23: val_loss improved from 0.11378 to 0.11199, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0559 - precision_1: 0.9085 - recall_1: 0.6778 - val_loss: 0.1120 - val_precision_1: 0.7850 - val_recall_1: 0.4175\n",
      "Epoch 24/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0538 - precision_1: 0.9042 - recall_1: 0.7030 \n",
      "Epoch 24: val_loss improved from 0.11199 to 0.11159, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0533 - precision_1: 0.9053 - recall_1: 0.7005 - val_loss: 0.1116 - val_precision_1: 0.8002 - val_recall_1: 0.4248\n",
      "Epoch 25/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0519 - precision_1: 0.9025 - recall_1: 0.7180 \n",
      "Epoch 25: val_loss improved from 0.11159 to 0.11014, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0515 - precision_1: 0.9032 - recall_1: 0.7158 - val_loss: 0.1101 - val_precision_1: 0.7981 - val_recall_1: 0.4404\n",
      "Epoch 26/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0488 - precision_1: 0.9179 - recall_1: 0.7416 \n",
      "Epoch 26: val_loss improved from 0.11014 to 0.10976, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0482 - precision_1: 0.9172 - recall_1: 0.7418 - val_loss: 0.1098 - val_precision_1: 0.8025 - val_recall_1: 0.4514\n",
      "Epoch 27/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0457 - precision_1: 0.9219 - recall_1: 0.7539 \n",
      "Epoch 27: val_loss did not improve from 0.10976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - precision_1: 0.9198 - recall_1: 0.7523 - val_loss: 0.1109 - val_precision_1: 0.8115 - val_recall_1: 0.4510\n",
      "Epoch 28/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0459 - precision_1: 0.9186 - recall_1: 0.7484 \n",
      "Epoch 28: val_loss improved from 0.10976 to 0.10797, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0453 - precision_1: 0.9195 - recall_1: 0.7502 - val_loss: 0.1080 - val_precision_1: 0.8060 - val_recall_1: 0.4772\n",
      "Epoch 29/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0432 - precision_1: 0.9102 - recall_1: 0.7833 \n",
      "Epoch 29: val_loss did not improve from 0.10797\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0430 - precision_1: 0.9125 - recall_1: 0.7781 - val_loss: 0.1095 - val_precision_1: 0.8128 - val_recall_1: 0.4779\n",
      "Epoch 30/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0430 - precision_1: 0.9234 - recall_1: 0.7747 \n",
      "Epoch 30: val_loss did not improve from 0.10797\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0425 - precision_1: 0.9220 - recall_1: 0.7758 - val_loss: 0.1083 - val_precision_1: 0.8177 - val_recall_1: 0.4951\n",
      "Epoch 31/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0400 - precision_1: 0.9326 - recall_1: 0.7946 \n",
      "Epoch 31: val_loss improved from 0.10797 to 0.10773, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0398 - precision_1: 0.9308 - recall_1: 0.7950 - val_loss: 0.1077 - val_precision_1: 0.8181 - val_recall_1: 0.5001\n",
      "Epoch 32/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0390 - precision_1: 0.9238 - recall_1: 0.8042 \n",
      "Epoch 32: val_loss did not improve from 0.10773\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0387 - precision_1: 0.9250 - recall_1: 0.8012 - val_loss: 0.1083 - val_precision_1: 0.8132 - val_recall_1: 0.5110\n",
      "Epoch 33/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0398 - precision_1: 0.9178 - recall_1: 0.7964 \n",
      "Epoch 33: val_loss improved from 0.10773 to 0.10764, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0389 - precision_1: 0.9214 - recall_1: 0.7989 - val_loss: 0.1076 - val_precision_1: 0.8224 - val_recall_1: 0.5157\n",
      "Epoch 34/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0363 - precision_1: 0.9325 - recall_1: 0.8157 \n",
      "Epoch 34: val_loss improved from 0.10764 to 0.10749, saving model to 62sec_1layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0358 - precision_1: 0.9336 - recall_1: 0.8160 - val_loss: 0.1075 - val_precision_1: 0.8208 - val_recall_1: 0.5215\n",
      "Epoch 35/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0359 - precision_1: 0.9337 - recall_1: 0.8205 \n",
      "Epoch 35: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0356 - precision_1: 0.9328 - recall_1: 0.8199 - val_loss: 0.1079 - val_precision_1: 0.8133 - val_recall_1: 0.5273\n",
      "Epoch 36/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0344 - precision_1: 0.9398 - recall_1: 0.8246 \n",
      "Epoch 36: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0339 - precision_1: 0.9404 - recall_1: 0.8264 - val_loss: 0.1087 - val_precision_1: 0.8158 - val_recall_1: 0.5299\n",
      "Epoch 37/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0327 - precision_1: 0.9362 - recall_1: 0.8441 \n",
      "Epoch 37: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0324 - precision_1: 0.9364 - recall_1: 0.8435 - val_loss: 0.1079 - val_precision_1: 0.8268 - val_recall_1: 0.5332\n",
      "Epoch 38/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0310 - precision_1: 0.9409 - recall_1: 0.8427 \n",
      "Epoch 38: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0311 - precision_1: 0.9399 - recall_1: 0.8419 - val_loss: 0.1076 - val_precision_1: 0.8284 - val_recall_1: 0.5385\n",
      "Epoch 39/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0304 - precision_1: 0.9387 - recall_1: 0.8571 \n",
      "Epoch 39: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0301 - precision_1: 0.9400 - recall_1: 0.8549 - val_loss: 0.1093 - val_precision_1: 0.8190 - val_recall_1: 0.5409\n",
      "Epoch 40/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0299 - precision_1: 0.9418 - recall_1: 0.8583 \n",
      "Epoch 40: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0297 - precision_1: 0.9404 - recall_1: 0.8575 - val_loss: 0.1088 - val_precision_1: 0.8224 - val_recall_1: 0.5465\n",
      "Epoch 41/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0287 - precision_1: 0.9434 - recall_1: 0.8609 \n",
      "Epoch 41: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0285 - precision_1: 0.9438 - recall_1: 0.8598 - val_loss: 0.1092 - val_precision_1: 0.8313 - val_recall_1: 0.5545\n",
      "Epoch 42/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0295 - precision_1: 0.9405 - recall_1: 0.8690 \n",
      "Epoch 42: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0291 - precision_1: 0.9403 - recall_1: 0.8671 - val_loss: 0.1099 - val_precision_1: 0.8318 - val_recall_1: 0.5525\n",
      "Epoch 43/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0275 - precision_1: 0.9487 - recall_1: 0.8716 \n",
      "Epoch 43: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0272 - precision_1: 0.9478 - recall_1: 0.8720 - val_loss: 0.1098 - val_precision_1: 0.8281 - val_recall_1: 0.5549\n",
      "Epoch 44/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0274 - precision_1: 0.9470 - recall_1: 0.8646 \n",
      "Epoch 44: val_loss did not improve from 0.10749\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0271 - precision_1: 0.9472 - recall_1: 0.8654 - val_loss: 0.1098 - val_precision_1: 0.8260 - val_recall_1: 0.5540\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - precision_1: 0.9893 - recall_1: 0.8850 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1082 - precision_1: 0.8067 - recall_1: 0.5115\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1228 - precision_1: 0.8040 - recall_1: 0.4668\n",
      "Epoch 1/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6091 - precision_2: 0.0521 - recall_2: 0.3156  \n",
      "Epoch 1: val_loss improved from inf to 0.24494, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5931 - precision_2: 0.0521 - recall_2: 0.2965 - val_loss: 0.2449 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2630 - precision_2: 0.1637 - recall_2: 0.0015     \n",
      "Epoch 2: val_loss improved from 0.24494 to 0.21154, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2604 - precision_2: 0.1695 - recall_2: 0.0027 - val_loss: 0.2115 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2247 - precision_2: 0.1968 - recall_2: 0.0358 \n",
      "Epoch 3: val_loss improved from 0.21154 to 0.20003, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2229 - precision_2: 0.1989 - recall_2: 0.0346 - val_loss: 0.2000 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2008 - precision_2: 0.3600 - recall_2: 0.0087 \n",
      "Epoch 4: val_loss improved from 0.20003 to 0.18795, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1994 - precision_2: 0.3636 - recall_2: 0.0089 - val_loss: 0.1879 - val_precision_2: 0.7500 - val_recall_2: 4.9727e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1813 - precision_2: 0.4694 - recall_2: 0.0316 \n",
      "Epoch 5: val_loss improved from 0.18795 to 0.17672, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1801 - precision_2: 0.4702 - recall_2: 0.0336 - val_loss: 0.1767 - val_precision_2: 0.5976 - val_recall_2: 0.0081\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1636 - precision_2: 0.5123 - recall_2: 0.0699 \n",
      "Epoch 6: val_loss improved from 0.17672 to 0.16850, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1628 - precision_2: 0.5171 - recall_2: 0.0707 - val_loss: 0.1685 - val_precision_2: 0.5450 - val_recall_2: 0.0171\n",
      "Epoch 7/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1520 - precision_2: 0.5850 - recall_2: 0.0951 \n",
      "Epoch 7: val_loss improved from 0.16850 to 0.16206, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1505 - precision_2: 0.5901 - recall_2: 0.0972 - val_loss: 0.1621 - val_precision_2: 0.5414 - val_recall_2: 0.0325\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1404 - precision_2: 0.6660 - recall_2: 0.1241 \n",
      "Epoch 8: val_loss improved from 0.16206 to 0.15639, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1387 - precision_2: 0.6649 - recall_2: 0.1277 - val_loss: 0.1564 - val_precision_2: 0.5752 - val_recall_2: 0.0501\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1308 - precision_2: 0.6966 - recall_2: 0.1619 \n",
      "Epoch 9: val_loss improved from 0.15639 to 0.15169, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1293 - precision_2: 0.6996 - recall_2: 0.1651 - val_loss: 0.1517 - val_precision_2: 0.6176 - val_recall_2: 0.0688\n",
      "Epoch 10/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1229 - precision_2: 0.7322 - recall_2: 0.1993 \n",
      "Epoch 10: val_loss improved from 0.15169 to 0.14792, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1212 - precision_2: 0.7340 - recall_2: 0.2043 - val_loss: 0.1479 - val_precision_2: 0.6441 - val_recall_2: 0.0930\n",
      "Epoch 11/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1166 - precision_2: 0.7545 - recall_2: 0.2243 \n",
      "Epoch 11: val_loss improved from 0.14792 to 0.14330, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1147 - precision_2: 0.7565 - recall_2: 0.2323 - val_loss: 0.1433 - val_precision_2: 0.6670 - val_recall_2: 0.1132\n",
      "Epoch 12/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1092 - precision_2: 0.7886 - recall_2: 0.2730 \n",
      "Epoch 12: val_loss improved from 0.14330 to 0.13919, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1080 - precision_2: 0.7881 - recall_2: 0.2765 - val_loss: 0.1392 - val_precision_2: 0.6777 - val_recall_2: 0.1523\n",
      "Epoch 13/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1033 - precision_2: 0.7846 - recall_2: 0.3362 \n",
      "Epoch 13: val_loss improved from 0.13919 to 0.13611, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1020 - precision_2: 0.7882 - recall_2: 0.3363 - val_loss: 0.1361 - val_precision_2: 0.7142 - val_recall_2: 0.1644\n",
      "Epoch 14/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0965 - precision_2: 0.8317 - recall_2: 0.3533 \n",
      "Epoch 14: val_loss improved from 0.13611 to 0.13250, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0957 - precision_2: 0.8293 - recall_2: 0.3582 - val_loss: 0.1325 - val_precision_2: 0.7345 - val_recall_2: 0.1999\n",
      "Epoch 15/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0930 - precision_2: 0.8158 - recall_2: 0.4090 \n",
      "Epoch 15: val_loss improved from 0.13250 to 0.13006, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0917 - precision_2: 0.8175 - recall_2: 0.4149 - val_loss: 0.1301 - val_precision_2: 0.7487 - val_recall_2: 0.2198\n",
      "Epoch 16/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0864 - precision_2: 0.8519 - recall_2: 0.4583 \n",
      "Epoch 16: val_loss improved from 0.13006 to 0.12714, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0856 - precision_2: 0.8493 - recall_2: 0.4564 - val_loss: 0.1271 - val_precision_2: 0.7585 - val_recall_2: 0.2577\n",
      "Epoch 17/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0842 - precision_2: 0.8306 - recall_2: 0.4764 \n",
      "Epoch 17: val_loss improved from 0.12714 to 0.12516, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0829 - precision_2: 0.8356 - recall_2: 0.4827 - val_loss: 0.1252 - val_precision_2: 0.7729 - val_recall_2: 0.2556\n",
      "Epoch 18/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0790 - precision_2: 0.8538 - recall_2: 0.5214 \n",
      "Epoch 18: val_loss improved from 0.12516 to 0.12266, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0781 - precision_2: 0.8560 - recall_2: 0.5202 - val_loss: 0.1227 - val_precision_2: 0.7790 - val_recall_2: 0.2793\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0749 - precision_2: 0.8536 - recall_2: 0.5545 \n",
      "Epoch 19: val_loss improved from 0.12266 to 0.12098, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0745 - precision_2: 0.8524 - recall_2: 0.5502 - val_loss: 0.1210 - val_precision_2: 0.7854 - val_recall_2: 0.3003\n",
      "Epoch 20/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0733 - precision_2: 0.8724 - recall_2: 0.5539 \n",
      "Epoch 20: val_loss improved from 0.12098 to 0.11858, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0724 - precision_2: 0.8700 - recall_2: 0.5565 - val_loss: 0.1186 - val_precision_2: 0.7994 - val_recall_2: 0.3289\n",
      "Epoch 21/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0682 - precision_2: 0.8827 - recall_2: 0.5865 \n",
      "Epoch 21: val_loss improved from 0.11858 to 0.11727, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0676 - precision_2: 0.8802 - recall_2: 0.5877 - val_loss: 0.1173 - val_precision_2: 0.8056 - val_recall_2: 0.3434\n",
      "Epoch 22/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0682 - precision_2: 0.8713 - recall_2: 0.5995 \n",
      "Epoch 22: val_loss improved from 0.11727 to 0.11615, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0669 - precision_2: 0.8727 - recall_2: 0.6036 - val_loss: 0.1162 - val_precision_2: 0.8061 - val_recall_2: 0.3570\n",
      "Epoch 23/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0638 - precision_2: 0.8890 - recall_2: 0.6289 \n",
      "Epoch 23: val_loss improved from 0.11615 to 0.11395, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0631 - precision_2: 0.8906 - recall_2: 0.6280 - val_loss: 0.1140 - val_precision_2: 0.8044 - val_recall_2: 0.3796\n",
      "Epoch 24/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0617 - precision_2: 0.8750 - recall_2: 0.6625 \n",
      "Epoch 24: val_loss did not improve from 0.11395\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0608 - precision_2: 0.8777 - recall_2: 0.6613 - val_loss: 0.1140 - val_precision_2: 0.8110 - val_recall_2: 0.3854\n",
      "Epoch 25/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0611 - precision_2: 0.8803 - recall_2: 0.6490 \n",
      "Epoch 25: val_loss improved from 0.11395 to 0.11237, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0600 - precision_2: 0.8810 - recall_2: 0.6523 - val_loss: 0.1124 - val_precision_2: 0.8262 - val_recall_2: 0.3963\n",
      "Epoch 26/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0572 - precision_2: 0.9042 - recall_2: 0.6639 \n",
      "Epoch 26: val_loss improved from 0.11237 to 0.11159, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0567 - precision_2: 0.9004 - recall_2: 0.6671 - val_loss: 0.1116 - val_precision_2: 0.8221 - val_recall_2: 0.4167\n",
      "Epoch 27/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0547 - precision_2: 0.8981 - recall_2: 0.6937 \n",
      "Epoch 27: val_loss improved from 0.11159 to 0.11087, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0544 - precision_2: 0.8976 - recall_2: 0.6933 - val_loss: 0.1109 - val_precision_2: 0.8277 - val_recall_2: 0.4213\n",
      "Epoch 28/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0535 - precision_2: 0.8958 - recall_2: 0.7068 \n",
      "Epoch 28: val_loss improved from 0.11087 to 0.11023, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0531 - precision_2: 0.8950 - recall_2: 0.7062 - val_loss: 0.1102 - val_precision_2: 0.8269 - val_recall_2: 0.4260\n",
      "Epoch 29/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0520 - precision_2: 0.8997 - recall_2: 0.7055 \n",
      "Epoch 29: val_loss improved from 0.11023 to 0.10976, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0513 - precision_2: 0.9003 - recall_2: 0.7079 - val_loss: 0.1098 - val_precision_2: 0.8290 - val_recall_2: 0.4442\n",
      "Epoch 30/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0508 - precision_2: 0.8957 - recall_2: 0.7182 \n",
      "Epoch 30: val_loss improved from 0.10976 to 0.10964, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0499 - precision_2: 0.8968 - recall_2: 0.7221 - val_loss: 0.1096 - val_precision_2: 0.8392 - val_recall_2: 0.4402\n",
      "Epoch 31/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0474 - precision_2: 0.9096 - recall_2: 0.7317 \n",
      "Epoch 31: val_loss improved from 0.10964 to 0.10891, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0472 - precision_2: 0.9085 - recall_2: 0.7334 - val_loss: 0.1089 - val_precision_2: 0.8316 - val_recall_2: 0.4641\n",
      "Epoch 32/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0476 - precision_2: 0.9078 - recall_2: 0.7338 \n",
      "Epoch 32: val_loss improved from 0.10891 to 0.10845, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0474 - precision_2: 0.9058 - recall_2: 0.7343 - val_loss: 0.1085 - val_precision_2: 0.8327 - val_recall_2: 0.4810\n",
      "Epoch 33/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0455 - precision_2: 0.9096 - recall_2: 0.7615 \n",
      "Epoch 33: val_loss improved from 0.10845 to 0.10794, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0453 - precision_2: 0.9068 - recall_2: 0.7599 - val_loss: 0.1079 - val_precision_2: 0.8359 - val_recall_2: 0.4830\n",
      "Epoch 34/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0458 - precision_2: 0.9098 - recall_2: 0.7453 \n",
      "Epoch 34: val_loss improved from 0.10794 to 0.10660, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0450 - precision_2: 0.9103 - recall_2: 0.7484 - val_loss: 0.1066 - val_precision_2: 0.8372 - val_recall_2: 0.4928\n",
      "Epoch 35/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0431 - precision_2: 0.9163 - recall_2: 0.7729 \n",
      "Epoch 35: val_loss did not improve from 0.10660\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0426 - precision_2: 0.9155 - recall_2: 0.7738 - val_loss: 0.1071 - val_precision_2: 0.8370 - val_recall_2: 0.4978\n",
      "Epoch 36/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0422 - precision_2: 0.9131 - recall_2: 0.7692 \n",
      "Epoch 36: val_loss did not improve from 0.10660\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0421 - precision_2: 0.9125 - recall_2: 0.7702 - val_loss: 0.1074 - val_precision_2: 0.8381 - val_recall_2: 0.5052\n",
      "Epoch 37/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0407 - precision_2: 0.9151 - recall_2: 0.7881 \n",
      "Epoch 37: val_loss improved from 0.10660 to 0.10624, saving model to 62sec_1layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0403 - precision_2: 0.9156 - recall_2: 0.7874 - val_loss: 0.1062 - val_precision_2: 0.8404 - val_recall_2: 0.5142\n",
      "Epoch 38/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0392 - precision_2: 0.9142 - recall_2: 0.8053 \n",
      "Epoch 38: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0394 - precision_2: 0.9133 - recall_2: 0.8014 - val_loss: 0.1063 - val_precision_2: 0.8440 - val_recall_2: 0.5102\n",
      "Epoch 39/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - precision_2: 0.9187 - recall_2: 0.8017 \n",
      "Epoch 39: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0385 - precision_2: 0.9185 - recall_2: 0.7996 - val_loss: 0.1075 - val_precision_2: 0.8454 - val_recall_2: 0.5140\n",
      "Epoch 40/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - precision_2: 0.9245 - recall_2: 0.8055 \n",
      "Epoch 40: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0380 - precision_2: 0.9224 - recall_2: 0.8042 - val_loss: 0.1081 - val_precision_2: 0.8322 - val_recall_2: 0.5228\n",
      "Epoch 41/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0366 - precision_2: 0.9206 - recall_2: 0.8160 \n",
      "Epoch 41: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0362 - precision_2: 0.9214 - recall_2: 0.8149 - val_loss: 0.1082 - val_precision_2: 0.8362 - val_recall_2: 0.5254\n",
      "Epoch 42/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - precision_2: 0.9232 - recall_2: 0.8124 \n",
      "Epoch 42: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0356 - precision_2: 0.9225 - recall_2: 0.8133 - val_loss: 0.1075 - val_precision_2: 0.8304 - val_recall_2: 0.5347\n",
      "Epoch 43/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0359 - precision_2: 0.9273 - recall_2: 0.8142 \n",
      "Epoch 43: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0355 - precision_2: 0.9262 - recall_2: 0.8172 - val_loss: 0.1088 - val_precision_2: 0.8412 - val_recall_2: 0.5314\n",
      "Epoch 44/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0334 - precision_2: 0.9328 - recall_2: 0.8296 \n",
      "Epoch 44: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0333 - precision_2: 0.9314 - recall_2: 0.8293 - val_loss: 0.1080 - val_precision_2: 0.8374 - val_recall_2: 0.5354\n",
      "Epoch 45/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0329 - precision_2: 0.9206 - recall_2: 0.8434 \n",
      "Epoch 45: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0327 - precision_2: 0.9211 - recall_2: 0.8410 - val_loss: 0.1085 - val_precision_2: 0.8345 - val_recall_2: 0.5382\n",
      "Epoch 46/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0326 - precision_2: 0.9301 - recall_2: 0.8315 \n",
      "Epoch 46: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0322 - precision_2: 0.9299 - recall_2: 0.8327 - val_loss: 0.1086 - val_precision_2: 0.8383 - val_recall_2: 0.5395\n",
      "Epoch 47/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0327 - precision_2: 0.9260 - recall_2: 0.8426 \n",
      "Epoch 47: val_loss did not improve from 0.10624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0323 - precision_2: 0.9253 - recall_2: 0.8412 - val_loss: 0.1090 - val_precision_2: 0.8363 - val_recall_2: 0.5452\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - precision_2: 0.9884 - recall_2: 0.8692 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1070 - precision_2: 0.8306 - recall_2: 0.5034 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1219 - precision_2: 0.8199 - recall_2: 0.4613\n",
      "Epoch 1/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6067 - precision_3: 0.0521 - recall_3: 0.2930  \n",
      "Epoch 1: val_loss improved from inf to 0.24687, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5276 - precision_3: 0.0521 - recall_3: 0.2132 - val_loss: 0.2469 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2573 - precision_3: 0.1919 - recall_3: 0.0046         \n",
      "Epoch 2: val_loss improved from 0.24687 to 0.20280, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2450 - precision_3: 0.2159 - recall_3: 0.0111 - val_loss: 0.2028 - val_precision_3: 0.2500 - val_recall_3: 1.6576e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2031 - precision_3: 0.3237 - recall_3: 0.0048 \n",
      "Epoch 3: val_loss improved from 0.20280 to 0.18319, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1968 - precision_3: 0.3609 - recall_3: 0.0043 - val_loss: 0.1832 - val_precision_3: 0.8621 - val_recall_3: 0.0041\n",
      "Epoch 4/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1714 - precision_3: 0.6020 - recall_3: 0.0316 \n",
      "Epoch 4: val_loss improved from 0.18319 to 0.16679, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1660 - precision_3: 0.5966 - recall_3: 0.0431 - val_loss: 0.1668 - val_precision_3: 0.5934 - val_recall_3: 0.0300\n",
      "Epoch 5/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1486 - precision_3: 0.6704 - recall_3: 0.0955 \n",
      "Epoch 5: val_loss improved from 0.16679 to 0.15581, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1432 - precision_3: 0.6841 - recall_3: 0.1062 - val_loss: 0.1558 - val_precision_3: 0.5747 - val_recall_3: 0.0670\n",
      "Epoch 6/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1274 - precision_3: 0.7626 - recall_3: 0.1837 \n",
      "Epoch 6: val_loss improved from 0.15581 to 0.14786, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1239 - precision_3: 0.7637 - recall_3: 0.1846 - val_loss: 0.1479 - val_precision_3: 0.6221 - val_recall_3: 0.1140\n",
      "Epoch 7/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1123 - precision_3: 0.8078 - recall_3: 0.2732 \n",
      "Epoch 7: val_loss improved from 0.14786 to 0.14089, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1092 - precision_3: 0.8090 - recall_3: 0.2813 - val_loss: 0.1409 - val_precision_3: 0.6704 - val_recall_3: 0.1470\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0966 - precision_3: 0.8479 - recall_3: 0.3531\n",
      "Epoch 8: val_loss improved from 0.14089 to 0.13396, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0964 - precision_3: 0.8483 - recall_3: 0.3550 - val_loss: 0.1340 - val_precision_3: 0.7168 - val_recall_3: 0.2077\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0850 - precision_3: 0.8783 - recall_3: 0.4468\n",
      "Epoch 9: val_loss improved from 0.13396 to 0.12760, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0848 - precision_3: 0.8787 - recall_3: 0.4478 - val_loss: 0.1276 - val_precision_3: 0.7219 - val_recall_3: 0.2745\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0752 - precision_3: 0.8988 - recall_3: 0.5371\n",
      "Epoch 10: val_loss improved from 0.12760 to 0.12281, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0751 - precision_3: 0.8993 - recall_3: 0.5374 - val_loss: 0.1228 - val_precision_3: 0.7468 - val_recall_3: 0.3143\n",
      "Epoch 11/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0693 - precision_3: 0.9020 - recall_3: 0.6027 \n",
      "Epoch 11: val_loss improved from 0.12281 to 0.11902, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0670 - precision_3: 0.9064 - recall_3: 0.6059 - val_loss: 0.1190 - val_precision_3: 0.7669 - val_recall_3: 0.3507\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0600 - precision_3: 0.9290 - recall_3: 0.6533\n",
      "Epoch 12: val_loss improved from 0.11902 to 0.11541, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0599 - precision_3: 0.9290 - recall_3: 0.6539 - val_loss: 0.1154 - val_precision_3: 0.7703 - val_recall_3: 0.3907\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0543 - precision_3: 0.9252 - recall_3: 0.7016\n",
      "Epoch 13: val_loss improved from 0.11541 to 0.11255, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0542 - precision_3: 0.9256 - recall_3: 0.7021 - val_loss: 0.1126 - val_precision_3: 0.7868 - val_recall_3: 0.4202\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0485 - precision_3: 0.9420 - recall_3: 0.7372\n",
      "Epoch 14: val_loss improved from 0.11255 to 0.11071, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0484 - precision_3: 0.9420 - recall_3: 0.7375 - val_loss: 0.1107 - val_precision_3: 0.7845 - val_recall_3: 0.4434\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0441 - precision_3: 0.9430 - recall_3: 0.7692\n",
      "Epoch 15: val_loss improved from 0.11071 to 0.10898, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0440 - precision_3: 0.9430 - recall_3: 0.7696 - val_loss: 0.1090 - val_precision_3: 0.8010 - val_recall_3: 0.4676\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0407 - precision_3: 0.9515 - recall_3: 0.7907\n",
      "Epoch 16: val_loss improved from 0.10898 to 0.10708, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0406 - precision_3: 0.9516 - recall_3: 0.7910 - val_loss: 0.1071 - val_precision_3: 0.8092 - val_recall_3: 0.5027\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0371 - precision_3: 0.9505 - recall_3: 0.8229\n",
      "Epoch 17: val_loss did not improve from 0.10708\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0370 - precision_3: 0.9508 - recall_3: 0.8231 - val_loss: 0.1071 - val_precision_3: 0.8121 - val_recall_3: 0.5128\n",
      "Epoch 18/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0344 - precision_3: 0.9543 - recall_3: 0.8404\n",
      "Epoch 18: val_loss improved from 0.10708 to 0.10640, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0342 - precision_3: 0.9549 - recall_3: 0.8409 - val_loss: 0.1064 - val_precision_3: 0.8164 - val_recall_3: 0.5220\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0319 - precision_3: 0.9585 - recall_3: 0.8521\n",
      "Epoch 19: val_loss did not improve from 0.10640\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0318 - precision_3: 0.9584 - recall_3: 0.8526 - val_loss: 0.1075 - val_precision_3: 0.8216 - val_recall_3: 0.5244\n",
      "Epoch 20/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0295 - precision_3: 0.9614 - recall_3: 0.8592\n",
      "Epoch 20: val_loss improved from 0.10640 to 0.10564, saving model to 62sec_1layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0293 - precision_3: 0.9617 - recall_3: 0.8598 - val_loss: 0.1056 - val_precision_3: 0.8145 - val_recall_3: 0.5523\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0272 - precision_3: 0.9606 - recall_3: 0.8871\n",
      "Epoch 21: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0271 - precision_3: 0.9609 - recall_3: 0.8872 - val_loss: 0.1077 - val_precision_3: 0.8195 - val_recall_3: 0.5495\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0257 - precision_3: 0.9653 - recall_3: 0.8882\n",
      "Epoch 22: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0257 - precision_3: 0.9654 - recall_3: 0.8883 - val_loss: 0.1068 - val_precision_3: 0.8164 - val_recall_3: 0.5616\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0236 - precision_3: 0.9682 - recall_3: 0.9045\n",
      "Epoch 23: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0235 - precision_3: 0.9682 - recall_3: 0.9046 - val_loss: 0.1079 - val_precision_3: 0.8293 - val_recall_3: 0.5675\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0221 - precision_3: 0.9695 - recall_3: 0.9085\n",
      "Epoch 24: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0221 - precision_3: 0.9695 - recall_3: 0.9086 - val_loss: 0.1084 - val_precision_3: 0.8220 - val_recall_3: 0.5778\n",
      "Epoch 25/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0211 - precision_3: 0.9672 - recall_3: 0.9191\n",
      "Epoch 25: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0210 - precision_3: 0.9676 - recall_3: 0.9187 - val_loss: 0.1087 - val_precision_3: 0.8253 - val_recall_3: 0.5811\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - precision_3: 0.9716 - recall_3: 0.9208\n",
      "Epoch 26: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0201 - precision_3: 0.9718 - recall_3: 0.9210 - val_loss: 0.1099 - val_precision_3: 0.8237 - val_recall_3: 0.5878\n",
      "Epoch 27/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0189 - precision_3: 0.9739 - recall_3: 0.9248\n",
      "Epoch 27: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0189 - precision_3: 0.9739 - recall_3: 0.9250 - val_loss: 0.1111 - val_precision_3: 0.8256 - val_recall_3: 0.5861\n",
      "Epoch 28/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0178 - precision_3: 0.9717 - recall_3: 0.9356\n",
      "Epoch 28: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0177 - precision_3: 0.9719 - recall_3: 0.9354 - val_loss: 0.1111 - val_precision_3: 0.8326 - val_recall_3: 0.5884\n",
      "Epoch 29/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0168 - precision_3: 0.9749 - recall_3: 0.9378\n",
      "Epoch 29: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0168 - precision_3: 0.9750 - recall_3: 0.9378 - val_loss: 0.1122 - val_precision_3: 0.8317 - val_recall_3: 0.5881\n",
      "Epoch 30/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0158 - precision_3: 0.9772 - recall_3: 0.9433\n",
      "Epoch 30: val_loss did not improve from 0.10564\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0157 - precision_3: 0.9772 - recall_3: 0.9434 - val_loss: 0.1135 - val_precision_3: 0.8328 - val_recall_3: 0.5911\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0197 - precision_3: 0.9893 - recall_3: 0.9220 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1061 - precision_3: 0.8025 - recall_3: 0.5437 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1208 - precision_3: 0.8168 - recall_3: 0.5001 \n",
      "Epoch 1/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6150 - precision_4: 0.0517 - recall_4: 0.3076  \n",
      "Epoch 1: val_loss improved from inf to 0.25084, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5368 - precision_4: 0.0519 - recall_4: 0.2269 - val_loss: 0.2508 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2660 - precision_4: 0.2338 - recall_4: 0.0026         \n",
      "Epoch 2: val_loss improved from 0.25084 to 0.20294, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2507 - precision_4: 0.2239 - recall_4: 0.0116 - val_loss: 0.2029 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2075 - precision_4: 0.3116 - recall_4: 0.0179 \n",
      "Epoch 3: val_loss improved from 0.20294 to 0.18488, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2011 - precision_4: 0.3277 - recall_4: 0.0144 - val_loss: 0.1849 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1720 - precision_4: 0.5546 - recall_4: 0.0311\n",
      "Epoch 4: val_loss improved from 0.18488 to 0.16787, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1715 - precision_4: 0.5557 - recall_4: 0.0327 - val_loss: 0.1679 - val_precision_4: 0.5309 - val_recall_4: 0.0313\n",
      "Epoch 5/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1524 - precision_4: 0.6016 - recall_4: 0.0932 \n",
      "Epoch 5: val_loss improved from 0.16787 to 0.15724, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1478 - precision_4: 0.6256 - recall_4: 0.0988 - val_loss: 0.1572 - val_precision_4: 0.5631 - val_recall_4: 0.0577\n",
      "Epoch 6/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1346 - precision_4: 0.6920 - recall_4: 0.1579 \n",
      "Epoch 6: val_loss improved from 0.15724 to 0.14944, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1299 - precision_4: 0.7095 - recall_4: 0.1652 - val_loss: 0.1494 - val_precision_4: 0.5866 - val_recall_4: 0.0724\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1152 - precision_4: 0.7865 - recall_4: 0.2339\n",
      "Epoch 7: val_loss improved from 0.14944 to 0.14254, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1149 - precision_4: 0.7872 - recall_4: 0.2360 - val_loss: 0.1425 - val_precision_4: 0.6383 - val_recall_4: 0.1182\n",
      "Epoch 8/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1052 - precision_4: 0.8297 - recall_4: 0.2993 \n",
      "Epoch 8: val_loss improved from 0.14254 to 0.13602, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1024 - precision_4: 0.8334 - recall_4: 0.3093 - val_loss: 0.1360 - val_precision_4: 0.6815 - val_recall_4: 0.1979\n",
      "Epoch 9/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0945 - precision_4: 0.8499 - recall_4: 0.3950 \n",
      "Epoch 9: val_loss improved from 0.13602 to 0.13040, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0915 - precision_4: 0.8557 - recall_4: 0.3994 - val_loss: 0.1304 - val_precision_4: 0.7158 - val_recall_4: 0.2375\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0818 - precision_4: 0.8674 - recall_4: 0.4887\n",
      "Epoch 10: val_loss improved from 0.13040 to 0.12626, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0816 - precision_4: 0.8681 - recall_4: 0.4897 - val_loss: 0.1263 - val_precision_4: 0.7418 - val_recall_4: 0.2558\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0739 - precision_4: 0.8997 - recall_4: 0.5404\n",
      "Epoch 11: val_loss improved from 0.12626 to 0.12122, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0737 - precision_4: 0.8999 - recall_4: 0.5417 - val_loss: 0.1212 - val_precision_4: 0.7590 - val_recall_4: 0.3284\n",
      "Epoch 12/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680 - precision_4: 0.9010 - recall_4: 0.6025 \n",
      "Epoch 12: val_loss improved from 0.12122 to 0.11763, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0662 - precision_4: 0.9054 - recall_4: 0.6031 - val_loss: 0.1176 - val_precision_4: 0.7651 - val_recall_4: 0.3564\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0608 - precision_4: 0.9117 - recall_4: 0.6455\n",
      "Epoch 13: val_loss improved from 0.11763 to 0.11529, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0606 - precision_4: 0.9120 - recall_4: 0.6462 - val_loss: 0.1153 - val_precision_4: 0.7876 - val_recall_4: 0.3774\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0546 - precision_4: 0.9244 - recall_4: 0.6913\n",
      "Epoch 14: val_loss improved from 0.11529 to 0.11320, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0545 - precision_4: 0.9244 - recall_4: 0.6915 - val_loss: 0.1132 - val_precision_4: 0.7859 - val_recall_4: 0.4137\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0509 - precision_4: 0.9282 - recall_4: 0.7190\n",
      "Epoch 15: val_loss improved from 0.11320 to 0.11079, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0508 - precision_4: 0.9284 - recall_4: 0.7193 - val_loss: 0.1108 - val_precision_4: 0.7855 - val_recall_4: 0.4510\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0462 - precision_4: 0.9340 - recall_4: 0.7575\n",
      "Epoch 16: val_loss improved from 0.11079 to 0.10972, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0461 - precision_4: 0.9342 - recall_4: 0.7577 - val_loss: 0.1097 - val_precision_4: 0.7994 - val_recall_4: 0.4525\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0436 - precision_4: 0.9360 - recall_4: 0.7694\n",
      "Epoch 17: val_loss improved from 0.10972 to 0.10861, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0435 - precision_4: 0.9362 - recall_4: 0.7699 - val_loss: 0.1086 - val_precision_4: 0.7972 - val_recall_4: 0.4804\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0399 - precision_4: 0.9435 - recall_4: 0.7915\n",
      "Epoch 18: val_loss improved from 0.10861 to 0.10700, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0398 - precision_4: 0.9436 - recall_4: 0.7915 - val_loss: 0.1070 - val_precision_4: 0.7993 - val_recall_4: 0.5002\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0372 - precision_4: 0.9372 - recall_4: 0.8174\n",
      "Epoch 19: val_loss did not improve from 0.10700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0372 - precision_4: 0.9376 - recall_4: 0.8175 - val_loss: 0.1077 - val_precision_4: 0.8120 - val_recall_4: 0.5077\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0351 - precision_4: 0.9521 - recall_4: 0.8225\n",
      "Epoch 20: val_loss improved from 0.10700 to 0.10625, saving model to 62sec_1layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0351 - precision_4: 0.9519 - recall_4: 0.8228 - val_loss: 0.1062 - val_precision_4: 0.8103 - val_recall_4: 0.5304\n",
      "Epoch 21/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0327 - precision_4: 0.9521 - recall_4: 0.8436 \n",
      "Epoch 21: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0321 - precision_4: 0.9525 - recall_4: 0.8441 - val_loss: 0.1066 - val_precision_4: 0.8139 - val_recall_4: 0.5438\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0302 - precision_4: 0.9557 - recall_4: 0.8555\n",
      "Epoch 22: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0301 - precision_4: 0.9556 - recall_4: 0.8557 - val_loss: 0.1071 - val_precision_4: 0.8155 - val_recall_4: 0.5443\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0295 - precision_4: 0.9529 - recall_4: 0.8577\n",
      "Epoch 23: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0294 - precision_4: 0.9531 - recall_4: 0.8578 - val_loss: 0.1070 - val_precision_4: 0.8125 - val_recall_4: 0.5545\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0268 - precision_4: 0.9549 - recall_4: 0.8879\n",
      "Epoch 24: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0268 - precision_4: 0.9550 - recall_4: 0.8874 - val_loss: 0.1074 - val_precision_4: 0.8176 - val_recall_4: 0.5609\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0256 - precision_4: 0.9600 - recall_4: 0.8820\n",
      "Epoch 25: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0256 - precision_4: 0.9600 - recall_4: 0.8820 - val_loss: 0.1084 - val_precision_4: 0.8161 - val_recall_4: 0.5649\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0244 - precision_4: 0.9614 - recall_4: 0.8930\n",
      "Epoch 26: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0244 - precision_4: 0.9615 - recall_4: 0.8931 - val_loss: 0.1092 - val_precision_4: 0.8169 - val_recall_4: 0.5700\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0235 - precision_4: 0.9623 - recall_4: 0.8975\n",
      "Epoch 27: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0235 - precision_4: 0.9623 - recall_4: 0.8978 - val_loss: 0.1097 - val_precision_4: 0.8172 - val_recall_4: 0.5767\n",
      "Epoch 28/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0225 - precision_4: 0.9638 - recall_4: 0.9051\n",
      "Epoch 28: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0225 - precision_4: 0.9637 - recall_4: 0.9052 - val_loss: 0.1094 - val_precision_4: 0.8205 - val_recall_4: 0.5825\n",
      "Epoch 29/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0213 - precision_4: 0.9617 - recall_4: 0.9098\n",
      "Epoch 29: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - precision_4: 0.9618 - recall_4: 0.9098 - val_loss: 0.1107 - val_precision_4: 0.8204 - val_recall_4: 0.5859\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0199 - precision_4: 0.9655 - recall_4: 0.9207\n",
      "Epoch 30: val_loss did not improve from 0.10625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0199 - precision_4: 0.9656 - recall_4: 0.9207 - val_loss: 0.1120 - val_precision_4: 0.8247 - val_recall_4: 0.5810\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - precision_4: 0.9904 - recall_4: 0.8942 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - precision_4: 0.7961 - recall_4: 0.5182 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1218 - precision_4: 0.8139 - recall_4: 0.4812 \n",
      "Epoch 1/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6293 - precision_5: 0.0504 - recall_5: 0.3210  \n",
      "Epoch 1: val_loss improved from inf to 0.25236, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.5391 - precision_5: 0.0506 - recall_5: 0.2262 - val_loss: 0.2524 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2667 - precision_5: 0.2272 - recall_5: 0.0048     \n",
      "Epoch 2: val_loss improved from 0.25236 to 0.20363, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2539 - precision_5: 0.2230 - recall_5: 0.0143 - val_loss: 0.2036 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2107 - precision_5: 0.2721 - recall_5: 0.0327 \n",
      "Epoch 3: val_loss improved from 0.20363 to 0.18651, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2042 - precision_5: 0.2864 - recall_5: 0.0273 - val_loss: 0.1865 - val_precision_5: 1.0000 - val_recall_5: 1.6576e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1805 - precision_5: 0.4900 - recall_5: 0.0181 \n",
      "Epoch 4: val_loss improved from 0.18651 to 0.16997, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1753 - precision_5: 0.5080 - recall_5: 0.0293 - val_loss: 0.1700 - val_precision_5: 0.5448 - val_recall_5: 0.0262\n",
      "Epoch 5/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1583 - precision_5: 0.5587 - recall_5: 0.0961 \n",
      "Epoch 5: val_loss improved from 0.16997 to 0.15912, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1535 - precision_5: 0.5736 - recall_5: 0.1008 - val_loss: 0.1591 - val_precision_5: 0.6361 - val_recall_5: 0.0403\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1360 - precision_5: 0.6719 - recall_5: 0.1459\n",
      "Epoch 6: val_loss improved from 0.15912 to 0.15162, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1357 - precision_5: 0.6732 - recall_5: 0.1469 - val_loss: 0.1516 - val_precision_5: 0.6412 - val_recall_5: 0.0613\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1212 - precision_5: 0.7629 - recall_5: 0.1967\n",
      "Epoch 7: val_loss improved from 0.15162 to 0.14510, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1210 - precision_5: 0.7629 - recall_5: 0.1983 - val_loss: 0.1451 - val_precision_5: 0.6625 - val_recall_5: 0.1061\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1097 - precision_5: 0.7965 - recall_5: 0.2616\n",
      "Epoch 8: val_loss improved from 0.14510 to 0.13886, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1094 - precision_5: 0.7971 - recall_5: 0.2632 - val_loss: 0.1389 - val_precision_5: 0.6928 - val_recall_5: 0.1525\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1003 - precision_5: 0.8153 - recall_5: 0.3349\n",
      "Epoch 9: val_loss improved from 0.13886 to 0.13374, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1001 - precision_5: 0.8161 - recall_5: 0.3360 - val_loss: 0.1337 - val_precision_5: 0.6952 - val_recall_5: 0.1842\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0915 - precision_5: 0.8476 - recall_5: 0.4035\n",
      "Epoch 10: val_loss improved from 0.13374 to 0.12950, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0913 - precision_5: 0.8481 - recall_5: 0.4048 - val_loss: 0.1295 - val_precision_5: 0.7252 - val_recall_5: 0.2156\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0823 - precision_5: 0.8582 - recall_5: 0.4702\n",
      "Epoch 11: val_loss improved from 0.12950 to 0.12493, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0822 - precision_5: 0.8590 - recall_5: 0.4712 - val_loss: 0.1249 - val_precision_5: 0.7436 - val_recall_5: 0.2591\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0755 - precision_5: 0.8833 - recall_5: 0.5365\n",
      "Epoch 12: val_loss improved from 0.12493 to 0.12130, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0751 - precision_5: 0.8834 - recall_5: 0.5380 - val_loss: 0.1213 - val_precision_5: 0.7610 - val_recall_5: 0.3018\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0697 - precision_5: 0.8865 - recall_5: 0.5740\n",
      "Epoch 13: val_loss improved from 0.12130 to 0.11763, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0695 - precision_5: 0.8868 - recall_5: 0.5748 - val_loss: 0.1176 - val_precision_5: 0.7685 - val_recall_5: 0.3335\n",
      "Epoch 14/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0645 - precision_5: 0.8852 - recall_5: 0.6210\n",
      "Epoch 14: val_loss improved from 0.11763 to 0.11522, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0641 - precision_5: 0.8866 - recall_5: 0.6212 - val_loss: 0.1152 - val_precision_5: 0.7772 - val_recall_5: 0.3585\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0591 - precision_5: 0.9089 - recall_5: 0.6576\n",
      "Epoch 15: val_loss improved from 0.11522 to 0.11278, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0590 - precision_5: 0.9090 - recall_5: 0.6580 - val_loss: 0.1128 - val_precision_5: 0.7893 - val_recall_5: 0.3857\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0549 - precision_5: 0.9143 - recall_5: 0.6899\n",
      "Epoch 16: val_loss improved from 0.11278 to 0.11010, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0545 - precision_5: 0.9155 - recall_5: 0.6902 - val_loss: 0.1101 - val_precision_5: 0.7926 - val_recall_5: 0.4180\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0512 - precision_5: 0.9148 - recall_5: 0.7113\n",
      "Epoch 17: val_loss improved from 0.11010 to 0.10924, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0511 - precision_5: 0.9150 - recall_5: 0.7118 - val_loss: 0.1092 - val_precision_5: 0.7977 - val_recall_5: 0.4346\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0473 - precision_5: 0.9193 - recall_5: 0.7409\n",
      "Epoch 18: val_loss improved from 0.10924 to 0.10848, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0472 - precision_5: 0.9197 - recall_5: 0.7412 - val_loss: 0.1085 - val_precision_5: 0.8033 - val_recall_5: 0.4568\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0453 - precision_5: 0.9248 - recall_5: 0.7571\n",
      "Epoch 19: val_loss improved from 0.10848 to 0.10693, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0452 - precision_5: 0.9248 - recall_5: 0.7572 - val_loss: 0.1069 - val_precision_5: 0.8124 - val_recall_5: 0.4688\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0426 - precision_5: 0.9226 - recall_5: 0.7751\n",
      "Epoch 20: val_loss improved from 0.10693 to 0.10663, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0425 - precision_5: 0.9231 - recall_5: 0.7753 - val_loss: 0.1066 - val_precision_5: 0.8134 - val_recall_5: 0.4848\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0394 - precision_5: 0.9323 - recall_5: 0.7960\n",
      "Epoch 21: val_loss did not improve from 0.10663\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0393 - precision_5: 0.9325 - recall_5: 0.7962 - val_loss: 0.1067 - val_precision_5: 0.8101 - val_recall_5: 0.5019\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0373 - precision_5: 0.9304 - recall_5: 0.8123\n",
      "Epoch 22: val_loss improved from 0.10663 to 0.10645, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0373 - precision_5: 0.9306 - recall_5: 0.8121 - val_loss: 0.1064 - val_precision_5: 0.8168 - val_recall_5: 0.5114\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0360 - precision_5: 0.9417 - recall_5: 0.8147\n",
      "Epoch 23: val_loss improved from 0.10645 to 0.10558, saving model to 62sec_1layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0360 - precision_5: 0.9418 - recall_5: 0.8149 - val_loss: 0.1056 - val_precision_5: 0.8118 - val_recall_5: 0.5332\n",
      "Epoch 24/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0340 - precision_5: 0.9335 - recall_5: 0.8352\n",
      "Epoch 24: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0339 - precision_5: 0.9341 - recall_5: 0.8362 - val_loss: 0.1069 - val_precision_5: 0.8369 - val_recall_5: 0.5221\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0325 - precision_5: 0.9416 - recall_5: 0.8335\n",
      "Epoch 25: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0325 - precision_5: 0.9416 - recall_5: 0.8340 - val_loss: 0.1073 - val_precision_5: 0.8150 - val_recall_5: 0.5301\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0313 - precision_5: 0.9414 - recall_5: 0.8445\n",
      "Epoch 26: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0312 - precision_5: 0.9415 - recall_5: 0.8449 - val_loss: 0.1064 - val_precision_5: 0.8213 - val_recall_5: 0.5394\n",
      "Epoch 27/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0292 - precision_5: 0.9485 - recall_5: 0.8578\n",
      "Epoch 27: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0292 - precision_5: 0.9484 - recall_5: 0.8580 - val_loss: 0.1070 - val_precision_5: 0.8270 - val_recall_5: 0.5419\n",
      "Epoch 28/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0278 - precision_5: 0.9486 - recall_5: 0.8692\n",
      "Epoch 28: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0278 - precision_5: 0.9488 - recall_5: 0.8692 - val_loss: 0.1063 - val_precision_5: 0.8275 - val_recall_5: 0.5526\n",
      "Epoch 29/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0275 - precision_5: 0.9507 - recall_5: 0.8709\n",
      "Epoch 29: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0274 - precision_5: 0.9509 - recall_5: 0.8713 - val_loss: 0.1068 - val_precision_5: 0.8255 - val_recall_5: 0.5624\n",
      "Epoch 30/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0253 - precision_5: 0.9518 - recall_5: 0.8838\n",
      "Epoch 30: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0253 - precision_5: 0.9517 - recall_5: 0.8838 - val_loss: 0.1078 - val_precision_5: 0.8321 - val_recall_5: 0.5629\n",
      "Epoch 31/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0252 - precision_5: 0.9565 - recall_5: 0.8801\n",
      "Epoch 31: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0251 - precision_5: 0.9564 - recall_5: 0.8802 - val_loss: 0.1083 - val_precision_5: 0.8299 - val_recall_5: 0.5646\n",
      "Epoch 32/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0243 - precision_5: 0.9502 - recall_5: 0.8887\n",
      "Epoch 32: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0242 - precision_5: 0.9505 - recall_5: 0.8887 - val_loss: 0.1090 - val_precision_5: 0.8296 - val_recall_5: 0.5747\n",
      "Epoch 33/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0228 - precision_5: 0.9549 - recall_5: 0.9051\n",
      "Epoch 33: val_loss did not improve from 0.10558\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0227 - precision_5: 0.9550 - recall_5: 0.9048 - val_loss: 0.1101 - val_precision_5: 0.8430 - val_recall_5: 0.5705\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0218 - precision_5: 0.9880 - recall_5: 0.8985 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1065 - precision_5: 0.7994 - recall_5: 0.5197 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1204 - precision_5: 0.8001 - recall_5: 0.4873 \n",
      "Epoch 1/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5178 - precision_6: 0.0550 - recall_6: 0.2154\n",
      "Epoch 1: val_loss improved from inf to 0.22155, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.4806 - precision_6: 0.0550 - recall_6: 0.1805 - val_loss: 0.2215 - val_precision_6: 0.2105 - val_recall_6: 6.6302e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2287 - precision_6: 0.2986 - recall_6: 0.0354\n",
      "Epoch 2: val_loss improved from 0.22155 to 0.18804, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2239 - precision_6: 0.3028 - recall_6: 0.0356 - val_loss: 0.1880 - val_precision_6: 0.0000e+00 - val_recall_6: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1773 - precision_6: 0.7221 - recall_6: 0.0057\n",
      "Epoch 3: val_loss improved from 0.18804 to 0.16472, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1732 - precision_6: 0.6859 - recall_6: 0.0144 - val_loss: 0.1647 - val_precision_6: 0.5561 - val_recall_6: 0.0690\n",
      "Epoch 4/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1413 - precision_6: 0.6998 - recall_6: 0.1457\n",
      "Epoch 4: val_loss improved from 0.16472 to 0.15036, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1382 - precision_6: 0.7119 - recall_6: 0.1495 - val_loss: 0.1504 - val_precision_6: 0.6426 - val_recall_6: 0.0840\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1156 - precision_6: 0.8179 - recall_6: 0.2305\n",
      "Epoch 5: val_loss improved from 0.15036 to 0.14060, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1144 - precision_6: 0.8205 - recall_6: 0.2371 - val_loss: 0.1406 - val_precision_6: 0.6695 - val_recall_6: 0.1313\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0961 - precision_6: 0.8839 - recall_6: 0.3486\n",
      "Epoch 6: val_loss improved from 0.14060 to 0.13122, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0952 - precision_6: 0.8835 - recall_6: 0.3557 - val_loss: 0.1312 - val_precision_6: 0.7056 - val_recall_6: 0.2284\n",
      "Epoch 7/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0802 - precision_6: 0.9064 - recall_6: 0.4913\n",
      "Epoch 7: val_loss improved from 0.13122 to 0.12316, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0789 - precision_6: 0.9083 - recall_6: 0.4949 - val_loss: 0.1232 - val_precision_6: 0.7361 - val_recall_6: 0.3325\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0670 - precision_6: 0.9124 - recall_6: 0.6244\n",
      "Epoch 8: val_loss improved from 0.12316 to 0.11662, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0658 - precision_6: 0.9169 - recall_6: 0.6209 - val_loss: 0.1166 - val_precision_6: 0.7656 - val_recall_6: 0.3741\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0558 - precision_6: 0.9412 - recall_6: 0.6957\n",
      "Epoch 9: val_loss improved from 0.11662 to 0.11339, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0549 - precision_6: 0.9414 - recall_6: 0.6972 - val_loss: 0.1134 - val_precision_6: 0.7927 - val_recall_6: 0.3885\n",
      "Epoch 10/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0471 - precision_6: 0.9548 - recall_6: 0.7372\n",
      "Epoch 10: val_loss improved from 0.11339 to 0.10839, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0463 - precision_6: 0.9544 - recall_6: 0.7432 - val_loss: 0.1084 - val_precision_6: 0.7931 - val_recall_6: 0.4595\n",
      "Epoch 11/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0408 - precision_6: 0.9637 - recall_6: 0.7852\n",
      "Epoch 11: val_loss improved from 0.10839 to 0.10607, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0401 - precision_6: 0.9639 - recall_6: 0.7878 - val_loss: 0.1061 - val_precision_6: 0.8008 - val_recall_6: 0.5125\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0345 - precision_6: 0.9592 - recall_6: 0.8485\n",
      "Epoch 12: val_loss improved from 0.10607 to 0.10465, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0340 - precision_6: 0.9612 - recall_6: 0.8465 - val_loss: 0.1046 - val_precision_6: 0.8167 - val_recall_6: 0.5288\n",
      "Epoch 13/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0305 - precision_6: 0.9664 - recall_6: 0.8717\n",
      "Epoch 13: val_loss did not improve from 0.10465\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0299 - precision_6: 0.9672 - recall_6: 0.8719 - val_loss: 0.1052 - val_precision_6: 0.8235 - val_recall_6: 0.5304\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0267 - precision_6: 0.9746 - recall_6: 0.8848\n",
      "Epoch 14: val_loss improved from 0.10465 to 0.10443, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0262 - precision_6: 0.9742 - recall_6: 0.8873 - val_loss: 0.1044 - val_precision_6: 0.8149 - val_recall_6: 0.5604\n",
      "Epoch 15/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0232 - precision_6: 0.9780 - recall_6: 0.9105\n",
      "Epoch 15: val_loss improved from 0.10443 to 0.10420, saving model to 62sec_1layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0229 - precision_6: 0.9782 - recall_6: 0.9096 - val_loss: 0.1042 - val_precision_6: 0.8071 - val_recall_6: 0.5848\n",
      "Epoch 16/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0211 - precision_6: 0.9750 - recall_6: 0.9267\n",
      "Epoch 16: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0208 - precision_6: 0.9757 - recall_6: 0.9246 - val_loss: 0.1050 - val_precision_6: 0.8207 - val_recall_6: 0.5866\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0188 - precision_6: 0.9792 - recall_6: 0.9379\n",
      "Epoch 17: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0186 - precision_6: 0.9790 - recall_6: 0.9379 - val_loss: 0.1073 - val_precision_6: 0.8276 - val_recall_6: 0.5833\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0168 - precision_6: 0.9802 - recall_6: 0.9417\n",
      "Epoch 18: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0166 - precision_6: 0.9803 - recall_6: 0.9416 - val_loss: 0.1071 - val_precision_6: 0.8095 - val_recall_6: 0.6030\n",
      "Epoch 19/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0157 - precision_6: 0.9802 - recall_6: 0.9558\n",
      "Epoch 19: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0154 - precision_6: 0.9809 - recall_6: 0.9555 - val_loss: 0.1099 - val_precision_6: 0.8221 - val_recall_6: 0.5936\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0144 - precision_6: 0.9819 - recall_6: 0.9545\n",
      "Epoch 20: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0142 - precision_6: 0.9817 - recall_6: 0.9549 - val_loss: 0.1097 - val_precision_6: 0.8193 - val_recall_6: 0.6082\n",
      "Epoch 21/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0134 - precision_6: 0.9826 - recall_6: 0.9618\n",
      "Epoch 21: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0131 - precision_6: 0.9834 - recall_6: 0.9617 - val_loss: 0.1103 - val_precision_6: 0.8164 - val_recall_6: 0.6072\n",
      "Epoch 22/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0120 - precision_6: 0.9832 - recall_6: 0.9684\n",
      "Epoch 22: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0118 - precision_6: 0.9834 - recall_6: 0.9679 - val_loss: 0.1143 - val_precision_6: 0.8206 - val_recall_6: 0.6118\n",
      "Epoch 23/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0115 - precision_6: 0.9825 - recall_6: 0.9690\n",
      "Epoch 23: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0113 - precision_6: 0.9826 - recall_6: 0.9690 - val_loss: 0.1135 - val_precision_6: 0.8202 - val_recall_6: 0.6108\n",
      "Epoch 24/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0108 - precision_6: 0.9842 - recall_6: 0.9702\n",
      "Epoch 24: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0106 - precision_6: 0.9845 - recall_6: 0.9701 - val_loss: 0.1160 - val_precision_6: 0.8194 - val_recall_6: 0.6136\n",
      "Epoch 25/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0100 - precision_6: 0.9845 - recall_6: 0.9735\n",
      "Epoch 25: val_loss did not improve from 0.10420\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0098 - precision_6: 0.9847 - recall_6: 0.9734 - val_loss: 0.1173 - val_precision_6: 0.8203 - val_recall_6: 0.6068\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0156 - precision_6: 0.9915 - recall_6: 0.9502 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1048 - precision_6: 0.7964 - recall_6: 0.5753 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1210 - precision_6: 0.8053 - recall_6: 0.5244 \n",
      "Epoch 1/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5385 - precision_7: 0.0535 - recall_7: 0.2327\n",
      "Epoch 1: val_loss improved from inf to 0.22360, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.4885 - precision_7: 0.0536 - recall_7: 0.1857 - val_loss: 0.2236 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2322 - precision_7: 0.2974 - recall_7: 0.0383\n",
      "Epoch 2: val_loss improved from 0.22360 to 0.18851, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2257 - precision_7: 0.3043 - recall_7: 0.0419 - val_loss: 0.1885 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1809 - precision_7: 0.6764 - recall_7: 0.0068\n",
      "Epoch 3: val_loss improved from 0.18851 to 0.16613, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1768 - precision_7: 0.6559 - recall_7: 0.0128 - val_loss: 0.1661 - val_precision_7: 0.6000 - val_recall_7: 0.0527\n",
      "Epoch 4/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1454 - precision_7: 0.6562 - recall_7: 0.1331\n",
      "Epoch 4: val_loss improved from 0.16613 to 0.15201, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1424 - precision_7: 0.6642 - recall_7: 0.1371 - val_loss: 0.1520 - val_precision_7: 0.6458 - val_recall_7: 0.0650\n",
      "Epoch 5/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1221 - precision_7: 0.7797 - recall_7: 0.1919\n",
      "Epoch 5: val_loss improved from 0.15201 to 0.14195, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1197 - precision_7: 0.7825 - recall_7: 0.2046 - val_loss: 0.1419 - val_precision_7: 0.6714 - val_recall_7: 0.1165\n",
      "Epoch 6/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1028 - precision_7: 0.8514 - recall_7: 0.3099\n",
      "Epoch 6: val_loss improved from 0.14195 to 0.13283, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1008 - precision_7: 0.8530 - recall_7: 0.3196 - val_loss: 0.1328 - val_precision_7: 0.7093 - val_recall_7: 0.2030\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0857 - precision_7: 0.8850 - recall_7: 0.4459\n",
      "Epoch 7: val_loss improved from 0.13283 to 0.12509, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0855 - precision_7: 0.8855 - recall_7: 0.4466 - val_loss: 0.1251 - val_precision_7: 0.7336 - val_recall_7: 0.2684\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0737 - precision_7: 0.9052 - recall_7: 0.5518\n",
      "Epoch 8: val_loss improved from 0.12509 to 0.11910, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0723 - precision_7: 0.9081 - recall_7: 0.5554 - val_loss: 0.1191 - val_precision_7: 0.7760 - val_recall_7: 0.3239\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0618 - precision_7: 0.9248 - recall_7: 0.6403\n",
      "Epoch 9: val_loss improved from 0.11910 to 0.11370, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0609 - precision_7: 0.9264 - recall_7: 0.6428 - val_loss: 0.1137 - val_precision_7: 0.7872 - val_recall_7: 0.3827\n",
      "Epoch 10/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0531 - precision_7: 0.9388 - recall_7: 0.7039\n",
      "Epoch 10: val_loss improved from 0.11370 to 0.10968, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0522 - precision_7: 0.9396 - recall_7: 0.7070 - val_loss: 0.1097 - val_precision_7: 0.7983 - val_recall_7: 0.4245\n",
      "Epoch 11/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0466 - precision_7: 0.9497 - recall_7: 0.7519\n",
      "Epoch 11: val_loss improved from 0.10968 to 0.10610, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0457 - precision_7: 0.9502 - recall_7: 0.7549 - val_loss: 0.1061 - val_precision_7: 0.8110 - val_recall_7: 0.4636\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0397 - precision_7: 0.9522 - recall_7: 0.7994\n",
      "Epoch 12: val_loss improved from 0.10610 to 0.10464, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0396 - precision_7: 0.9524 - recall_7: 0.7998 - val_loss: 0.1046 - val_precision_7: 0.8101 - val_recall_7: 0.4913\n",
      "Epoch 13/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0346 - precision_7: 0.9606 - recall_7: 0.8300\n",
      "Epoch 13: val_loss improved from 0.10464 to 0.10371, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0344 - precision_7: 0.9608 - recall_7: 0.8307 - val_loss: 0.1037 - val_precision_7: 0.8069 - val_recall_7: 0.5216\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0315 - precision_7: 0.9600 - recall_7: 0.8538\n",
      "Epoch 14: val_loss improved from 0.10371 to 0.10196, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0309 - precision_7: 0.9605 - recall_7: 0.8557 - val_loss: 0.1020 - val_precision_7: 0.8164 - val_recall_7: 0.5336\n",
      "Epoch 15/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0279 - precision_7: 0.9678 - recall_7: 0.8783\n",
      "Epoch 15: val_loss improved from 0.10196 to 0.10196, saving model to 62sec_1layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0274 - precision_7: 0.9682 - recall_7: 0.8785 - val_loss: 0.1020 - val_precision_7: 0.8088 - val_recall_7: 0.5518\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0248 - precision_7: 0.9689 - recall_7: 0.8979\n",
      "Epoch 16: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0247 - precision_7: 0.9690 - recall_7: 0.8981 - val_loss: 0.1025 - val_precision_7: 0.8254 - val_recall_7: 0.5609\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0229 - precision_7: 0.9699 - recall_7: 0.9083\n",
      "Epoch 17: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0225 - precision_7: 0.9705 - recall_7: 0.9095 - val_loss: 0.1037 - val_precision_7: 0.8181 - val_recall_7: 0.5733\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0205 - precision_7: 0.9752 - recall_7: 0.9212\n",
      "Epoch 18: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0202 - precision_7: 0.9753 - recall_7: 0.9209 - val_loss: 0.1037 - val_precision_7: 0.8172 - val_recall_7: 0.5874\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0188 - precision_7: 0.9735 - recall_7: 0.9334\n",
      "Epoch 19: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0188 - precision_7: 0.9737 - recall_7: 0.9333 - val_loss: 0.1051 - val_precision_7: 0.8198 - val_recall_7: 0.5851\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - precision_7: 0.9789 - recall_7: 0.9417\n",
      "Epoch 20: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0167 - precision_7: 0.9787 - recall_7: 0.9423 - val_loss: 0.1063 - val_precision_7: 0.8221 - val_recall_7: 0.5859\n",
      "Epoch 21/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0161 - precision_7: 0.9793 - recall_7: 0.9416\n",
      "Epoch 21: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0158 - precision_7: 0.9793 - recall_7: 0.9421 - val_loss: 0.1065 - val_precision_7: 0.8188 - val_recall_7: 0.5919\n",
      "Epoch 22/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0152 - precision_7: 0.9789 - recall_7: 0.9529\n",
      "Epoch 22: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0149 - precision_7: 0.9791 - recall_7: 0.9523 - val_loss: 0.1096 - val_precision_7: 0.8297 - val_recall_7: 0.5873\n",
      "Epoch 23/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0138 - precision_7: 0.9826 - recall_7: 0.9542\n",
      "Epoch 23: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - precision_7: 0.9819 - recall_7: 0.9544 - val_loss: 0.1094 - val_precision_7: 0.8221 - val_recall_7: 0.5974\n",
      "Epoch 24/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0131 - precision_7: 0.9798 - recall_7: 0.9592\n",
      "Epoch 24: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0129 - precision_7: 0.9799 - recall_7: 0.9589 - val_loss: 0.1104 - val_precision_7: 0.8172 - val_recall_7: 0.5987\n",
      "Epoch 25/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0124 - precision_7: 0.9803 - recall_7: 0.9647\n",
      "Epoch 25: val_loss did not improve from 0.10196\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0121 - precision_7: 0.9806 - recall_7: 0.9649 - val_loss: 0.1121 - val_precision_7: 0.8241 - val_recall_7: 0.6017\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0177 - precision_7: 0.9941 - recall_7: 0.9287 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1029 - precision_7: 0.7995 - recall_7: 0.5397 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1181 - precision_7: 0.8237 - recall_7: 0.5038 \n",
      "Epoch 1/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5434 - precision_8: 0.0530 - recall_8: 0.2406\n",
      "Epoch 1: val_loss improved from inf to 0.22938, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4930 - precision_8: 0.0531 - recall_8: 0.1930 - val_loss: 0.2294 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2375 - precision_8: 0.2658 - recall_8: 0.0359\n",
      "Epoch 2: val_loss improved from 0.22938 to 0.18935, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2309 - precision_8: 0.2694 - recall_8: 0.0418 - val_loss: 0.1893 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1833 - precision_8: 0.5368 - recall_8: 0.0142\n",
      "Epoch 3: val_loss improved from 0.18935 to 0.16797, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1794 - precision_8: 0.5502 - recall_8: 0.0167 - val_loss: 0.1680 - val_precision_8: 0.6833 - val_recall_8: 0.0250\n",
      "Epoch 4/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1504 - precision_8: 0.6553 - recall_8: 0.1166\n",
      "Epoch 4: val_loss improved from 0.16797 to 0.15371, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1473 - precision_8: 0.6563 - recall_8: 0.1236 - val_loss: 0.1537 - val_precision_8: 0.6336 - val_recall_8: 0.0519\n",
      "Epoch 5/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1266 - precision_8: 0.7538 - recall_8: 0.1710\n",
      "Epoch 5: val_loss improved from 0.15371 to 0.14408, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1244 - precision_8: 0.7587 - recall_8: 0.1819 - val_loss: 0.1441 - val_precision_8: 0.6515 - val_recall_8: 0.1023\n",
      "Epoch 6/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1083 - precision_8: 0.8191 - recall_8: 0.2777\n",
      "Epoch 6: val_loss improved from 0.14408 to 0.13542, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1063 - precision_8: 0.8215 - recall_8: 0.2873 - val_loss: 0.1354 - val_precision_8: 0.6959 - val_recall_8: 0.1696\n",
      "Epoch 7/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0927 - precision_8: 0.8592 - recall_8: 0.3967\n",
      "Epoch 7: val_loss improved from 0.13542 to 0.12816, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0914 - precision_8: 0.8622 - recall_8: 0.4007 - val_loss: 0.1282 - val_precision_8: 0.7239 - val_recall_8: 0.2277\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0804 - precision_8: 0.8789 - recall_8: 0.4877\n",
      "Epoch 8: val_loss improved from 0.12816 to 0.12149, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0790 - precision_8: 0.8820 - recall_8: 0.4931 - val_loss: 0.1215 - val_precision_8: 0.7665 - val_recall_8: 0.2977\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0703 - precision_8: 0.9026 - recall_8: 0.5718\n",
      "Epoch 9: val_loss improved from 0.12149 to 0.11595, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0691 - precision_8: 0.9038 - recall_8: 0.5758 - val_loss: 0.1159 - val_precision_8: 0.7842 - val_recall_8: 0.3487\n",
      "Epoch 10/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0608 - precision_8: 0.9128 - recall_8: 0.6462\n",
      "Epoch 10: val_loss improved from 0.11595 to 0.11186, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0599 - precision_8: 0.9133 - recall_8: 0.6488 - val_loss: 0.1119 - val_precision_8: 0.7924 - val_recall_8: 0.3897\n",
      "Epoch 11/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0532 - precision_8: 0.9353 - recall_8: 0.6913\n",
      "Epoch 11: val_loss improved from 0.11186 to 0.10832, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0524 - precision_8: 0.9359 - recall_8: 0.6940 - val_loss: 0.1083 - val_precision_8: 0.8002 - val_recall_8: 0.4296\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0467 - precision_8: 0.9398 - recall_8: 0.7458\n",
      "Epoch 12: val_loss improved from 0.10832 to 0.10707, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0460 - precision_8: 0.9393 - recall_8: 0.7485 - val_loss: 0.1071 - val_precision_8: 0.8165 - val_recall_8: 0.4500\n",
      "Epoch 13/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0420 - precision_8: 0.9477 - recall_8: 0.7697\n",
      "Epoch 13: val_loss improved from 0.10707 to 0.10431, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0414 - precision_8: 0.9482 - recall_8: 0.7734 - val_loss: 0.1043 - val_precision_8: 0.8151 - val_recall_8: 0.4903\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0377 - precision_8: 0.9412 - recall_8: 0.8110\n",
      "Epoch 14: val_loss improved from 0.10431 to 0.10376, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0371 - precision_8: 0.9441 - recall_8: 0.8117 - val_loss: 0.1038 - val_precision_8: 0.8275 - val_recall_8: 0.5065\n",
      "Epoch 15/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0330 - precision_8: 0.9571 - recall_8: 0.8428\n",
      "Epoch 15: val_loss improved from 0.10376 to 0.10325, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0325 - precision_8: 0.9574 - recall_8: 0.8432 - val_loss: 0.1033 - val_precision_8: 0.8139 - val_recall_8: 0.5298\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0292 - precision_8: 0.9580 - recall_8: 0.8616\n",
      "Epoch 16: val_loss improved from 0.10325 to 0.10309, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0292 - precision_8: 0.9580 - recall_8: 0.8617 - val_loss: 0.1031 - val_precision_8: 0.8249 - val_recall_8: 0.5389\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0270 - precision_8: 0.9649 - recall_8: 0.8802\n",
      "Epoch 17: val_loss improved from 0.10309 to 0.10198, saving model to 62sec_1layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0268 - precision_8: 0.9645 - recall_8: 0.8790 - val_loss: 0.1020 - val_precision_8: 0.8256 - val_recall_8: 0.5627\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0249 - precision_8: 0.9628 - recall_8: 0.8924\n",
      "Epoch 18: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0247 - precision_8: 0.9628 - recall_8: 0.8917 - val_loss: 0.1028 - val_precision_8: 0.8276 - val_recall_8: 0.5699\n",
      "Epoch 19/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0240 - precision_8: 0.9631 - recall_8: 0.8991\n",
      "Epoch 19: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0236 - precision_8: 0.9638 - recall_8: 0.8989 - val_loss: 0.1040 - val_precision_8: 0.8333 - val_recall_8: 0.5800\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0217 - precision_8: 0.9693 - recall_8: 0.9061\n",
      "Epoch 20: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0215 - precision_8: 0.9690 - recall_8: 0.9072 - val_loss: 0.1032 - val_precision_8: 0.8297 - val_recall_8: 0.5871\n",
      "Epoch 21/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0201 - precision_8: 0.9670 - recall_8: 0.9194\n",
      "Epoch 21: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0199 - precision_8: 0.9677 - recall_8: 0.9194 - val_loss: 0.1046 - val_precision_8: 0.8350 - val_recall_8: 0.5821\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0184 - precision_8: 0.9680 - recall_8: 0.9278\n",
      "Epoch 22: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0184 - precision_8: 0.9681 - recall_8: 0.9277 - val_loss: 0.1053 - val_precision_8: 0.8307 - val_recall_8: 0.5936\n",
      "Epoch 23/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - precision_8: 0.9681 - recall_8: 0.9405\n",
      "Epoch 23: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0172 - precision_8: 0.9688 - recall_8: 0.9391 - val_loss: 0.1067 - val_precision_8: 0.8322 - val_recall_8: 0.5926\n",
      "Epoch 24/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0167 - precision_8: 0.9753 - recall_8: 0.9367\n",
      "Epoch 24: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0165 - precision_8: 0.9753 - recall_8: 0.9373 - val_loss: 0.1073 - val_precision_8: 0.8350 - val_recall_8: 0.5964\n",
      "Epoch 25/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0153 - precision_8: 0.9749 - recall_8: 0.9432\n",
      "Epoch 25: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0152 - precision_8: 0.9747 - recall_8: 0.9430 - val_loss: 0.1079 - val_precision_8: 0.8348 - val_recall_8: 0.5974\n",
      "Epoch 26/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0148 - precision_8: 0.9739 - recall_8: 0.9492\n",
      "Epoch 26: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0146 - precision_8: 0.9741 - recall_8: 0.9480 - val_loss: 0.1086 - val_precision_8: 0.8352 - val_recall_8: 0.6005\n",
      "Epoch 27/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0134 - precision_8: 0.9781 - recall_8: 0.9533\n",
      "Epoch 27: val_loss did not improve from 0.10198\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0134 - precision_8: 0.9774 - recall_8: 0.9528 - val_loss: 0.1100 - val_precision_8: 0.8368 - val_recall_8: 0.5942\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0167 - precision_8: 0.9934 - recall_8: 0.9300 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1028 - precision_8: 0.8152 - recall_8: 0.5521 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1166 - precision_8: 0.8244 - recall_8: 0.5061 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4649 - precision_9: 0.0519 - recall_9: 0.1549\n",
      "Epoch 1: val_loss improved from inf to 0.20833, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4407 - precision_9: 0.0528 - recall_9: 0.1364 - val_loss: 0.2083 - val_precision_9: 0.4028 - val_recall_9: 0.0670\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2060 - precision_9: 0.4215 - recall_9: 0.0940\n",
      "Epoch 2: val_loss improved from 0.20833 to 0.17599, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2026 - precision_9: 0.4257 - recall_9: 0.0864 - val_loss: 0.1760 - val_precision_9: 1.0000 - val_recall_9: 9.9453e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1534 - precision_9: 0.7726 - recall_9: 0.0727\n",
      "Epoch 3: val_loss improved from 0.17599 to 0.14922, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1513 - precision_9: 0.7463 - recall_9: 0.0919 - val_loss: 0.1492 - val_precision_9: 0.6061 - val_recall_9: 0.1056\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1159 - precision_9: 0.8363 - recall_9: 0.2136\n",
      "Epoch 4: val_loss improved from 0.14922 to 0.13673, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1146 - precision_9: 0.8362 - recall_9: 0.2230 - val_loss: 0.1367 - val_precision_9: 0.6447 - val_recall_9: 0.2367\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0896 - precision_9: 0.8822 - recall_9: 0.4503\n",
      "Epoch 5: val_loss improved from 0.13673 to 0.12472, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0887 - precision_9: 0.8861 - recall_9: 0.4468 - val_loss: 0.1247 - val_precision_9: 0.7026 - val_recall_9: 0.2859\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0692 - precision_9: 0.9132 - recall_9: 0.6114\n",
      "Epoch 6: val_loss improved from 0.12472 to 0.11705, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0686 - precision_9: 0.9151 - recall_9: 0.6119 - val_loss: 0.1170 - val_precision_9: 0.7683 - val_recall_9: 0.3050\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0540 - precision_9: 0.9533 - recall_9: 0.6748\n",
      "Epoch 7: val_loss improved from 0.11705 to 0.10851, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0535 - precision_9: 0.9518 - recall_9: 0.6826 - val_loss: 0.1085 - val_precision_9: 0.7856 - val_recall_9: 0.4160\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0425 - precision_9: 0.9686 - recall_9: 0.7623\n",
      "Epoch 8: val_loss improved from 0.10851 to 0.10276, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0421 - precision_9: 0.9684 - recall_9: 0.7652 - val_loss: 0.1028 - val_precision_9: 0.7770 - val_recall_9: 0.5208\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0335 - precision_9: 0.9652 - recall_9: 0.8583\n",
      "Epoch 9: val_loss improved from 0.10276 to 0.10091, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0333 - precision_9: 0.9667 - recall_9: 0.8564 - val_loss: 0.1009 - val_precision_9: 0.8012 - val_recall_9: 0.5432\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0269 - precision_9: 0.9743 - recall_9: 0.8989\n",
      "Epoch 10: val_loss did not improve from 0.10091\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0267 - precision_9: 0.9746 - recall_9: 0.8994 - val_loss: 0.1020 - val_precision_9: 0.8234 - val_recall_9: 0.5433\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0221 - precision_9: 0.9834 - recall_9: 0.9098\n",
      "Epoch 11: val_loss improved from 0.10091 to 0.10068, saving model to 62sec_1layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0219 - precision_9: 0.9830 - recall_9: 0.9120 - val_loss: 0.1007 - val_precision_9: 0.8156 - val_recall_9: 0.5820\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0187 - precision_9: 0.9849 - recall_9: 0.9376\n",
      "Epoch 12: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0185 - precision_9: 0.9849 - recall_9: 0.9377 - val_loss: 0.1014 - val_precision_9: 0.8071 - val_recall_9: 0.6014\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0155 - precision_9: 0.9817 - recall_9: 0.9581\n",
      "Epoch 13: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0154 - precision_9: 0.9822 - recall_9: 0.9578 - val_loss: 0.1045 - val_precision_9: 0.8248 - val_recall_9: 0.5869\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0134 - precision_9: 0.9865 - recall_9: 0.9644\n",
      "Epoch 14: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0134 - precision_9: 0.9864 - recall_9: 0.9645 - val_loss: 0.1055 - val_precision_9: 0.8193 - val_recall_9: 0.5980\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0116 - precision_9: 0.9879 - recall_9: 0.9698\n",
      "Epoch 15: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0115 - precision_9: 0.9879 - recall_9: 0.9695 - val_loss: 0.1068 - val_precision_9: 0.8128 - val_recall_9: 0.6123\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0108 - precision_9: 0.9846 - recall_9: 0.9761\n",
      "Epoch 16: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0107 - precision_9: 0.9848 - recall_9: 0.9760 - val_loss: 0.1101 - val_precision_9: 0.8269 - val_recall_9: 0.6017\n",
      "Epoch 17/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0096 - precision_9: 0.9857 - recall_9: 0.9764\n",
      "Epoch 17: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0095 - precision_9: 0.9857 - recall_9: 0.9766 - val_loss: 0.1101 - val_precision_9: 0.8178 - val_recall_9: 0.6055\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0085 - precision_9: 0.9871 - recall_9: 0.9811\n",
      "Epoch 18: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0085 - precision_9: 0.9873 - recall_9: 0.9807 - val_loss: 0.1130 - val_precision_9: 0.8191 - val_recall_9: 0.6048\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0078 - precision_9: 0.9856 - recall_9: 0.9827\n",
      "Epoch 19: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - precision_9: 0.9858 - recall_9: 0.9826 - val_loss: 0.1153 - val_precision_9: 0.8219 - val_recall_9: 0.6022\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0075 - precision_9: 0.9857 - recall_9: 0.9833\n",
      "Epoch 20: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - precision_9: 0.9860 - recall_9: 0.9830 - val_loss: 0.1173 - val_precision_9: 0.8159 - val_recall_9: 0.6091\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0063 - precision_9: 0.9900 - recall_9: 0.9861\n",
      "Epoch 21: val_loss did not improve from 0.10068\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - precision_9: 0.9899 - recall_9: 0.9858 - val_loss: 0.1176 - val_precision_9: 0.8201 - val_recall_9: 0.6073\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0146 - precision_9: 0.9935 - recall_9: 0.9554\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1014 - precision_9: 0.8063 - recall_9: 0.5720 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1156 - precision_9: 0.8202 - recall_9: 0.5349 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4651 - precision_10: 0.0555 - recall_10: 0.1690\n",
      "Epoch 1: val_loss improved from inf to 0.20640, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4410 - precision_10: 0.0562 - recall_10: 0.1486 - val_loss: 0.2064 - val_precision_10: 0.4349 - val_recall_10: 0.0520\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2084 - precision_10: 0.3808 - recall_10: 0.0923\n",
      "Epoch 2: val_loss improved from 0.20640 to 0.17696, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2051 - precision_10: 0.3862 - recall_10: 0.0859 - val_loss: 0.1770 - val_precision_10: 1.0000 - val_recall_10: 1.6576e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1569 - precision_10: 0.7498 - recall_10: 0.0553\n",
      "Epoch 3: val_loss improved from 0.17696 to 0.15019, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1547 - precision_10: 0.7263 - recall_10: 0.0724 - val_loss: 0.1502 - val_precision_10: 0.6083 - val_recall_10: 0.1192\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1182 - precision_10: 0.8081 - recall_10: 0.2172\n",
      "Epoch 4: val_loss improved from 0.15019 to 0.13800, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1170 - precision_10: 0.8111 - recall_10: 0.2233 - val_loss: 0.1380 - val_precision_10: 0.6610 - val_recall_10: 0.2120\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0933 - precision_10: 0.8706 - recall_10: 0.4126\n",
      "Epoch 5: val_loss improved from 0.13800 to 0.12682, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0924 - precision_10: 0.8744 - recall_10: 0.4114 - val_loss: 0.1268 - val_precision_10: 0.7094 - val_recall_10: 0.2476\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0734 - precision_10: 0.9061 - recall_10: 0.5542\n",
      "Epoch 6: val_loss improved from 0.12682 to 0.11807, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0727 - precision_10: 0.9073 - recall_10: 0.5587 - val_loss: 0.1181 - val_precision_10: 0.7727 - val_recall_10: 0.3025\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0581 - precision_10: 0.9497 - recall_10: 0.6341\n",
      "Epoch 7: val_loss improved from 0.11807 to 0.10981, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0576 - precision_10: 0.9484 - recall_10: 0.6425 - val_loss: 0.1098 - val_precision_10: 0.7853 - val_recall_10: 0.4141\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0460 - precision_10: 0.9544 - recall_10: 0.7395\n",
      "Epoch 8: val_loss improved from 0.10981 to 0.10400, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0456 - precision_10: 0.9553 - recall_10: 0.7413 - val_loss: 0.1040 - val_precision_10: 0.7818 - val_recall_10: 0.5006\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0368 - precision_10: 0.9557 - recall_10: 0.8350\n",
      "Epoch 9: val_loss improved from 0.10400 to 0.10281, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0365 - precision_10: 0.9576 - recall_10: 0.8330 - val_loss: 0.1028 - val_precision_10: 0.8029 - val_recall_10: 0.5198\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0303 - precision_10: 0.9693 - recall_10: 0.8664\n",
      "Epoch 10: val_loss improved from 0.10281 to 0.10229, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0300 - precision_10: 0.9693 - recall_10: 0.8681 - val_loss: 0.1023 - val_precision_10: 0.8291 - val_recall_10: 0.5195\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0253 - precision_10: 0.9797 - recall_10: 0.8835\n",
      "Epoch 11: val_loss improved from 0.10229 to 0.10001, saving model to 62sec_1layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0251 - precision_10: 0.9794 - recall_10: 0.8860 - val_loss: 0.1000 - val_precision_10: 0.8140 - val_recall_10: 0.5831\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0215 - precision_10: 0.9750 - recall_10: 0.9217\n",
      "Epoch 12: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0214 - precision_10: 0.9759 - recall_10: 0.9208 - val_loss: 0.1007 - val_precision_10: 0.8161 - val_recall_10: 0.5967\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0183 - precision_10: 0.9760 - recall_10: 0.9448\n",
      "Epoch 13: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0182 - precision_10: 0.9768 - recall_10: 0.9444 - val_loss: 0.1035 - val_precision_10: 0.8289 - val_recall_10: 0.5848\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0157 - precision_10: 0.9845 - recall_10: 0.9452\n",
      "Epoch 14: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0156 - precision_10: 0.9840 - recall_10: 0.9463 - val_loss: 0.1039 - val_precision_10: 0.8217 - val_recall_10: 0.5982\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0134 - precision_10: 0.9850 - recall_10: 0.9602\n",
      "Epoch 15: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0134 - precision_10: 0.9853 - recall_10: 0.9598 - val_loss: 0.1046 - val_precision_10: 0.8196 - val_recall_10: 0.6053\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0122 - precision_10: 0.9834 - recall_10: 0.9717\n",
      "Epoch 16: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0121 - precision_10: 0.9838 - recall_10: 0.9711 - val_loss: 0.1077 - val_precision_10: 0.8276 - val_recall_10: 0.6000\n",
      "Epoch 17/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0109 - precision_10: 0.9860 - recall_10: 0.9711\n",
      "Epoch 17: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0108 - precision_10: 0.9860 - recall_10: 0.9712 - val_loss: 0.1087 - val_precision_10: 0.8249 - val_recall_10: 0.6052\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0101 - precision_10: 0.9867 - recall_10: 0.9721\n",
      "Epoch 18: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0100 - precision_10: 0.9868 - recall_10: 0.9721 - val_loss: 0.1104 - val_precision_10: 0.8219 - val_recall_10: 0.6052\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0094 - precision_10: 0.9837 - recall_10: 0.9788\n",
      "Epoch 19: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0094 - precision_10: 0.9840 - recall_10: 0.9786 - val_loss: 0.1127 - val_precision_10: 0.8310 - val_recall_10: 0.6030\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0082 - precision_10: 0.9866 - recall_10: 0.9788\n",
      "Epoch 20: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - precision_10: 0.9869 - recall_10: 0.9790 - val_loss: 0.1134 - val_precision_10: 0.8248 - val_recall_10: 0.6085\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0077 - precision_10: 0.9879 - recall_10: 0.9808\n",
      "Epoch 21: val_loss did not improve from 0.10001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0077 - precision_10: 0.9879 - recall_10: 0.9807 - val_loss: 0.1161 - val_precision_10: 0.8280 - val_recall_10: 0.6063\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0162 - precision_10: 0.9913 - recall_10: 0.9483\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1011 - precision_10: 0.8050 - recall_10: 0.5725 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1127 - precision_10: 0.8133 - recall_10: 0.5329 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4718 - precision_11: 0.0535 - recall_11: 0.1715\n",
      "Epoch 1: val_loss improved from inf to 0.20492, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4472 - precision_11: 0.0540 - recall_11: 0.1508 - val_loss: 0.2049 - val_precision_11: 0.4096 - val_recall_11: 0.0255\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2100 - precision_11: 0.3541 - recall_11: 0.0918\n",
      "Epoch 2: val_loss improved from 0.20492 to 0.17792, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2069 - precision_11: 0.3588 - recall_11: 0.0868 - val_loss: 0.1779 - val_precision_11: 0.0000e+00 - val_recall_11: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1603 - precision_11: 0.7569 - recall_11: 0.0402\n",
      "Epoch 3: val_loss improved from 0.17792 to 0.15192, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1582 - precision_11: 0.7307 - recall_11: 0.0545 - val_loss: 0.1519 - val_precision_11: 0.5671 - val_recall_11: 0.1253\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1230 - precision_11: 0.7555 - recall_11: 0.2169\n",
      "Epoch 4: val_loss improved from 0.15192 to 0.13893, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1218 - precision_11: 0.7610 - recall_11: 0.2187 - val_loss: 0.1389 - val_precision_11: 0.6413 - val_recall_11: 0.1553\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0985 - precision_11: 0.8579 - recall_11: 0.3672\n",
      "Epoch 5: val_loss improved from 0.13893 to 0.12926, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0976 - precision_11: 0.8597 - recall_11: 0.3689 - val_loss: 0.1293 - val_precision_11: 0.6893 - val_recall_11: 0.1949\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0797 - precision_11: 0.8981 - recall_11: 0.4779\n",
      "Epoch 6: val_loss improved from 0.12926 to 0.12019, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0790 - precision_11: 0.8979 - recall_11: 0.4848 - val_loss: 0.1202 - val_precision_11: 0.7385 - val_recall_11: 0.2776\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0643 - precision_11: 0.9296 - recall_11: 0.5945\n",
      "Epoch 7: val_loss improved from 0.12019 to 0.11245, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0638 - precision_11: 0.9301 - recall_11: 0.5990 - val_loss: 0.1124 - val_precision_11: 0.7600 - val_recall_11: 0.3953\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0522 - precision_11: 0.9381 - recall_11: 0.7118\n",
      "Epoch 8: val_loss improved from 0.11245 to 0.10733, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0518 - precision_11: 0.9394 - recall_11: 0.7113 - val_loss: 0.1073 - val_precision_11: 0.7840 - val_recall_11: 0.4535\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0428 - precision_11: 0.9534 - recall_11: 0.7795\n",
      "Epoch 9: val_loss improved from 0.10733 to 0.10443, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0424 - precision_11: 0.9538 - recall_11: 0.7806 - val_loss: 0.1044 - val_precision_11: 0.8036 - val_recall_11: 0.4707\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0358 - precision_11: 0.9586 - recall_11: 0.8174\n",
      "Epoch 10: val_loss improved from 0.10443 to 0.10154, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0355 - precision_11: 0.9593 - recall_11: 0.8195 - val_loss: 0.1015 - val_precision_11: 0.8047 - val_recall_11: 0.5233\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0293 - precision_11: 0.9695 - recall_11: 0.8655\n",
      "Epoch 11: val_loss improved from 0.10154 to 0.10095, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0291 - precision_11: 0.9697 - recall_11: 0.8655 - val_loss: 0.1010 - val_precision_11: 0.8103 - val_recall_11: 0.5521\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0257 - precision_11: 0.9708 - recall_11: 0.8905\n",
      "Epoch 12: val_loss improved from 0.10095 to 0.10042, saving model to 62sec_1layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0254 - precision_11: 0.9710 - recall_11: 0.8911 - val_loss: 0.1004 - val_precision_11: 0.8131 - val_recall_11: 0.5770\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0212 - precision_11: 0.9754 - recall_11: 0.9195\n",
      "Epoch 13: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0212 - precision_11: 0.9752 - recall_11: 0.9193 - val_loss: 0.1013 - val_precision_11: 0.8163 - val_recall_11: 0.5813\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0187 - precision_11: 0.9793 - recall_11: 0.9280\n",
      "Epoch 14: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0186 - precision_11: 0.9793 - recall_11: 0.9286 - val_loss: 0.1032 - val_precision_11: 0.8082 - val_recall_11: 0.5931\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0172 - precision_11: 0.9770 - recall_11: 0.9397\n",
      "Epoch 15: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0170 - precision_11: 0.9774 - recall_11: 0.9398 - val_loss: 0.1037 - val_precision_11: 0.8131 - val_recall_11: 0.5951\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0146 - precision_11: 0.9833 - recall_11: 0.9558\n",
      "Epoch 16: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0145 - precision_11: 0.9833 - recall_11: 0.9555 - val_loss: 0.1051 - val_precision_11: 0.8200 - val_recall_11: 0.5989\n",
      "Epoch 17/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0136 - precision_11: 0.9806 - recall_11: 0.9544\n",
      "Epoch 17: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0135 - precision_11: 0.9810 - recall_11: 0.9551 - val_loss: 0.1075 - val_precision_11: 0.8147 - val_recall_11: 0.5989\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0120 - precision_11: 0.9816 - recall_11: 0.9656\n",
      "Epoch 18: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0120 - precision_11: 0.9817 - recall_11: 0.9654 - val_loss: 0.1091 - val_precision_11: 0.8120 - val_recall_11: 0.6055\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0108 - precision_11: 0.9840 - recall_11: 0.9716\n",
      "Epoch 19: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0108 - precision_11: 0.9839 - recall_11: 0.9717 - val_loss: 0.1106 - val_precision_11: 0.8276 - val_recall_11: 0.6024\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0101 - precision_11: 0.9843 - recall_11: 0.9697\n",
      "Epoch 20: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0101 - precision_11: 0.9846 - recall_11: 0.9697 - val_loss: 0.1118 - val_precision_11: 0.8147 - val_recall_11: 0.6113\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0095 - precision_11: 0.9864 - recall_11: 0.9732\n",
      "Epoch 21: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0095 - precision_11: 0.9861 - recall_11: 0.9730 - val_loss: 0.1140 - val_precision_11: 0.8204 - val_recall_11: 0.6048\n",
      "Epoch 22/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0089 - precision_11: 0.9866 - recall_11: 0.9755\n",
      "Epoch 22: val_loss did not improve from 0.10042\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0088 - precision_11: 0.9864 - recall_11: 0.9755 - val_loss: 0.1142 - val_precision_11: 0.8144 - val_recall_11: 0.6123\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - precision_11: 0.9934 - recall_11: 0.9474\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1012 - precision_11: 0.8043 - recall_11: 0.5659 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1126 - precision_11: 0.8208 - recall_11: 0.5282 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6015 - precision_12: 0.0542 - recall_12: 0.3083  \n",
      "Epoch 1: val_loss improved from inf to 0.27162, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5750 - precision_12: 0.0544 - recall_12: 0.2785 - val_loss: 0.2716 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2763 - precision_12: 0.1563 - recall_12: 0.0065     \n",
      "Epoch 2: val_loss improved from 0.27162 to 0.21512, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2664 - precision_12: 0.1557 - recall_12: 0.0113 - val_loss: 0.2151 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2150 - precision_12: 0.1862 - recall_12: 0.0137 \n",
      "Epoch 3: val_loss improved from 0.21512 to 0.19406, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2128 - precision_12: 0.1869 - recall_12: 0.0118 - val_loss: 0.1941 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1912 - precision_12: 0.2511 - recall_12: 0.0014 \n",
      "Epoch 4: val_loss improved from 0.19406 to 0.18030, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1898 - precision_12: 0.2562 - recall_12: 0.0015 - val_loss: 0.1803 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1715 - precision_12: 0.4231 - recall_12: 0.0036 \n",
      "Epoch 5: val_loss improved from 0.18030 to 0.16768, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1708 - precision_12: 0.4250 - recall_12: 0.0038 - val_loss: 0.1677 - val_precision_12: 0.0000e+00 - val_recall_12: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1572 - precision_12: 0.4775 - recall_12: 0.0109 \n",
      "Epoch 6: val_loss improved from 0.16768 to 0.16119, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1564 - precision_12: 0.4767 - recall_12: 0.0125 - val_loss: 0.1612 - val_precision_12: 0.5068 - val_recall_12: 0.0123\n",
      "Epoch 7/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1486 - precision_12: 0.4592 - recall_12: 0.0361 \n",
      "Epoch 7: val_loss improved from 0.16119 to 0.15434, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1472 - precision_12: 0.4731 - recall_12: 0.0385 - val_loss: 0.1543 - val_precision_12: 0.5294 - val_recall_12: 0.0373\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1425 - precision_12: 0.4674 - recall_12: 0.0702 \n",
      "Epoch 8: val_loss improved from 0.15434 to 0.14817, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1409 - precision_12: 0.4831 - recall_12: 0.0714 - val_loss: 0.1482 - val_precision_12: 0.5691 - val_recall_12: 0.0348\n",
      "Epoch 9/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1367 - precision_12: 0.5457 - recall_12: 0.0834 \n",
      "Epoch 9: val_loss improved from 0.14817 to 0.14493, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1344 - precision_12: 0.5670 - recall_12: 0.0927 - val_loss: 0.1449 - val_precision_12: 0.5750 - val_recall_12: 0.0496\n",
      "Epoch 10/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1293 - precision_12: 0.6165 - recall_12: 0.1102 \n",
      "Epoch 10: val_loss improved from 0.14493 to 0.14186, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1278 - precision_12: 0.6206 - recall_12: 0.1234 - val_loss: 0.1419 - val_precision_12: 0.5938 - val_recall_12: 0.1086\n",
      "Epoch 11/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1223 - precision_12: 0.6799 - recall_12: 0.1518 \n",
      "Epoch 11: val_loss improved from 0.14186 to 0.14105, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1210 - precision_12: 0.6831 - recall_12: 0.1581 - val_loss: 0.1411 - val_precision_12: 0.5764 - val_recall_12: 0.1838\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1155 - precision_12: 0.6781 - recall_12: 0.2434 \n",
      "Epoch 12: val_loss improved from 0.14105 to 0.13427, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1146 - precision_12: 0.6837 - recall_12: 0.2406 - val_loss: 0.1343 - val_precision_12: 0.6056 - val_recall_12: 0.1820\n",
      "Epoch 13/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1078 - precision_12: 0.7438 - recall_12: 0.2705 \n",
      "Epoch 13: val_loss improved from 0.13427 to 0.13105, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1063 - precision_12: 0.7392 - recall_12: 0.2842 - val_loss: 0.1311 - val_precision_12: 0.6474 - val_recall_12: 0.1856\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1011 - precision_12: 0.7708 - recall_12: 0.3166 \n",
      "Epoch 14: val_loss improved from 0.13105 to 0.12709, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1004 - precision_12: 0.7664 - recall_12: 0.3279 - val_loss: 0.1271 - val_precision_12: 0.6219 - val_recall_12: 0.2364\n",
      "Epoch 15/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0943 - precision_12: 0.7854 - recall_12: 0.3743 \n",
      "Epoch 15: val_loss improved from 0.12709 to 0.12465, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0934 - precision_12: 0.7839 - recall_12: 0.3769 - val_loss: 0.1247 - val_precision_12: 0.6288 - val_recall_12: 0.2990\n",
      "Epoch 16/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0891 - precision_12: 0.7904 - recall_12: 0.4401 \n",
      "Epoch 16: val_loss improved from 0.12465 to 0.12093, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0886 - precision_12: 0.7873 - recall_12: 0.4393 - val_loss: 0.1209 - val_precision_12: 0.6549 - val_recall_12: 0.3055\n",
      "Epoch 17/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0854 - precision_12: 0.8013 - recall_12: 0.4610 \n",
      "Epoch 17: val_loss improved from 0.12093 to 0.11902, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0844 - precision_12: 0.7976 - recall_12: 0.4702 - val_loss: 0.1190 - val_precision_12: 0.6816 - val_recall_12: 0.3378\n",
      "Epoch 18/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0806 - precision_12: 0.8158 - recall_12: 0.4882 \n",
      "Epoch 18: val_loss improved from 0.11902 to 0.11662, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0801 - precision_12: 0.8129 - recall_12: 0.4894 - val_loss: 0.1166 - val_precision_12: 0.6753 - val_recall_12: 0.3875\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0774 - precision_12: 0.8038 - recall_12: 0.5535 \n",
      "Epoch 19: val_loss improved from 0.11662 to 0.11357, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0769 - precision_12: 0.8068 - recall_12: 0.5471 - val_loss: 0.1136 - val_precision_12: 0.6841 - val_recall_12: 0.3784\n",
      "Epoch 20/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0737 - precision_12: 0.8244 - recall_12: 0.5604 \n",
      "Epoch 20: val_loss improved from 0.11357 to 0.11211, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0731 - precision_12: 0.8210 - recall_12: 0.5610 - val_loss: 0.1121 - val_precision_12: 0.6929 - val_recall_12: 0.3971\n",
      "Epoch 21/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0688 - precision_12: 0.8457 - recall_12: 0.5802 \n",
      "Epoch 21: val_loss improved from 0.11211 to 0.11101, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0688 - precision_12: 0.8390 - recall_12: 0.5830 - val_loss: 0.1110 - val_precision_12: 0.7112 - val_recall_12: 0.4242\n",
      "Epoch 22/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0673 - precision_12: 0.8366 - recall_12: 0.5939 \n",
      "Epoch 22: val_loss improved from 0.11101 to 0.11089, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0670 - precision_12: 0.8329 - recall_12: 0.5932 - val_loss: 0.1109 - val_precision_12: 0.6936 - val_recall_12: 0.4386\n",
      "Epoch 23/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0653 - precision_12: 0.8330 - recall_12: 0.6209 \n",
      "Epoch 23: val_loss improved from 0.11089 to 0.10929, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0652 - precision_12: 0.8333 - recall_12: 0.6157 - val_loss: 0.1093 - val_precision_12: 0.7044 - val_recall_12: 0.4467\n",
      "Epoch 24/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0636 - precision_12: 0.8384 - recall_12: 0.6340 \n",
      "Epoch 24: val_loss improved from 0.10929 to 0.10756, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0630 - precision_12: 0.8381 - recall_12: 0.6324 - val_loss: 0.1076 - val_precision_12: 0.7129 - val_recall_12: 0.4477\n",
      "Epoch 25/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0608 - precision_12: 0.8654 - recall_12: 0.6385 \n",
      "Epoch 25: val_loss did not improve from 0.10756\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0607 - precision_12: 0.8570 - recall_12: 0.6402 - val_loss: 0.1079 - val_precision_12: 0.7085 - val_recall_12: 0.4560\n",
      "Epoch 26/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0601 - precision_12: 0.8611 - recall_12: 0.6430 \n",
      "Epoch 26: val_loss did not improve from 0.10756\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0596 - precision_12: 0.8580 - recall_12: 0.6471 - val_loss: 0.1082 - val_precision_12: 0.6995 - val_recall_12: 0.4818\n",
      "Epoch 27/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0573 - precision_12: 0.8536 - recall_12: 0.6800 \n",
      "Epoch 27: val_loss improved from 0.10756 to 0.10567, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0570 - precision_12: 0.8546 - recall_12: 0.6740 - val_loss: 0.1057 - val_precision_12: 0.6911 - val_recall_12: 0.4936\n",
      "Epoch 28/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0552 - precision_12: 0.8552 - recall_12: 0.6976 \n",
      "Epoch 28: val_loss improved from 0.10567 to 0.10462, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0548 - precision_12: 0.8573 - recall_12: 0.6952 - val_loss: 0.1046 - val_precision_12: 0.7132 - val_recall_12: 0.4979\n",
      "Epoch 29/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0542 - precision_12: 0.8765 - recall_12: 0.6821 \n",
      "Epoch 29: val_loss did not improve from 0.10462\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0540 - precision_12: 0.8700 - recall_12: 0.6862 - val_loss: 0.1060 - val_precision_12: 0.7028 - val_recall_12: 0.5142\n",
      "Epoch 30/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0532 - precision_12: 0.8591 - recall_12: 0.7004 \n",
      "Epoch 30: val_loss did not improve from 0.10462\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0528 - precision_12: 0.8590 - recall_12: 0.7023 - val_loss: 0.1048 - val_precision_12: 0.6990 - val_recall_12: 0.5213\n",
      "Epoch 31/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0518 - precision_12: 0.8714 - recall_12: 0.7010 \n",
      "Epoch 31: val_loss improved from 0.10462 to 0.10344, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0514 - precision_12: 0.8703 - recall_12: 0.7040 - val_loss: 0.1034 - val_precision_12: 0.7099 - val_recall_12: 0.5208\n",
      "Epoch 32/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0489 - precision_12: 0.8752 - recall_12: 0.7281 \n",
      "Epoch 32: val_loss did not improve from 0.10344\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0487 - precision_12: 0.8727 - recall_12: 0.7285 - val_loss: 0.1043 - val_precision_12: 0.7075 - val_recall_12: 0.5165\n",
      "Epoch 33/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0486 - precision_12: 0.8784 - recall_12: 0.7270 \n",
      "Epoch 33: val_loss did not improve from 0.10344\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0479 - precision_12: 0.8805 - recall_12: 0.7293 - val_loss: 0.1056 - val_precision_12: 0.7015 - val_recall_12: 0.5196\n",
      "Epoch 34/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0466 - precision_12: 0.8814 - recall_12: 0.7486 \n",
      "Epoch 34: val_loss improved from 0.10344 to 0.10305, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0463 - precision_12: 0.8783 - recall_12: 0.7492 - val_loss: 0.1030 - val_precision_12: 0.7106 - val_recall_12: 0.5278\n",
      "Epoch 35/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0446 - precision_12: 0.8925 - recall_12: 0.7470 \n",
      "Epoch 35: val_loss improved from 0.10305 to 0.10264, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0443 - precision_12: 0.8922 - recall_12: 0.7476 - val_loss: 0.1026 - val_precision_12: 0.7163 - val_recall_12: 0.5467\n",
      "Epoch 36/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0442 - precision_12: 0.8855 - recall_12: 0.7499 \n",
      "Epoch 36: val_loss did not improve from 0.10264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0436 - precision_12: 0.8873 - recall_12: 0.7537 - val_loss: 0.1034 - val_precision_12: 0.7118 - val_recall_12: 0.5554\n",
      "Epoch 37/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0439 - precision_12: 0.8736 - recall_12: 0.7604 \n",
      "Epoch 37: val_loss did not improve from 0.10264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0435 - precision_12: 0.8756 - recall_12: 0.7588 - val_loss: 0.1035 - val_precision_12: 0.7103 - val_recall_12: 0.5637\n",
      "Epoch 38/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0410 - precision_12: 0.8970 - recall_12: 0.7708 \n",
      "Epoch 38: val_loss did not improve from 0.10264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0410 - precision_12: 0.8922 - recall_12: 0.7737 - val_loss: 0.1035 - val_precision_12: 0.7196 - val_recall_12: 0.5637\n",
      "Epoch 39/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0412 - precision_12: 0.9026 - recall_12: 0.7627 \n",
      "Epoch 39: val_loss improved from 0.10264 to 0.10259, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0407 - precision_12: 0.9019 - recall_12: 0.7650 - val_loss: 0.1026 - val_precision_12: 0.7128 - val_recall_12: 0.5677\n",
      "Epoch 40/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0401 - precision_12: 0.8842 - recall_12: 0.7854 \n",
      "Epoch 40: val_loss did not improve from 0.10259\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0397 - precision_12: 0.8857 - recall_12: 0.7868 - val_loss: 0.1033 - val_precision_12: 0.7207 - val_recall_12: 0.5662\n",
      "Epoch 41/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0410 - precision_12: 0.8894 - recall_12: 0.7727 \n",
      "Epoch 41: val_loss improved from 0.10259 to 0.10180, saving model to 62sec_2layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0405 - precision_12: 0.8905 - recall_12: 0.7731 - val_loss: 0.1018 - val_precision_12: 0.7156 - val_recall_12: 0.5806\n",
      "Epoch 42/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0375 - precision_12: 0.8986 - recall_12: 0.8069 \n",
      "Epoch 42: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0375 - precision_12: 0.8972 - recall_12: 0.8050 - val_loss: 0.1029 - val_precision_12: 0.7235 - val_recall_12: 0.5712\n",
      "Epoch 43/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0369 - precision_12: 0.9034 - recall_12: 0.7925 \n",
      "Epoch 43: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0367 - precision_12: 0.9013 - recall_12: 0.7965 - val_loss: 0.1021 - val_precision_12: 0.7196 - val_recall_12: 0.5787\n",
      "Epoch 44/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0368 - precision_12: 0.9067 - recall_12: 0.7968 \n",
      "Epoch 44: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0366 - precision_12: 0.9037 - recall_12: 0.7982 - val_loss: 0.1021 - val_precision_12: 0.7212 - val_recall_12: 0.5869\n",
      "Epoch 45/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0347 - precision_12: 0.9044 - recall_12: 0.8218 \n",
      "Epoch 45: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0345 - precision_12: 0.9068 - recall_12: 0.8192 - val_loss: 0.1031 - val_precision_12: 0.7220 - val_recall_12: 0.5922\n",
      "Epoch 46/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - precision_12: 0.8999 - recall_12: 0.8144 \n",
      "Epoch 46: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0351 - precision_12: 0.9009 - recall_12: 0.8164 - val_loss: 0.1038 - val_precision_12: 0.7163 - val_recall_12: 0.5927\n",
      "Epoch 47/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0353 - precision_12: 0.9034 - recall_12: 0.8136 \n",
      "Epoch 47: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0349 - precision_12: 0.9036 - recall_12: 0.8148 - val_loss: 0.1032 - val_precision_12: 0.7256 - val_recall_12: 0.5926\n",
      "Epoch 48/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0342 - precision_12: 0.9032 - recall_12: 0.8201 \n",
      "Epoch 48: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0337 - precision_12: 0.9051 - recall_12: 0.8218 - val_loss: 0.1043 - val_precision_12: 0.7252 - val_recall_12: 0.5931\n",
      "Epoch 49/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0343 - precision_12: 0.9115 - recall_12: 0.8189 \n",
      "Epoch 49: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0338 - precision_12: 0.9096 - recall_12: 0.8205 - val_loss: 0.1028 - val_precision_12: 0.7211 - val_recall_12: 0.6042\n",
      "Epoch 50/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0329 - precision_12: 0.9041 - recall_12: 0.8320 \n",
      "Epoch 50: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0327 - precision_12: 0.9051 - recall_12: 0.8300 - val_loss: 0.1023 - val_precision_12: 0.7177 - val_recall_12: 0.6030\n",
      "Epoch 51/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0323 - precision_12: 0.9071 - recall_12: 0.8391 \n",
      "Epoch 51: val_loss did not improve from 0.10180\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0318 - precision_12: 0.9073 - recall_12: 0.8396 - val_loss: 0.1039 - val_precision_12: 0.7310 - val_recall_12: 0.5999\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0206 - precision_12: 0.9688 - recall_12: 0.9034\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1023 - precision_12: 0.7010 - recall_12: 0.5704\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1118 - precision_12: 0.6966 - recall_12: 0.5400\n",
      "Epoch 1/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5979 - precision_13: 0.0519 - recall_13: 0.3008  \n",
      "Epoch 1: val_loss improved from inf to 0.27249, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5815 - precision_13: 0.0519 - recall_13: 0.2821 - val_loss: 0.2725 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2764 - precision_13: 0.1580 - recall_13: 0.0109 \n",
      "Epoch 2: val_loss improved from 0.27249 to 0.21806, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2712 - precision_13: 0.1570 - recall_13: 0.0140 - val_loss: 0.2181 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2189 - precision_13: 0.1622 - recall_13: 0.0184 \n",
      "Epoch 3: val_loss improved from 0.21806 to 0.19508, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2170 - precision_13: 0.1629 - recall_13: 0.0168 - val_loss: 0.1951 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1942 - precision_13: 0.2710 - recall_13: 0.0026 \n",
      "Epoch 4: val_loss improved from 0.19508 to 0.18383, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1923 - precision_13: 0.2678 - recall_13: 0.0026 - val_loss: 0.1838 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1759 - precision_13: 0.4179 - recall_13: 0.0023 \n",
      "Epoch 5: val_loss improved from 0.18383 to 0.17398, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1746 - precision_13: 0.4221 - recall_13: 0.0026 - val_loss: 0.1740 - val_precision_13: 0.0000e+00 - val_recall_13: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1645 - precision_13: 0.4243 - recall_13: 0.0059 \n",
      "Epoch 6: val_loss improved from 0.17398 to 0.16600, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1632 - precision_13: 0.4355 - recall_13: 0.0067 - val_loss: 0.1660 - val_precision_13: 0.6250 - val_recall_13: 0.0033\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1547 - precision_13: 0.4655 - recall_13: 0.0233 \n",
      "Epoch 7: val_loss improved from 0.16600 to 0.15668, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1538 - precision_13: 0.4671 - recall_13: 0.0245 - val_loss: 0.1567 - val_precision_13: 0.5357 - val_recall_13: 0.0124\n",
      "Epoch 8/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1498 - precision_13: 0.4422 - recall_13: 0.0447 \n",
      "Epoch 8: val_loss improved from 0.15668 to 0.15066, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1478 - precision_13: 0.4557 - recall_13: 0.0482 - val_loss: 0.1507 - val_precision_13: 0.5263 - val_recall_13: 0.0133\n",
      "Epoch 9/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1433 - precision_13: 0.5257 - recall_13: 0.0646 \n",
      "Epoch 9: val_loss improved from 0.15066 to 0.14868, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1416 - precision_13: 0.5239 - recall_13: 0.0695 - val_loss: 0.1487 - val_precision_13: 0.5199 - val_recall_13: 0.0411\n",
      "Epoch 10/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1376 - precision_13: 0.5507 - recall_13: 0.0791 \n",
      "Epoch 10: val_loss improved from 0.14868 to 0.14856, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1363 - precision_13: 0.5510 - recall_13: 0.0848 - val_loss: 0.1486 - val_precision_13: 0.5481 - val_recall_13: 0.0981\n",
      "Epoch 11/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1321 - precision_13: 0.5573 - recall_13: 0.1153 \n",
      "Epoch 11: val_loss improved from 0.14856 to 0.14405, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1306 - precision_13: 0.5714 - recall_13: 0.1196 - val_loss: 0.1440 - val_precision_13: 0.5670 - val_recall_13: 0.1009\n",
      "Epoch 12/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1278 - precision_13: 0.5854 - recall_13: 0.1375 \n",
      "Epoch 12: val_loss improved from 0.14405 to 0.13902, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1262 - precision_13: 0.5959 - recall_13: 0.1473 - val_loss: 0.1390 - val_precision_13: 0.5953 - val_recall_13: 0.1124\n",
      "Epoch 13/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1214 - precision_13: 0.6574 - recall_13: 0.1788 \n",
      "Epoch 13: val_loss improved from 0.13902 to 0.13742, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1203 - precision_13: 0.6609 - recall_13: 0.1915 - val_loss: 0.1374 - val_precision_13: 0.5999 - val_recall_13: 0.1518\n",
      "Epoch 14/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1138 - precision_13: 0.7268 - recall_13: 0.2112 \n",
      "Epoch 14: val_loss improved from 0.13742 to 0.13649, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1134 - precision_13: 0.7201 - recall_13: 0.2174 - val_loss: 0.1365 - val_precision_13: 0.5847 - val_recall_13: 0.2254\n",
      "Epoch 15/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1114 - precision_13: 0.6829 - recall_13: 0.2921 \n",
      "Epoch 15: val_loss improved from 0.13649 to 0.13170, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1100 - precision_13: 0.6896 - recall_13: 0.2898 - val_loss: 0.1317 - val_precision_13: 0.6282 - val_recall_13: 0.2123\n",
      "Epoch 16/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1061 - precision_13: 0.7246 - recall_13: 0.2982 \n",
      "Epoch 16: val_loss improved from 0.13170 to 0.12905, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1052 - precision_13: 0.7242 - recall_13: 0.3045 - val_loss: 0.1290 - val_precision_13: 0.6442 - val_recall_13: 0.2503\n",
      "Epoch 17/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0994 - precision_13: 0.7635 - recall_13: 0.3425 \n",
      "Epoch 17: val_loss improved from 0.12905 to 0.12618, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0989 - precision_13: 0.7606 - recall_13: 0.3477 - val_loss: 0.1262 - val_precision_13: 0.6369 - val_recall_13: 0.2911\n",
      "Epoch 18/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0964 - precision_13: 0.7479 - recall_13: 0.3745 \n",
      "Epoch 18: val_loss improved from 0.12618 to 0.12453, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0959 - precision_13: 0.7488 - recall_13: 0.3794 - val_loss: 0.1245 - val_precision_13: 0.6553 - val_recall_13: 0.3113\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0930 - precision_13: 0.7602 - recall_13: 0.4112 \n",
      "Epoch 19: val_loss improved from 0.12453 to 0.12392, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0925 - precision_13: 0.7581 - recall_13: 0.4120 - val_loss: 0.1239 - val_precision_13: 0.6348 - val_recall_13: 0.3396\n",
      "Epoch 20/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0890 - precision_13: 0.7700 - recall_13: 0.4686 \n",
      "Epoch 20: val_loss improved from 0.12392 to 0.12059, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0883 - precision_13: 0.7696 - recall_13: 0.4648 - val_loss: 0.1206 - val_precision_13: 0.6522 - val_recall_13: 0.3391\n",
      "Epoch 21/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0861 - precision_13: 0.7851 - recall_13: 0.4592 \n",
      "Epoch 21: val_loss improved from 0.12059 to 0.11891, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - precision_13: 0.7821 - recall_13: 0.4677 - val_loss: 0.1189 - val_precision_13: 0.6679 - val_recall_13: 0.3640\n",
      "Epoch 22/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0839 - precision_13: 0.7945 - recall_13: 0.4712 \n",
      "Epoch 22: val_loss improved from 0.11891 to 0.11890, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0833 - precision_13: 0.7928 - recall_13: 0.4781 - val_loss: 0.1189 - val_precision_13: 0.6392 - val_recall_13: 0.4160\n",
      "Epoch 23/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0805 - precision_13: 0.7816 - recall_13: 0.5424 \n",
      "Epoch 23: val_loss improved from 0.11890 to 0.11544, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0798 - precision_13: 0.7835 - recall_13: 0.5381 - val_loss: 0.1154 - val_precision_13: 0.6738 - val_recall_13: 0.4000\n",
      "Epoch 24/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0773 - precision_13: 0.8031 - recall_13: 0.5377 \n",
      "Epoch 24: val_loss improved from 0.11544 to 0.11467, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0771 - precision_13: 0.8023 - recall_13: 0.5346 - val_loss: 0.1147 - val_precision_13: 0.6791 - val_recall_13: 0.4255\n",
      "Epoch 25/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0759 - precision_13: 0.7898 - recall_13: 0.5646 \n",
      "Epoch 25: val_loss improved from 0.11467 to 0.11309, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0751 - precision_13: 0.7926 - recall_13: 0.5656 - val_loss: 0.1131 - val_precision_13: 0.6814 - val_recall_13: 0.4333\n",
      "Epoch 26/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0746 - precision_13: 0.8187 - recall_13: 0.5484 \n",
      "Epoch 26: val_loss improved from 0.11309 to 0.11265, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - precision_13: 0.8181 - recall_13: 0.5520 - val_loss: 0.1126 - val_precision_13: 0.6918 - val_recall_13: 0.4465\n",
      "Epoch 27/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0725 - precision_13: 0.8222 - recall_13: 0.5582 \n",
      "Epoch 27: val_loss improved from 0.11265 to 0.11052, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0721 - precision_13: 0.8185 - recall_13: 0.5634 - val_loss: 0.1105 - val_precision_13: 0.6941 - val_recall_13: 0.4581\n",
      "Epoch 28/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0703 - precision_13: 0.8254 - recall_13: 0.5884 \n",
      "Epoch 28: val_loss improved from 0.11052 to 0.10990, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0702 - precision_13: 0.8210 - recall_13: 0.5863 - val_loss: 0.1099 - val_precision_13: 0.6965 - val_recall_13: 0.4721\n",
      "Epoch 29/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0679 - precision_13: 0.8388 - recall_13: 0.6020 \n",
      "Epoch 29: val_loss improved from 0.10990 to 0.10976, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0678 - precision_13: 0.8332 - recall_13: 0.6019 - val_loss: 0.1098 - val_precision_13: 0.6728 - val_recall_13: 0.4818\n",
      "Epoch 30/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0688 - precision_13: 0.8140 - recall_13: 0.5915 \n",
      "Epoch 30: val_loss did not improve from 0.10976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0677 - precision_13: 0.8162 - recall_13: 0.5991 - val_loss: 0.1108 - val_precision_13: 0.6635 - val_recall_13: 0.4799\n",
      "Epoch 31/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0655 - precision_13: 0.8197 - recall_13: 0.6354 \n",
      "Epoch 31: val_loss improved from 0.10976 to 0.10864, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0651 - precision_13: 0.8182 - recall_13: 0.6323 - val_loss: 0.1086 - val_precision_13: 0.6981 - val_recall_13: 0.4860\n",
      "Epoch 32/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0628 - precision_13: 0.8593 - recall_13: 0.6294 \n",
      "Epoch 32: val_loss did not improve from 0.10864\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0629 - precision_13: 0.8512 - recall_13: 0.6304 - val_loss: 0.1091 - val_precision_13: 0.6722 - val_recall_13: 0.5065\n",
      "Epoch 33/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0660 - precision_13: 0.8283 - recall_13: 0.6250 \n",
      "Epoch 33: val_loss improved from 0.10864 to 0.10597, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0650 - precision_13: 0.8255 - recall_13: 0.6292 - val_loss: 0.1060 - val_precision_13: 0.6765 - val_recall_13: 0.5185\n",
      "Epoch 34/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0625 - precision_13: 0.8200 - recall_13: 0.6482 \n",
      "Epoch 34: val_loss did not improve from 0.10597\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0619 - precision_13: 0.8223 - recall_13: 0.6500 - val_loss: 0.1082 - val_precision_13: 0.6974 - val_recall_13: 0.5095\n",
      "Epoch 35/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0607 - precision_13: 0.8504 - recall_13: 0.6373 \n",
      "Epoch 35: val_loss did not improve from 0.10597\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0601 - precision_13: 0.8479 - recall_13: 0.6410 - val_loss: 0.1067 - val_precision_13: 0.6841 - val_recall_13: 0.5220\n",
      "Epoch 36/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0603 - precision_13: 0.8255 - recall_13: 0.6772 \n",
      "Epoch 36: val_loss did not improve from 0.10597\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0598 - precision_13: 0.8281 - recall_13: 0.6723 - val_loss: 0.1063 - val_precision_13: 0.6891 - val_recall_13: 0.5276\n",
      "Epoch 37/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0593 - precision_13: 0.8597 - recall_13: 0.6514 \n",
      "Epoch 37: val_loss did not improve from 0.10597\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0587 - precision_13: 0.8538 - recall_13: 0.6590 - val_loss: 0.1062 - val_precision_13: 0.6840 - val_recall_13: 0.5385\n",
      "Epoch 38/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0595 - precision_13: 0.8396 - recall_13: 0.6565 \n",
      "Epoch 38: val_loss improved from 0.10597 to 0.10582, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0583 - precision_13: 0.8423 - recall_13: 0.6643 - val_loss: 0.1058 - val_precision_13: 0.6732 - val_recall_13: 0.5374\n",
      "Epoch 39/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0546 - precision_13: 0.8523 - recall_13: 0.6994 \n",
      "Epoch 39: val_loss improved from 0.10582 to 0.10507, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0546 - precision_13: 0.8525 - recall_13: 0.6959 - val_loss: 0.1051 - val_precision_13: 0.6843 - val_recall_13: 0.5367\n",
      "Epoch 40/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0543 - precision_13: 0.8524 - recall_13: 0.7001 \n",
      "Epoch 40: val_loss did not improve from 0.10507\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0541 - precision_13: 0.8524 - recall_13: 0.6997 - val_loss: 0.1059 - val_precision_13: 0.6877 - val_recall_13: 0.5417\n",
      "Epoch 41/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0557 - precision_13: 0.8407 - recall_13: 0.7006 \n",
      "Epoch 41: val_loss did not improve from 0.10507\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0550 - precision_13: 0.8417 - recall_13: 0.7016 - val_loss: 0.1052 - val_precision_13: 0.6892 - val_recall_13: 0.5359\n",
      "Epoch 42/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0535 - precision_13: 0.8601 - recall_13: 0.6953 \n",
      "Epoch 42: val_loss improved from 0.10507 to 0.10499, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0532 - precision_13: 0.8608 - recall_13: 0.6947 - val_loss: 0.1050 - val_precision_13: 0.6873 - val_recall_13: 0.5559\n",
      "Epoch 43/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0531 - precision_13: 0.8471 - recall_13: 0.7071 \n",
      "Epoch 43: val_loss improved from 0.10499 to 0.10285, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0526 - precision_13: 0.8476 - recall_13: 0.7089 - val_loss: 0.1028 - val_precision_13: 0.7003 - val_recall_13: 0.5480\n",
      "Epoch 44/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0510 - precision_13: 0.8665 - recall_13: 0.7160 \n",
      "Epoch 44: val_loss did not improve from 0.10285\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0508 - precision_13: 0.8649 - recall_13: 0.7163 - val_loss: 0.1039 - val_precision_13: 0.6798 - val_recall_13: 0.5641\n",
      "Epoch 45/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0499 - precision_13: 0.8705 - recall_13: 0.7243 \n",
      "Epoch 45: val_loss did not improve from 0.10285\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0496 - precision_13: 0.8675 - recall_13: 0.7231 - val_loss: 0.1030 - val_precision_13: 0.6777 - val_recall_13: 0.5657\n",
      "Epoch 46/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0511 - precision_13: 0.8580 - recall_13: 0.7213 \n",
      "Epoch 46: val_loss improved from 0.10285 to 0.10229, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0503 - precision_13: 0.8574 - recall_13: 0.7239 - val_loss: 0.1023 - val_precision_13: 0.6851 - val_recall_13: 0.5641\n",
      "Epoch 47/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0489 - precision_13: 0.8628 - recall_13: 0.7357 \n",
      "Epoch 47: val_loss did not improve from 0.10229\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0490 - precision_13: 0.8621 - recall_13: 0.7333 - val_loss: 0.1027 - val_precision_13: 0.7001 - val_recall_13: 0.5559\n",
      "Epoch 48/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0486 - precision_13: 0.8768 - recall_13: 0.7232 \n",
      "Epoch 48: val_loss did not improve from 0.10229\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0485 - precision_13: 0.8731 - recall_13: 0.7256 - val_loss: 0.1032 - val_precision_13: 0.6939 - val_recall_13: 0.5738\n",
      "Epoch 49/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0476 - precision_13: 0.8630 - recall_13: 0.7481 \n",
      "Epoch 49: val_loss did not improve from 0.10229\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0474 - precision_13: 0.8625 - recall_13: 0.7480 - val_loss: 0.1026 - val_precision_13: 0.7054 - val_recall_13: 0.5730\n",
      "Epoch 50/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0469 - precision_13: 0.8684 - recall_13: 0.7514 \n",
      "Epoch 50: val_loss improved from 0.10229 to 0.10215, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0463 - precision_13: 0.8712 - recall_13: 0.7498 - val_loss: 0.1022 - val_precision_13: 0.7024 - val_recall_13: 0.5767\n",
      "Epoch 51/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0475 - precision_13: 0.8709 - recall_13: 0.7330 \n",
      "Epoch 51: val_loss improved from 0.10215 to 0.10159, saving model to 62sec_2layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0472 - precision_13: 0.8681 - recall_13: 0.7369 - val_loss: 0.1016 - val_precision_13: 0.7018 - val_recall_13: 0.5813\n",
      "Epoch 52/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0463 - precision_13: 0.8648 - recall_13: 0.7379 \n",
      "Epoch 52: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0458 - precision_13: 0.8675 - recall_13: 0.7407 - val_loss: 0.1025 - val_precision_13: 0.7065 - val_recall_13: 0.5878\n",
      "Epoch 53/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0432 - precision_13: 0.8806 - recall_13: 0.7598 \n",
      "Epoch 53: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0436 - precision_13: 0.8773 - recall_13: 0.7587 - val_loss: 0.1037 - val_precision_13: 0.7086 - val_recall_13: 0.5916\n",
      "Epoch 54/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0443 - precision_13: 0.8790 - recall_13: 0.7553 \n",
      "Epoch 54: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0439 - precision_13: 0.8794 - recall_13: 0.7589 - val_loss: 0.1034 - val_precision_13: 0.7187 - val_recall_13: 0.5777\n",
      "Epoch 55/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0441 - precision_13: 0.8911 - recall_13: 0.7556 \n",
      "Epoch 55: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - precision_13: 0.8882 - recall_13: 0.7624 - val_loss: 0.1031 - val_precision_13: 0.7184 - val_recall_13: 0.5966\n",
      "Epoch 56/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0437 - precision_13: 0.8744 - recall_13: 0.7635 \n",
      "Epoch 56: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0433 - precision_13: 0.8745 - recall_13: 0.7646 - val_loss: 0.1024 - val_precision_13: 0.7194 - val_recall_13: 0.5970\n",
      "Epoch 57/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0424 - precision_13: 0.8903 - recall_13: 0.7648 \n",
      "Epoch 57: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0420 - precision_13: 0.8885 - recall_13: 0.7681 - val_loss: 0.1026 - val_precision_13: 0.6998 - val_recall_13: 0.6050\n",
      "Epoch 58/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0435 - precision_13: 0.8601 - recall_13: 0.7844 \n",
      "Epoch 58: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0429 - precision_13: 0.8642 - recall_13: 0.7824 - val_loss: 0.1031 - val_precision_13: 0.7124 - val_recall_13: 0.5977\n",
      "Epoch 59/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0410 - precision_13: 0.8934 - recall_13: 0.7752 \n",
      "Epoch 59: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0411 - precision_13: 0.8916 - recall_13: 0.7751 - val_loss: 0.1034 - val_precision_13: 0.7007 - val_recall_13: 0.6078\n",
      "Epoch 60/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0439 - precision_13: 0.8738 - recall_13: 0.7640 \n",
      "Epoch 60: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0432 - precision_13: 0.8741 - recall_13: 0.7693 - val_loss: 0.1021 - val_precision_13: 0.7000 - val_recall_13: 0.6111\n",
      "Epoch 61/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0410 - precision_13: 0.8777 - recall_13: 0.7783 \n",
      "Epoch 61: val_loss did not improve from 0.10159\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0407 - precision_13: 0.8777 - recall_13: 0.7796 - val_loss: 0.1033 - val_precision_13: 0.7045 - val_recall_13: 0.6070\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0226 - precision_13: 0.9616 - recall_13: 0.8981\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1021 - precision_13: 0.6937 - recall_13: 0.5715\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1073 - precision_13: 0.7000 - recall_13: 0.5592\n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6147 - precision_14: 0.0518 - recall_14: 0.3238  \n",
      "Epoch 1: val_loss improved from inf to 0.27068, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5892 - precision_14: 0.0518 - recall_14: 0.2941 - val_loss: 0.2707 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2853 - precision_14: 0.1231 - recall_14: 0.0063 \n",
      "Epoch 2: val_loss improved from 0.27068 to 0.22070, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2772 - precision_14: 0.1306 - recall_14: 0.0102 - val_loss: 0.2207 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2237 - precision_14: 0.1507 - recall_14: 0.0297 \n",
      "Epoch 3: val_loss improved from 0.22070 to 0.19546, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2219 - precision_14: 0.1506 - recall_14: 0.0276 - val_loss: 0.1955 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2009 - precision_14: 0.1923 - recall_14: 0.0036 \n",
      "Epoch 4: val_loss improved from 0.19546 to 0.18608, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1995 - precision_14: 0.1960 - recall_14: 0.0035 - val_loss: 0.1861 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1822 - precision_14: 0.2626 - recall_14: 0.0014 \n",
      "Epoch 5: val_loss improved from 0.18608 to 0.17862, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1811 - precision_14: 0.2671 - recall_14: 0.0015 - val_loss: 0.1786 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1728 - precision_14: 0.3677 - recall_14: 0.0029 \n",
      "Epoch 6: val_loss improved from 0.17862 to 0.17375, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1722 - precision_14: 0.3658 - recall_14: 0.0028 - val_loss: 0.1738 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1676 - precision_14: 0.4104 - recall_14: 0.0058 \n",
      "Epoch 7: val_loss improved from 0.17375 to 0.16240, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1662 - precision_14: 0.4245 - recall_14: 0.0059 - val_loss: 0.1624 - val_precision_14: 0.0000e+00 - val_recall_14: 0.0000e+00\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1616 - precision_14: 0.4656 - recall_14: 0.0143 \n",
      "Epoch 8: val_loss improved from 0.16240 to 0.15528, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1599 - precision_14: 0.4754 - recall_14: 0.0162 - val_loss: 0.1553 - val_precision_14: 0.6667 - val_recall_14: 9.9453e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1545 - precision_14: 0.4693 - recall_14: 0.0289 \n",
      "Epoch 9: val_loss improved from 0.15528 to 0.15315, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1529 - precision_14: 0.4783 - recall_14: 0.0339 - val_loss: 0.1532 - val_precision_14: 0.4954 - val_recall_14: 0.0179\n",
      "Epoch 10/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1481 - precision_14: 0.4623 - recall_14: 0.0527 \n",
      "Epoch 10: val_loss improved from 0.15315 to 0.15181, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1467 - precision_14: 0.4700 - recall_14: 0.0564 - val_loss: 0.1518 - val_precision_14: 0.5373 - val_recall_14: 0.0489\n",
      "Epoch 11/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1436 - precision_14: 0.4744 - recall_14: 0.0708 \n",
      "Epoch 11: val_loss improved from 0.15181 to 0.14679, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1420 - precision_14: 0.4926 - recall_14: 0.0756 - val_loss: 0.1468 - val_precision_14: 0.5236 - val_recall_14: 0.0477\n",
      "Epoch 12/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1403 - precision_14: 0.5352 - recall_14: 0.0894 \n",
      "Epoch 12: val_loss improved from 0.14679 to 0.14432, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1384 - precision_14: 0.5399 - recall_14: 0.0949 - val_loss: 0.1443 - val_precision_14: 0.5695 - val_recall_14: 0.0564\n",
      "Epoch 13/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1335 - precision_14: 0.5759 - recall_14: 0.1024 \n",
      "Epoch 13: val_loss improved from 0.14432 to 0.14348, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1326 - precision_14: 0.5763 - recall_14: 0.1087 - val_loss: 0.1435 - val_precision_14: 0.5912 - val_recall_14: 0.1160\n",
      "Epoch 14/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1313 - precision_14: 0.5809 - recall_14: 0.1430 \n",
      "Epoch 14: val_loss improved from 0.14348 to 0.14045, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1301 - precision_14: 0.5846 - recall_14: 0.1460 - val_loss: 0.1405 - val_precision_14: 0.5835 - val_recall_14: 0.1303\n",
      "Epoch 15/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1287 - precision_14: 0.5888 - recall_14: 0.1510 \n",
      "Epoch 15: val_loss improved from 0.14045 to 0.13805, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1270 - precision_14: 0.6045 - recall_14: 0.1589 - val_loss: 0.1380 - val_precision_14: 0.6028 - val_recall_14: 0.1595\n",
      "Epoch 16/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1239 - precision_14: 0.6138 - recall_14: 0.1751 \n",
      "Epoch 16: val_loss improved from 0.13805 to 0.13532, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1221 - precision_14: 0.6240 - recall_14: 0.1893 - val_loss: 0.1353 - val_precision_14: 0.5958 - val_recall_14: 0.1881\n",
      "Epoch 17/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1178 - precision_14: 0.6929 - recall_14: 0.2456 \n",
      "Epoch 17: val_loss improved from 0.13532 to 0.13358, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1169 - precision_14: 0.6920 - recall_14: 0.2444 - val_loss: 0.1336 - val_precision_14: 0.6103 - val_recall_14: 0.2142\n",
      "Epoch 18/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1158 - precision_14: 0.6881 - recall_14: 0.2384 \n",
      "Epoch 18: val_loss improved from 0.13358 to 0.13139, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1147 - precision_14: 0.6885 - recall_14: 0.2451 - val_loss: 0.1314 - val_precision_14: 0.6154 - val_recall_14: 0.2498\n",
      "Epoch 19/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1081 - precision_14: 0.7267 - recall_14: 0.3034 \n",
      "Epoch 19: val_loss improved from 0.13139 to 0.12875, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1076 - precision_14: 0.7211 - recall_14: 0.3086 - val_loss: 0.1287 - val_precision_14: 0.6242 - val_recall_14: 0.2758\n",
      "Epoch 20/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1072 - precision_14: 0.7208 - recall_14: 0.2978 \n",
      "Epoch 20: val_loss improved from 0.12875 to 0.12809, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1061 - precision_14: 0.7205 - recall_14: 0.3097 - val_loss: 0.1281 - val_precision_14: 0.6227 - val_recall_14: 0.3143\n",
      "Epoch 21/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1049 - precision_14: 0.7039 - recall_14: 0.3580 \n",
      "Epoch 21: val_loss improved from 0.12809 to 0.12429, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1035 - precision_14: 0.7107 - recall_14: 0.3614 - val_loss: 0.1243 - val_precision_14: 0.6420 - val_recall_14: 0.2952\n",
      "Epoch 22/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1014 - precision_14: 0.7407 - recall_14: 0.3381 \n",
      "Epoch 22: val_loss improved from 0.12429 to 0.12267, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1004 - precision_14: 0.7377 - recall_14: 0.3505 - val_loss: 0.1227 - val_precision_14: 0.6223 - val_recall_14: 0.3411\n",
      "Epoch 23/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0972 - precision_14: 0.7370 - recall_14: 0.3855 \n",
      "Epoch 23: val_loss improved from 0.12267 to 0.12190, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0966 - precision_14: 0.7368 - recall_14: 0.3907 - val_loss: 0.1219 - val_precision_14: 0.6278 - val_recall_14: 0.3416\n",
      "Epoch 24/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0955 - precision_14: 0.7579 - recall_14: 0.4030 \n",
      "Epoch 24: val_loss improved from 0.12190 to 0.11992, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0944 - precision_14: 0.7549 - recall_14: 0.4063 - val_loss: 0.1199 - val_precision_14: 0.6333 - val_recall_14: 0.3555\n",
      "Epoch 25/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0919 - precision_14: 0.7666 - recall_14: 0.4386 \n",
      "Epoch 25: val_loss improved from 0.11992 to 0.11845, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0917 - precision_14: 0.7606 - recall_14: 0.4393 - val_loss: 0.1184 - val_precision_14: 0.6526 - val_recall_14: 0.3749\n",
      "Epoch 26/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0908 - precision_14: 0.7689 - recall_14: 0.4423 \n",
      "Epoch 26: val_loss improved from 0.11845 to 0.11745, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0901 - precision_14: 0.7651 - recall_14: 0.4434 - val_loss: 0.1174 - val_precision_14: 0.6449 - val_recall_14: 0.3922\n",
      "Epoch 27/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0898 - precision_14: 0.7657 - recall_14: 0.4612 \n",
      "Epoch 27: val_loss improved from 0.11745 to 0.11711, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0893 - precision_14: 0.7647 - recall_14: 0.4633 - val_loss: 0.1171 - val_precision_14: 0.6467 - val_recall_14: 0.3978\n",
      "Epoch 28/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0860 - precision_14: 0.7717 - recall_14: 0.4739 \n",
      "Epoch 28: val_loss improved from 0.11711 to 0.11379, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0861 - precision_14: 0.7670 - recall_14: 0.4715 - val_loss: 0.1138 - val_precision_14: 0.6719 - val_recall_14: 0.4151\n",
      "Epoch 29/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0868 - precision_14: 0.7789 - recall_14: 0.4728 \n",
      "Epoch 29: val_loss improved from 0.11379 to 0.11344, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0856 - precision_14: 0.7736 - recall_14: 0.4814 - val_loss: 0.1134 - val_precision_14: 0.6822 - val_recall_14: 0.4301\n",
      "Epoch 30/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0847 - precision_14: 0.7676 - recall_14: 0.4847 \n",
      "Epoch 30: val_loss did not improve from 0.11344\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0841 - precision_14: 0.7672 - recall_14: 0.4849 - val_loss: 0.1144 - val_precision_14: 0.6563 - val_recall_14: 0.4349\n",
      "Epoch 31/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0829 - precision_14: 0.7656 - recall_14: 0.5262 \n",
      "Epoch 31: val_loss improved from 0.11344 to 0.11179, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0821 - precision_14: 0.7670 - recall_14: 0.5256 - val_loss: 0.1118 - val_precision_14: 0.6788 - val_recall_14: 0.4238\n",
      "Epoch 32/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0807 - precision_14: 0.7872 - recall_14: 0.5027 \n",
      "Epoch 32: val_loss did not improve from 0.11179\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0802 - precision_14: 0.7820 - recall_14: 0.5090 - val_loss: 0.1132 - val_precision_14: 0.6628 - val_recall_14: 0.4545\n",
      "Epoch 33/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0804 - precision_14: 0.8021 - recall_14: 0.5257 \n",
      "Epoch 33: val_loss improved from 0.11179 to 0.11163, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0801 - precision_14: 0.7945 - recall_14: 0.5266 - val_loss: 0.1116 - val_precision_14: 0.6669 - val_recall_14: 0.4417\n",
      "Epoch 34/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0792 - precision_14: 0.7979 - recall_14: 0.5173 \n",
      "Epoch 34: val_loss did not improve from 0.11163\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0788 - precision_14: 0.7945 - recall_14: 0.5218 - val_loss: 0.1117 - val_precision_14: 0.6637 - val_recall_14: 0.4747\n",
      "Epoch 35/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0771 - precision_14: 0.7762 - recall_14: 0.5651 \n",
      "Epoch 35: val_loss improved from 0.11163 to 0.11048, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0768 - precision_14: 0.7782 - recall_14: 0.5581 - val_loss: 0.1105 - val_precision_14: 0.6719 - val_recall_14: 0.4671\n",
      "Epoch 36/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0762 - precision_14: 0.7839 - recall_14: 0.5518 \n",
      "Epoch 36: val_loss did not improve from 0.11048\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0757 - precision_14: 0.7845 - recall_14: 0.5540 - val_loss: 0.1105 - val_precision_14: 0.6577 - val_recall_14: 0.4774\n",
      "Epoch 37/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0751 - precision_14: 0.8116 - recall_14: 0.5468 \n",
      "Epoch 37: val_loss improved from 0.11048 to 0.10970, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0754 - precision_14: 0.8006 - recall_14: 0.5482 - val_loss: 0.1097 - val_precision_14: 0.6755 - val_recall_14: 0.4799\n",
      "Epoch 38/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0741 - precision_14: 0.8016 - recall_14: 0.5755 \n",
      "Epoch 38: val_loss improved from 0.10970 to 0.10867, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0738 - precision_14: 0.7952 - recall_14: 0.5770 - val_loss: 0.1087 - val_precision_14: 0.6686 - val_recall_14: 0.4769\n",
      "Epoch 39/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0727 - precision_14: 0.8084 - recall_14: 0.5847 \n",
      "Epoch 39: val_loss improved from 0.10867 to 0.10822, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0727 - precision_14: 0.8042 - recall_14: 0.5834 - val_loss: 0.1082 - val_precision_14: 0.6765 - val_recall_14: 0.4686\n",
      "Epoch 40/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0730 - precision_14: 0.8247 - recall_14: 0.5609 \n",
      "Epoch 40: val_loss improved from 0.10822 to 0.10806, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0724 - precision_14: 0.8188 - recall_14: 0.5644 - val_loss: 0.1081 - val_precision_14: 0.6561 - val_recall_14: 0.4968\n",
      "Epoch 41/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0714 - precision_14: 0.7969 - recall_14: 0.6054 \n",
      "Epoch 41: val_loss did not improve from 0.10806\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0712 - precision_14: 0.7941 - recall_14: 0.6024 - val_loss: 0.1084 - val_precision_14: 0.6697 - val_recall_14: 0.4893\n",
      "Epoch 42/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0710 - precision_14: 0.7911 - recall_14: 0.5879 \n",
      "Epoch 42: val_loss improved from 0.10806 to 0.10752, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0705 - precision_14: 0.7931 - recall_14: 0.5899 - val_loss: 0.1075 - val_precision_14: 0.6772 - val_recall_14: 0.4963\n",
      "Epoch 43/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0678 - precision_14: 0.8169 - recall_14: 0.6113 \n",
      "Epoch 43: val_loss did not improve from 0.10752\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0680 - precision_14: 0.8153 - recall_14: 0.6064 - val_loss: 0.1076 - val_precision_14: 0.6756 - val_recall_14: 0.5147\n",
      "Epoch 44/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0685 - precision_14: 0.8146 - recall_14: 0.6054 \n",
      "Epoch 44: val_loss improved from 0.10752 to 0.10692, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0680 - precision_14: 0.8081 - recall_14: 0.6108 - val_loss: 0.1069 - val_precision_14: 0.6778 - val_recall_14: 0.5188\n",
      "Epoch 45/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0673 - precision_14: 0.8013 - recall_14: 0.6099 \n",
      "Epoch 45: val_loss improved from 0.10692 to 0.10656, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0666 - precision_14: 0.8042 - recall_14: 0.6132 - val_loss: 0.1066 - val_precision_14: 0.6857 - val_recall_14: 0.5183\n",
      "Epoch 46/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0694 - precision_14: 0.8208 - recall_14: 0.5901 \n",
      "Epoch 46: val_loss improved from 0.10656 to 0.10563, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0687 - precision_14: 0.8135 - recall_14: 0.5983 - val_loss: 0.1056 - val_precision_14: 0.6835 - val_recall_14: 0.5279\n",
      "Epoch 47/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0674 - precision_14: 0.8088 - recall_14: 0.6184 \n",
      "Epoch 47: val_loss did not improve from 0.10563\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0673 - precision_14: 0.8083 - recall_14: 0.6164 - val_loss: 0.1058 - val_precision_14: 0.6892 - val_recall_14: 0.5259\n",
      "Epoch 48/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0691 - precision_14: 0.8206 - recall_14: 0.6027 \n",
      "Epoch 48: val_loss improved from 0.10563 to 0.10375, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0680 - precision_14: 0.8191 - recall_14: 0.6092 - val_loss: 0.1037 - val_precision_14: 0.6801 - val_recall_14: 0.5327\n",
      "Epoch 49/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0661 - precision_14: 0.8059 - recall_14: 0.6250 \n",
      "Epoch 49: val_loss did not improve from 0.10375\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0660 - precision_14: 0.8060 - recall_14: 0.6222 - val_loss: 0.1049 - val_precision_14: 0.6770 - val_recall_14: 0.5195\n",
      "Epoch 50/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0641 - precision_14: 0.8193 - recall_14: 0.6331 \n",
      "Epoch 50: val_loss did not improve from 0.10375\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0639 - precision_14: 0.8186 - recall_14: 0.6325 - val_loss: 0.1040 - val_precision_14: 0.6732 - val_recall_14: 0.5357\n",
      "Epoch 51/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0654 - precision_14: 0.8223 - recall_14: 0.6413 \n",
      "Epoch 51: val_loss did not improve from 0.10375\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0645 - precision_14: 0.8177 - recall_14: 0.6462 - val_loss: 0.1045 - val_precision_14: 0.6830 - val_recall_14: 0.5349\n",
      "Epoch 52/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0644 - precision_14: 0.8236 - recall_14: 0.6226 \n",
      "Epoch 52: val_loss improved from 0.10375 to 0.10252, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0637 - precision_14: 0.8209 - recall_14: 0.6297 - val_loss: 0.1025 - val_precision_14: 0.6830 - val_recall_14: 0.5374\n",
      "Epoch 53/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0635 - precision_14: 0.8237 - recall_14: 0.6420 \n",
      "Epoch 53: val_loss did not improve from 0.10252\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0631 - precision_14: 0.8228 - recall_14: 0.6430 - val_loss: 0.1037 - val_precision_14: 0.6781 - val_recall_14: 0.5395\n",
      "Epoch 54/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0629 - precision_14: 0.8282 - recall_14: 0.6581 \n",
      "Epoch 54: val_loss did not improve from 0.10252\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0622 - precision_14: 0.8276 - recall_14: 0.6584 - val_loss: 0.1028 - val_precision_14: 0.6735 - val_recall_14: 0.5453\n",
      "Epoch 55/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0658 - precision_14: 0.8111 - recall_14: 0.6328 \n",
      "Epoch 55: val_loss did not improve from 0.10252\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0644 - precision_14: 0.8102 - recall_14: 0.6389 - val_loss: 0.1029 - val_precision_14: 0.6787 - val_recall_14: 0.5503\n",
      "Epoch 56/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0630 - precision_14: 0.8265 - recall_14: 0.6369 \n",
      "Epoch 56: val_loss did not improve from 0.10252\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0619 - precision_14: 0.8254 - recall_14: 0.6438 - val_loss: 0.1029 - val_precision_14: 0.6798 - val_recall_14: 0.5521\n",
      "Epoch 57/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0604 - precision_14: 0.8387 - recall_14: 0.6578 \n",
      "Epoch 57: val_loss improved from 0.10252 to 0.10208, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0599 - precision_14: 0.8357 - recall_14: 0.6615 - val_loss: 0.1021 - val_precision_14: 0.6817 - val_recall_14: 0.5616\n",
      "Epoch 58/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0587 - precision_14: 0.8365 - recall_14: 0.6852 \n",
      "Epoch 58: val_loss improved from 0.10208 to 0.10197, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0586 - precision_14: 0.8338 - recall_14: 0.6817 - val_loss: 0.1020 - val_precision_14: 0.6778 - val_recall_14: 0.5496\n",
      "Epoch 59/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0606 - precision_14: 0.8444 - recall_14: 0.6483 \n",
      "Epoch 59: val_loss improved from 0.10197 to 0.10195, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0597 - precision_14: 0.8420 - recall_14: 0.6563 - val_loss: 0.1020 - val_precision_14: 0.6711 - val_recall_14: 0.5591\n",
      "Epoch 60/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0594 - precision_14: 0.8131 - recall_14: 0.6818 \n",
      "Epoch 60: val_loss did not improve from 0.10195\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0588 - precision_14: 0.8160 - recall_14: 0.6795 - val_loss: 0.1029 - val_precision_14: 0.6783 - val_recall_14: 0.5629\n",
      "Epoch 61/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0601 - precision_14: 0.8263 - recall_14: 0.6674 \n",
      "Epoch 61: val_loss did not improve from 0.10195\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0595 - precision_14: 0.8281 - recall_14: 0.6689 - val_loss: 0.1031 - val_precision_14: 0.6717 - val_recall_14: 0.5642\n",
      "Epoch 62/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0569 - precision_14: 0.8383 - recall_14: 0.6910 \n",
      "Epoch 62: val_loss improved from 0.10195 to 0.10126, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0572 - precision_14: 0.8323 - recall_14: 0.6888 - val_loss: 0.1013 - val_precision_14: 0.6887 - val_recall_14: 0.5601\n",
      "Epoch 63/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0567 - precision_14: 0.8466 - recall_14: 0.6770 \n",
      "Epoch 63: val_loss improved from 0.10126 to 0.10081, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0565 - precision_14: 0.8439 - recall_14: 0.6761 - val_loss: 0.1008 - val_precision_14: 0.6823 - val_recall_14: 0.5773\n",
      "Epoch 64/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0582 - precision_14: 0.8335 - recall_14: 0.6875 \n",
      "Epoch 64: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0575 - precision_14: 0.8296 - recall_14: 0.6897 - val_loss: 0.1020 - val_precision_14: 0.6768 - val_recall_14: 0.5820\n",
      "Epoch 65/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0566 - precision_14: 0.8410 - recall_14: 0.6818 \n",
      "Epoch 65: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0567 - precision_14: 0.8369 - recall_14: 0.6814 - val_loss: 0.1021 - val_precision_14: 0.6724 - val_recall_14: 0.5825\n",
      "Epoch 66/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0551 - precision_14: 0.8361 - recall_14: 0.6957 \n",
      "Epoch 66: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0547 - precision_14: 0.8358 - recall_14: 0.6988 - val_loss: 0.1013 - val_precision_14: 0.6852 - val_recall_14: 0.5755\n",
      "Epoch 67/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0536 - precision_14: 0.8650 - recall_14: 0.6929 \n",
      "Epoch 67: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0540 - precision_14: 0.8581 - recall_14: 0.6884 - val_loss: 0.1018 - val_precision_14: 0.6696 - val_recall_14: 0.5866\n",
      "Epoch 68/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0559 - precision_14: 0.8320 - recall_14: 0.6976 \n",
      "Epoch 68: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0551 - precision_14: 0.8320 - recall_14: 0.7012 - val_loss: 0.1014 - val_precision_14: 0.6755 - val_recall_14: 0.5894\n",
      "Epoch 69/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0560 - precision_14: 0.8394 - recall_14: 0.6855 \n",
      "Epoch 69: val_loss did not improve from 0.10081\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0557 - precision_14: 0.8362 - recall_14: 0.6887 - val_loss: 0.1018 - val_precision_14: 0.6729 - val_recall_14: 0.5811\n",
      "Epoch 70/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0545 - precision_14: 0.8390 - recall_14: 0.7073 \n",
      "Epoch 70: val_loss improved from 0.10081 to 0.10062, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0539 - precision_14: 0.8407 - recall_14: 0.7058 - val_loss: 0.1006 - val_precision_14: 0.6805 - val_recall_14: 0.5878\n",
      "Epoch 71/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0542 - precision_14: 0.8475 - recall_14: 0.6950 \n",
      "Epoch 71: val_loss did not improve from 0.10062\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0537 - precision_14: 0.8445 - recall_14: 0.7028 - val_loss: 0.1019 - val_precision_14: 0.6852 - val_recall_14: 0.5816\n",
      "Epoch 72/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0574 - precision_14: 0.8430 - recall_14: 0.6739 \n",
      "Epoch 72: val_loss did not improve from 0.10062\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0561 - precision_14: 0.8427 - recall_14: 0.6833 - val_loss: 0.1019 - val_precision_14: 0.6784 - val_recall_14: 0.5861\n",
      "Epoch 73/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0558 - precision_14: 0.8307 - recall_14: 0.7005 \n",
      "Epoch 73: val_loss improved from 0.10062 to 0.10058, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0546 - precision_14: 0.8310 - recall_14: 0.7057 - val_loss: 0.1006 - val_precision_14: 0.6887 - val_recall_14: 0.5904\n",
      "Epoch 74/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0543 - precision_14: 0.8537 - recall_14: 0.6994 \n",
      "Epoch 74: val_loss did not improve from 0.10058\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0531 - precision_14: 0.8520 - recall_14: 0.7062 - val_loss: 0.1008 - val_precision_14: 0.6831 - val_recall_14: 0.5987\n",
      "Epoch 75/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0527 - precision_14: 0.8359 - recall_14: 0.7139\n",
      "Epoch 75: val_loss improved from 0.10058 to 0.10012, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0525 - precision_14: 0.8366 - recall_14: 0.7147 - val_loss: 0.1001 - val_precision_14: 0.6827 - val_recall_14: 0.5966\n",
      "Epoch 76/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0550 - precision_14: 0.8471 - recall_14: 0.6808 \n",
      "Epoch 76: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0534 - precision_14: 0.8463 - recall_14: 0.6970 - val_loss: 0.1007 - val_precision_14: 0.6774 - val_recall_14: 0.6000\n",
      "Epoch 77/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0518 - precision_14: 0.8555 - recall_14: 0.7143 \n",
      "Epoch 77: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0516 - precision_14: 0.8508 - recall_14: 0.7165 - val_loss: 0.1029 - val_precision_14: 0.6720 - val_recall_14: 0.6022\n",
      "Epoch 78/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0523 - precision_14: 0.8434 - recall_14: 0.7107 \n",
      "Epoch 78: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0514 - precision_14: 0.8452 - recall_14: 0.7178 - val_loss: 0.1017 - val_precision_14: 0.6717 - val_recall_14: 0.5990\n",
      "Epoch 79/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0512 - precision_14: 0.8530 - recall_14: 0.7147 \n",
      "Epoch 79: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0511 - precision_14: 0.8515 - recall_14: 0.7143 - val_loss: 0.1016 - val_precision_14: 0.6707 - val_recall_14: 0.6103\n",
      "Epoch 80/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0541 - precision_14: 0.8357 - recall_14: 0.7123 \n",
      "Epoch 80: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0533 - precision_14: 0.8350 - recall_14: 0.7161 - val_loss: 0.1004 - val_precision_14: 0.6784 - val_recall_14: 0.6050\n",
      "Epoch 81/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0526 - precision_14: 0.8345 - recall_14: 0.7273 \n",
      "Epoch 81: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0517 - precision_14: 0.8403 - recall_14: 0.7262 - val_loss: 0.1008 - val_precision_14: 0.6795 - val_recall_14: 0.5984\n",
      "Epoch 82/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0517 - precision_14: 0.8499 - recall_14: 0.7153 \n",
      "Epoch 82: val_loss did not improve from 0.10012\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0515 - precision_14: 0.8485 - recall_14: 0.7169 - val_loss: 0.1001 - val_precision_14: 0.6765 - val_recall_14: 0.6032\n",
      "Epoch 83/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0503 - precision_14: 0.8497 - recall_14: 0.7175 \n",
      "Epoch 83: val_loss improved from 0.10012 to 0.10000, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0500 - precision_14: 0.8477 - recall_14: 0.7222 - val_loss: 0.1000 - val_precision_14: 0.6764 - val_recall_14: 0.6048\n",
      "Epoch 84/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0498 - precision_14: 0.8608 - recall_14: 0.7197 \n",
      "Epoch 84: val_loss did not improve from 0.10000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0498 - precision_14: 0.8575 - recall_14: 0.7221 - val_loss: 0.1007 - val_precision_14: 0.6787 - val_recall_14: 0.6068\n",
      "Epoch 85/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0494 - precision_14: 0.8617 - recall_14: 0.7387 \n",
      "Epoch 85: val_loss did not improve from 0.10000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0493 - precision_14: 0.8603 - recall_14: 0.7352 - val_loss: 0.1007 - val_precision_14: 0.6802 - val_recall_14: 0.6063\n",
      "Epoch 86/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0479 - precision_14: 0.8697 - recall_14: 0.7465 \n",
      "Epoch 86: val_loss did not improve from 0.10000\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0477 - precision_14: 0.8641 - recall_14: 0.7463 - val_loss: 0.1015 - val_precision_14: 0.6789 - val_recall_14: 0.6077\n",
      "Epoch 87/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0497 - precision_14: 0.8456 - recall_14: 0.7290\n",
      "Epoch 87: val_loss improved from 0.10000 to 0.09935, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0496 - precision_14: 0.8445 - recall_14: 0.7308 - val_loss: 0.0993 - val_precision_14: 0.6809 - val_recall_14: 0.6045\n",
      "Epoch 88/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0478 - precision_14: 0.8623 - recall_14: 0.7408 \n",
      "Epoch 88: val_loss did not improve from 0.09935\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0475 - precision_14: 0.8615 - recall_14: 0.7411 - val_loss: 0.0999 - val_precision_14: 0.6717 - val_recall_14: 0.6072\n",
      "Epoch 89/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0497 - precision_14: 0.8581 - recall_14: 0.7317 \n",
      "Epoch 89: val_loss did not improve from 0.09935\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0496 - precision_14: 0.8531 - recall_14: 0.7320 - val_loss: 0.1000 - val_precision_14: 0.6676 - val_recall_14: 0.6164\n",
      "Epoch 90/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0499 - precision_14: 0.8503 - recall_14: 0.7374 \n",
      "Epoch 90: val_loss improved from 0.09935 to 0.09837, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0489 - precision_14: 0.8506 - recall_14: 0.7403 - val_loss: 0.0984 - val_precision_14: 0.6796 - val_recall_14: 0.6100\n",
      "Epoch 91/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0484 - precision_14: 0.8578 - recall_14: 0.7359 \n",
      "Epoch 91: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0479 - precision_14: 0.8558 - recall_14: 0.7396 - val_loss: 0.0987 - val_precision_14: 0.6865 - val_recall_14: 0.6113\n",
      "Epoch 92/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0467 - precision_14: 0.8620 - recall_14: 0.7415 \n",
      "Epoch 92: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0466 - precision_14: 0.8589 - recall_14: 0.7447 - val_loss: 0.0999 - val_precision_14: 0.6731 - val_recall_14: 0.6198\n",
      "Epoch 93/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0486 - precision_14: 0.8606 - recall_14: 0.7348 \n",
      "Epoch 93: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0481 - precision_14: 0.8576 - recall_14: 0.7383 - val_loss: 0.0989 - val_precision_14: 0.6787 - val_recall_14: 0.6120\n",
      "Epoch 94/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0449 - precision_14: 0.8790 - recall_14: 0.7447 \n",
      "Epoch 94: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0453 - precision_14: 0.8740 - recall_14: 0.7445 - val_loss: 0.1002 - val_precision_14: 0.6715 - val_recall_14: 0.6176\n",
      "Epoch 95/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0497 - precision_14: 0.8465 - recall_14: 0.7391 \n",
      "Epoch 95: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0489 - precision_14: 0.8464 - recall_14: 0.7422 - val_loss: 0.0991 - val_precision_14: 0.6746 - val_recall_14: 0.6148\n",
      "Epoch 96/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0469 - precision_14: 0.8519 - recall_14: 0.7495 \n",
      "Epoch 96: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0461 - precision_14: 0.8531 - recall_14: 0.7534 - val_loss: 0.0985 - val_precision_14: 0.6851 - val_recall_14: 0.6130\n",
      "Epoch 97/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0483 - precision_14: 0.8508 - recall_14: 0.7452 \n",
      "Epoch 97: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0474 - precision_14: 0.8540 - recall_14: 0.7474 - val_loss: 0.0995 - val_precision_14: 0.6756 - val_recall_14: 0.6111\n",
      "Epoch 98/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0452 - precision_14: 0.8690 - recall_14: 0.7640 \n",
      "Epoch 98: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0454 - precision_14: 0.8648 - recall_14: 0.7601 - val_loss: 0.0987 - val_precision_14: 0.6779 - val_recall_14: 0.6151\n",
      "Epoch 99/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0430 - precision_14: 0.8717 - recall_14: 0.7735 \n",
      "Epoch 99: val_loss improved from 0.09837 to 0.09822, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0430 - precision_14: 0.8686 - recall_14: 0.7729 - val_loss: 0.0982 - val_precision_14: 0.6776 - val_recall_14: 0.6174\n",
      "Epoch 100/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0446 - precision_14: 0.8692 - recall_14: 0.7630 \n",
      "Epoch 100: val_loss did not improve from 0.09822\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0445 - precision_14: 0.8657 - recall_14: 0.7620 - val_loss: 0.0988 - val_precision_14: 0.6802 - val_recall_14: 0.6143\n",
      "Epoch 101/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0468 - precision_14: 0.8630 - recall_14: 0.7505 \n",
      "Epoch 101: val_loss did not improve from 0.09822\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0460 - precision_14: 0.8631 - recall_14: 0.7519 - val_loss: 0.0985 - val_precision_14: 0.6766 - val_recall_14: 0.6193\n",
      "Epoch 102/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0446 - precision_14: 0.8668 - recall_14: 0.7622 \n",
      "Epoch 102: val_loss improved from 0.09822 to 0.09700, saving model to 62sec_2layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0446 - precision_14: 0.8644 - recall_14: 0.7628 - val_loss: 0.0970 - val_precision_14: 0.6752 - val_recall_14: 0.6181\n",
      "Epoch 103/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0483 - precision_14: 0.8546 - recall_14: 0.7520 \n",
      "Epoch 103: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0469 - precision_14: 0.8567 - recall_14: 0.7586 - val_loss: 0.0974 - val_precision_14: 0.6776 - val_recall_14: 0.6183\n",
      "Epoch 104/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0460 - precision_14: 0.8720 - recall_14: 0.7440 \n",
      "Epoch 104: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0453 - precision_14: 0.8683 - recall_14: 0.7496 - val_loss: 0.0971 - val_precision_14: 0.6796 - val_recall_14: 0.6174\n",
      "Epoch 105/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0441 - precision_14: 0.8517 - recall_14: 0.7779 \n",
      "Epoch 105: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0438 - precision_14: 0.8568 - recall_14: 0.7745 - val_loss: 0.0986 - val_precision_14: 0.6807 - val_recall_14: 0.6138\n",
      "Epoch 106/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0433 - precision_14: 0.8765 - recall_14: 0.7640 \n",
      "Epoch 106: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0436 - precision_14: 0.8725 - recall_14: 0.7629 - val_loss: 0.0995 - val_precision_14: 0.6671 - val_recall_14: 0.6295\n",
      "Epoch 107/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0448 - precision_14: 0.8581 - recall_14: 0.7718 \n",
      "Epoch 107: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0444 - precision_14: 0.8568 - recall_14: 0.7720 - val_loss: 0.0985 - val_precision_14: 0.6728 - val_recall_14: 0.6295\n",
      "Epoch 108/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0437 - precision_14: 0.8568 - recall_14: 0.7706 \n",
      "Epoch 108: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0433 - precision_14: 0.8576 - recall_14: 0.7713 - val_loss: 0.0981 - val_precision_14: 0.6784 - val_recall_14: 0.6237\n",
      "Epoch 109/200\n",
      "\u001b[1m 7/15\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0449 - precision_14: 0.8698 - recall_14: 0.7672 \n",
      "Epoch 109: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0439 - precision_14: 0.8663 - recall_14: 0.7700 - val_loss: 0.0979 - val_precision_14: 0.6808 - val_recall_14: 0.6204\n",
      "Epoch 110/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0456 - precision_14: 0.8604 - recall_14: 0.7526 \n",
      "Epoch 110: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0456 - precision_14: 0.8586 - recall_14: 0.7553 - val_loss: 0.0981 - val_precision_14: 0.6826 - val_recall_14: 0.6217\n",
      "Epoch 111/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0448 - precision_14: 0.8785 - recall_14: 0.7560 \n",
      "Epoch 111: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0441 - precision_14: 0.8753 - recall_14: 0.7623 - val_loss: 0.0979 - val_precision_14: 0.6788 - val_recall_14: 0.6242\n",
      "Epoch 112/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0442 - precision_14: 0.8737 - recall_14: 0.7629 \n",
      "Epoch 112: val_loss did not improve from 0.09700\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0436 - precision_14: 0.8713 - recall_14: 0.7662 - val_loss: 0.0982 - val_precision_14: 0.6735 - val_recall_14: 0.6329\n",
      "Epoch 112: early stopping\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - precision_14: 0.9650 - recall_14: 0.9327\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0993 - precision_14: 0.6687 - recall_14: 0.6150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1082 - precision_14: 0.6611 - recall_14: 0.5796\n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5463 - precision_15: 0.0528 - recall_15: 0.2353\n",
      "Epoch 1: val_loss improved from inf to 0.21084, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.5194 - precision_15: 0.0529 - recall_15: 0.2092 - val_loss: 0.2108 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2317 - precision_15: 0.1630 - recall_15: 0.0364\n",
      "Epoch 2: val_loss improved from 0.21084 to 0.20550, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2311 - precision_15: 0.1632 - recall_15: 0.0360 - val_loss: 0.2055 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2066 - precision_15: 0.2619 - recall_15: 7.7286e-04 \n",
      "Epoch 3: val_loss improved from 0.20550 to 0.17850, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2037 - precision_15: 0.2801 - recall_15: 0.0011 - val_loss: 0.1785 - val_precision_15: 0.0000e+00 - val_recall_15: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1731 - precision_15: 0.4543 - recall_15: 0.0033 \n",
      "Epoch 4: val_loss improved from 0.17850 to 0.17424, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1721 - precision_15: 0.4514 - recall_15: 0.0039 - val_loss: 0.1742 - val_precision_15: 0.5769 - val_recall_15: 0.0050\n",
      "Epoch 5/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1557 - precision_15: 0.5030 - recall_15: 0.0268\n",
      "Epoch 5: val_loss improved from 0.17424 to 0.15686, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1550 - precision_15: 0.5019 - recall_15: 0.0271 - val_loss: 0.1569 - val_precision_15: 0.4990 - val_recall_15: 0.0404\n",
      "Epoch 6/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1421 - precision_15: 0.4957 - recall_15: 0.0837\n",
      "Epoch 6: val_loss improved from 0.15686 to 0.14671, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1417 - precision_15: 0.5000 - recall_15: 0.0839 - val_loss: 0.1467 - val_precision_15: 0.5452 - val_recall_15: 0.0380\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1333 - precision_15: 0.5779 - recall_15: 0.1167\n",
      "Epoch 7: val_loss improved from 0.14671 to 0.14344, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1326 - precision_15: 0.5789 - recall_15: 0.1221 - val_loss: 0.1434 - val_precision_15: 0.5853 - val_recall_15: 0.0489\n",
      "Epoch 8/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1258 - precision_15: 0.6685 - recall_15: 0.1201\n",
      "Epoch 8: val_loss improved from 0.14344 to 0.14022, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1247 - precision_15: 0.6664 - recall_15: 0.1360 - val_loss: 0.1402 - val_precision_15: 0.5671 - val_recall_15: 0.1653\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1128 - precision_15: 0.7297 - recall_15: 0.2261\n",
      "Epoch 9: val_loss improved from 0.14022 to 0.14012, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1122 - precision_15: 0.7311 - recall_15: 0.2296 - val_loss: 0.1401 - val_precision_15: 0.5380 - val_recall_15: 0.2945\n",
      "Epoch 10/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1042 - precision_15: 0.7067 - recall_15: 0.3629\n",
      "Epoch 10: val_loss improved from 0.14012 to 0.13093, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1033 - precision_15: 0.7157 - recall_15: 0.3542 - val_loss: 0.1309 - val_precision_15: 0.5877 - val_recall_15: 0.2889\n",
      "Epoch 11/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0928 - precision_15: 0.7705 - recall_15: 0.4302\n",
      "Epoch 11: val_loss improved from 0.13093 to 0.12232, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0920 - precision_15: 0.7722 - recall_15: 0.4314 - val_loss: 0.1223 - val_precision_15: 0.6765 - val_recall_15: 0.2624\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0837 - precision_15: 0.8224 - recall_15: 0.4443\n",
      "Epoch 12: val_loss improved from 0.12232 to 0.11742, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0829 - precision_15: 0.8142 - recall_15: 0.4635 - val_loss: 0.1174 - val_precision_15: 0.6719 - val_recall_15: 0.3221\n",
      "Epoch 13/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0755 - precision_15: 0.8443 - recall_15: 0.5032\n",
      "Epoch 13: val_loss improved from 0.11742 to 0.11638, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0750 - precision_15: 0.8396 - recall_15: 0.5113 - val_loss: 0.1164 - val_precision_15: 0.6544 - val_recall_15: 0.4407\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0673 - precision_15: 0.8480 - recall_15: 0.6189\n",
      "Epoch 14: val_loss improved from 0.11638 to 0.11253, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0669 - precision_15: 0.8528 - recall_15: 0.6105 - val_loss: 0.1125 - val_precision_15: 0.6545 - val_recall_15: 0.4817\n",
      "Epoch 15/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0618 - precision_15: 0.8423 - recall_15: 0.6806 \n",
      "Epoch 15: val_loss improved from 0.11253 to 0.10840, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0614 - precision_15: 0.8447 - recall_15: 0.6754 - val_loss: 0.1084 - val_precision_15: 0.7125 - val_recall_15: 0.4412\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0570 - precision_15: 0.8743 - recall_15: 0.6588\n",
      "Epoch 16: val_loss did not improve from 0.10840\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0567 - precision_15: 0.8722 - recall_15: 0.6639 - val_loss: 0.1103 - val_precision_15: 0.7071 - val_recall_15: 0.4770\n",
      "Epoch 17/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0534 - precision_15: 0.8827 - recall_15: 0.6751\n",
      "Epoch 17: val_loss improved from 0.10840 to 0.10709, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0531 - precision_15: 0.8812 - recall_15: 0.6781 - val_loss: 0.1071 - val_precision_15: 0.6921 - val_recall_15: 0.5271\n",
      "Epoch 18/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0497 - precision_15: 0.8823 - recall_15: 0.7253\n",
      "Epoch 18: val_loss improved from 0.10709 to 0.10544, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0493 - precision_15: 0.8833 - recall_15: 0.7233 - val_loss: 0.1054 - val_precision_15: 0.7028 - val_recall_15: 0.5480\n",
      "Epoch 19/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0468 - precision_15: 0.8793 - recall_15: 0.7477 \n",
      "Epoch 19: val_loss improved from 0.10544 to 0.10386, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0464 - precision_15: 0.8808 - recall_15: 0.7471 - val_loss: 0.1039 - val_precision_15: 0.7130 - val_recall_15: 0.5472\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0438 - precision_15: 0.8927 - recall_15: 0.7586\n",
      "Epoch 20: val_loss did not improve from 0.10386\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0433 - precision_15: 0.8922 - recall_15: 0.7603 - val_loss: 0.1041 - val_precision_15: 0.7167 - val_recall_15: 0.5448\n",
      "Epoch 21/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0403 - precision_15: 0.9059 - recall_15: 0.7737\n",
      "Epoch 21: val_loss improved from 0.10386 to 0.10345, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0401 - precision_15: 0.9052 - recall_15: 0.7754 - val_loss: 0.1034 - val_precision_15: 0.7060 - val_recall_15: 0.5712\n",
      "Epoch 22/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0383 - precision_15: 0.9071 - recall_15: 0.7966\n",
      "Epoch 22: val_loss improved from 0.10345 to 0.10327, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0379 - precision_15: 0.9083 - recall_15: 0.7966 - val_loss: 0.1033 - val_precision_15: 0.7116 - val_recall_15: 0.5800\n",
      "Epoch 23/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0353 - precision_15: 0.9193 - recall_15: 0.8074\n",
      "Epoch 23: val_loss improved from 0.10327 to 0.10306, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0351 - precision_15: 0.9189 - recall_15: 0.8088 - val_loss: 0.1031 - val_precision_15: 0.7044 - val_recall_15: 0.5944\n",
      "Epoch 24/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0340 - precision_15: 0.9142 - recall_15: 0.8186\n",
      "Epoch 24: val_loss improved from 0.10306 to 0.10232, saving model to 62sec_2layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0338 - precision_15: 0.9149 - recall_15: 0.8193 - val_loss: 0.1023 - val_precision_15: 0.7137 - val_recall_15: 0.5868\n",
      "Epoch 25/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0319 - precision_15: 0.9205 - recall_15: 0.8332\n",
      "Epoch 25: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0316 - precision_15: 0.9203 - recall_15: 0.8343 - val_loss: 0.1053 - val_precision_15: 0.7117 - val_recall_15: 0.6029\n",
      "Epoch 26/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0302 - precision_15: 0.9269 - recall_15: 0.8411\n",
      "Epoch 26: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0300 - precision_15: 0.9269 - recall_15: 0.8421 - val_loss: 0.1040 - val_precision_15: 0.7162 - val_recall_15: 0.6083\n",
      "Epoch 27/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0292 - precision_15: 0.9291 - recall_15: 0.8404\n",
      "Epoch 27: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0286 - precision_15: 0.9286 - recall_15: 0.8458 - val_loss: 0.1056 - val_precision_15: 0.7288 - val_recall_15: 0.6048\n",
      "Epoch 28/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0279 - precision_15: 0.9294 - recall_15: 0.8562\n",
      "Epoch 28: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0276 - precision_15: 0.9298 - recall_15: 0.8564 - val_loss: 0.1037 - val_precision_15: 0.7085 - val_recall_15: 0.6179\n",
      "Epoch 29/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0255 - precision_15: 0.9301 - recall_15: 0.8715\n",
      "Epoch 29: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0253 - precision_15: 0.9313 - recall_15: 0.8713 - val_loss: 0.1055 - val_precision_15: 0.7208 - val_recall_15: 0.6242\n",
      "Epoch 30/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0241 - precision_15: 0.9368 - recall_15: 0.8826\n",
      "Epoch 30: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - precision_15: 0.9366 - recall_15: 0.8820 - val_loss: 0.1057 - val_precision_15: 0.7277 - val_recall_15: 0.6249\n",
      "Epoch 31/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0234 - precision_15: 0.9408 - recall_15: 0.8783\n",
      "Epoch 31: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0233 - precision_15: 0.9405 - recall_15: 0.8796 - val_loss: 0.1060 - val_precision_15: 0.7225 - val_recall_15: 0.6252\n",
      "Epoch 32/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0225 - precision_15: 0.9373 - recall_15: 0.8890\n",
      "Epoch 32: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0223 - precision_15: 0.9375 - recall_15: 0.8898 - val_loss: 0.1085 - val_precision_15: 0.7342 - val_recall_15: 0.6290\n",
      "Epoch 33/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0218 - precision_15: 0.9397 - recall_15: 0.8936\n",
      "Epoch 33: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0216 - precision_15: 0.9402 - recall_15: 0.8945 - val_loss: 0.1092 - val_precision_15: 0.7204 - val_recall_15: 0.6358\n",
      "Epoch 34/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0213 - precision_15: 0.9448 - recall_15: 0.8966\n",
      "Epoch 34: val_loss did not improve from 0.10232\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0211 - precision_15: 0.9455 - recall_15: 0.8972 - val_loss: 0.1070 - val_precision_15: 0.7192 - val_recall_15: 0.6418\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0184 - precision_15: 0.9694 - recall_15: 0.9200 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1033 - precision_15: 0.7052 - recall_15: 0.5797 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1120 - precision_15: 0.7069 - recall_15: 0.5654 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5706 - precision_16: 0.0501 - recall_16: 0.2611\n",
      "Epoch 1: val_loss improved from inf to 0.21678, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.5436 - precision_16: 0.0501 - recall_16: 0.2327 - val_loss: 0.2168 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2365 - precision_16: 0.1660 - recall_16: 0.0302\n",
      "Epoch 2: val_loss improved from 0.21678 to 0.19639, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2347 - precision_16: 0.1667 - recall_16: 0.0312 - val_loss: 0.1964 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2094 - precision_16: 0.1949 - recall_16: 0.0021\n",
      "Epoch 3: val_loss improved from 0.19639 to 0.18662, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2061 - precision_16: 0.2196 - recall_16: 0.0024 - val_loss: 0.1866 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1777 - precision_16: 0.3324 - recall_16: 0.0037\n",
      "Epoch 4: val_loss improved from 0.18662 to 0.17321, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1764 - precision_16: 0.3379 - recall_16: 0.0038 - val_loss: 0.1732 - val_precision_16: 0.0000e+00 - val_recall_16: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1606 - precision_16: 0.4862 - recall_16: 0.0155\n",
      "Epoch 5: val_loss improved from 0.17321 to 0.15366, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1599 - precision_16: 0.4868 - recall_16: 0.0160 - val_loss: 0.1537 - val_precision_16: 0.5250 - val_recall_16: 0.0070\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1487 - precision_16: 0.4878 - recall_16: 0.0518\n",
      "Epoch 6: val_loss improved from 0.15366 to 0.14783, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1478 - precision_16: 0.4906 - recall_16: 0.0545 - val_loss: 0.1478 - val_precision_16: 0.4978 - val_recall_16: 0.0189\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1419 - precision_16: 0.4970 - recall_16: 0.0698\n",
      "Epoch 7: val_loss improved from 0.14783 to 0.14516, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1412 - precision_16: 0.4995 - recall_16: 0.0764 - val_loss: 0.1452 - val_precision_16: 0.5656 - val_recall_16: 0.0850\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1332 - precision_16: 0.5564 - recall_16: 0.1016\n",
      "Epoch 8: val_loss did not improve from 0.14516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1321 - precision_16: 0.5628 - recall_16: 0.1065 - val_loss: 0.1524 - val_precision_16: 0.5204 - val_recall_16: 0.1755\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1247 - precision_16: 0.6230 - recall_16: 0.1912\n",
      "Epoch 9: val_loss improved from 0.14516 to 0.13730, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1240 - precision_16: 0.6293 - recall_16: 0.1883 - val_loss: 0.1373 - val_precision_16: 0.5626 - val_recall_16: 0.1669\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1139 - precision_16: 0.6874 - recall_16: 0.2607\n",
      "Epoch 10: val_loss improved from 0.13730 to 0.13103, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1133 - precision_16: 0.6886 - recall_16: 0.2626 - val_loss: 0.1310 - val_precision_16: 0.6088 - val_recall_16: 0.1507\n",
      "Epoch 11/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1070 - precision_16: 0.7528 - recall_16: 0.2705\n",
      "Epoch 11: val_loss improved from 0.13103 to 0.12808, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1057 - precision_16: 0.7478 - recall_16: 0.2883 - val_loss: 0.1281 - val_precision_16: 0.5980 - val_recall_16: 0.2624\n",
      "Epoch 12/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0964 - precision_16: 0.7828 - recall_16: 0.3498\n",
      "Epoch 12: val_loss improved from 0.12808 to 0.12572, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0957 - precision_16: 0.7816 - recall_16: 0.3576 - val_loss: 0.1257 - val_precision_16: 0.6242 - val_recall_16: 0.3400\n",
      "Epoch 13/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0893 - precision_16: 0.7727 - recall_16: 0.4395\n",
      "Epoch 13: val_loss improved from 0.12572 to 0.11927, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0887 - precision_16: 0.7763 - recall_16: 0.4367 - val_loss: 0.1193 - val_precision_16: 0.6355 - val_recall_16: 0.3483\n",
      "Epoch 14/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0816 - precision_16: 0.8015 - recall_16: 0.5035\n",
      "Epoch 14: val_loss improved from 0.11927 to 0.11606, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0812 - precision_16: 0.8005 - recall_16: 0.5025 - val_loss: 0.1161 - val_precision_16: 0.6517 - val_recall_16: 0.3771\n",
      "Epoch 15/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0766 - precision_16: 0.8141 - recall_16: 0.5233\n",
      "Epoch 15: val_loss improved from 0.11606 to 0.11306, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0762 - precision_16: 0.8130 - recall_16: 0.5281 - val_loss: 0.1131 - val_precision_16: 0.6709 - val_recall_16: 0.4112\n",
      "Epoch 16/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0706 - precision_16: 0.8351 - recall_16: 0.5649\n",
      "Epoch 16: val_loss improved from 0.11306 to 0.11116, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0704 - precision_16: 0.8322 - recall_16: 0.5657 - val_loss: 0.1112 - val_precision_16: 0.6681 - val_recall_16: 0.4678\n",
      "Epoch 17/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0667 - precision_16: 0.8335 - recall_16: 0.6053\n",
      "Epoch 17: val_loss improved from 0.11116 to 0.10862, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0665 - precision_16: 0.8342 - recall_16: 0.6046 - val_loss: 0.1086 - val_precision_16: 0.6932 - val_recall_16: 0.4697\n",
      "Epoch 18/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0644 - precision_16: 0.8382 - recall_16: 0.6246\n",
      "Epoch 18: val_loss did not improve from 0.10862\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0640 - precision_16: 0.8380 - recall_16: 0.6266 - val_loss: 0.1090 - val_precision_16: 0.6889 - val_recall_16: 0.4782\n",
      "Epoch 19/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0610 - precision_16: 0.8537 - recall_16: 0.6321\n",
      "Epoch 19: val_loss improved from 0.10862 to 0.10607, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0606 - precision_16: 0.8510 - recall_16: 0.6361 - val_loss: 0.1061 - val_precision_16: 0.6975 - val_recall_16: 0.4961\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0579 - precision_16: 0.8560 - recall_16: 0.6652\n",
      "Epoch 20: val_loss did not improve from 0.10607\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0574 - precision_16: 0.8558 - recall_16: 0.6678 - val_loss: 0.1069 - val_precision_16: 0.6774 - val_recall_16: 0.5221\n",
      "Epoch 21/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0553 - precision_16: 0.8507 - recall_16: 0.6953\n",
      "Epoch 21: val_loss improved from 0.10607 to 0.10338, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0547 - precision_16: 0.8529 - recall_16: 0.6950 - val_loss: 0.1034 - val_precision_16: 0.6864 - val_recall_16: 0.5243\n",
      "Epoch 22/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0499 - precision_16: 0.8761 - recall_16: 0.7096\n",
      "Epoch 22: val_loss improved from 0.10338 to 0.10322, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0498 - precision_16: 0.8751 - recall_16: 0.7109 - val_loss: 0.1032 - val_precision_16: 0.6917 - val_recall_16: 0.5365\n",
      "Epoch 23/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0481 - precision_16: 0.8827 - recall_16: 0.7245\n",
      "Epoch 23: val_loss improved from 0.10322 to 0.10242, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0479 - precision_16: 0.8814 - recall_16: 0.7258 - val_loss: 0.1024 - val_precision_16: 0.7029 - val_recall_16: 0.5430\n",
      "Epoch 24/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0461 - precision_16: 0.8858 - recall_16: 0.7343\n",
      "Epoch 24: val_loss improved from 0.10242 to 0.10226, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0460 - precision_16: 0.8844 - recall_16: 0.7353 - val_loss: 0.1023 - val_precision_16: 0.6822 - val_recall_16: 0.5690\n",
      "Epoch 25/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0446 - precision_16: 0.8847 - recall_16: 0.7539 \n",
      "Epoch 25: val_loss did not improve from 0.10226\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0443 - precision_16: 0.8847 - recall_16: 0.7554 - val_loss: 0.1024 - val_precision_16: 0.6884 - val_recall_16: 0.5397\n",
      "Epoch 26/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0428 - precision_16: 0.8965 - recall_16: 0.7581\n",
      "Epoch 26: val_loss did not improve from 0.10226\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0426 - precision_16: 0.8953 - recall_16: 0.7581 - val_loss: 0.1025 - val_precision_16: 0.6867 - val_recall_16: 0.5810\n",
      "Epoch 27/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0417 - precision_16: 0.8873 - recall_16: 0.7801\n",
      "Epoch 27: val_loss improved from 0.10226 to 0.10179, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0415 - precision_16: 0.8874 - recall_16: 0.7805 - val_loss: 0.1018 - val_precision_16: 0.7030 - val_recall_16: 0.5684\n",
      "Epoch 28/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0386 - precision_16: 0.9025 - recall_16: 0.7887\n",
      "Epoch 28: val_loss improved from 0.10179 to 0.10166, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0385 - precision_16: 0.9003 - recall_16: 0.7902 - val_loss: 0.1017 - val_precision_16: 0.7011 - val_recall_16: 0.5874\n",
      "Epoch 29/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0384 - precision_16: 0.9040 - recall_16: 0.7947\n",
      "Epoch 29: val_loss improved from 0.10166 to 0.10028, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0380 - precision_16: 0.9039 - recall_16: 0.7947 - val_loss: 0.1003 - val_precision_16: 0.7022 - val_recall_16: 0.5894\n",
      "Epoch 30/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0366 - precision_16: 0.9032 - recall_16: 0.7968\n",
      "Epoch 30: val_loss did not improve from 0.10028\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0364 - precision_16: 0.9028 - recall_16: 0.7991 - val_loss: 0.1004 - val_precision_16: 0.6952 - val_recall_16: 0.6012\n",
      "Epoch 31/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0344 - precision_16: 0.9066 - recall_16: 0.8159\n",
      "Epoch 31: val_loss improved from 0.10028 to 0.09997, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0342 - precision_16: 0.9056 - recall_16: 0.8169 - val_loss: 0.1000 - val_precision_16: 0.7043 - val_recall_16: 0.5984\n",
      "Epoch 32/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0346 - precision_16: 0.9091 - recall_16: 0.8134\n",
      "Epoch 32: val_loss improved from 0.09997 to 0.09976, saving model to 62sec_2layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - precision_16: 0.9091 - recall_16: 0.8152 - val_loss: 0.0998 - val_precision_16: 0.6883 - val_recall_16: 0.6065\n",
      "Epoch 33/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0320 - precision_16: 0.9099 - recall_16: 0.8269\n",
      "Epoch 33: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0319 - precision_16: 0.9095 - recall_16: 0.8290 - val_loss: 0.1003 - val_precision_16: 0.7055 - val_recall_16: 0.6106\n",
      "Epoch 34/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0321 - precision_16: 0.9184 - recall_16: 0.8257\n",
      "Epoch 34: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0318 - precision_16: 0.9177 - recall_16: 0.8274 - val_loss: 0.1001 - val_precision_16: 0.7027 - val_recall_16: 0.6193\n",
      "Epoch 35/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0296 - precision_16: 0.9238 - recall_16: 0.8480\n",
      "Epoch 35: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0295 - precision_16: 0.9218 - recall_16: 0.8498 - val_loss: 0.1001 - val_precision_16: 0.7074 - val_recall_16: 0.6204\n",
      "Epoch 36/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0292 - precision_16: 0.9214 - recall_16: 0.8450\n",
      "Epoch 36: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0290 - precision_16: 0.9213 - recall_16: 0.8459 - val_loss: 0.1019 - val_precision_16: 0.6887 - val_recall_16: 0.6274\n",
      "Epoch 37/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0284 - precision_16: 0.9200 - recall_16: 0.8562\n",
      "Epoch 37: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0282 - precision_16: 0.9206 - recall_16: 0.8559 - val_loss: 0.1026 - val_precision_16: 0.6934 - val_recall_16: 0.6284\n",
      "Epoch 38/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0275 - precision_16: 0.9236 - recall_16: 0.8604\n",
      "Epoch 38: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0274 - precision_16: 0.9232 - recall_16: 0.8605 - val_loss: 0.1036 - val_precision_16: 0.6965 - val_recall_16: 0.6333\n",
      "Epoch 39/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0280 - precision_16: 0.9193 - recall_16: 0.8599\n",
      "Epoch 39: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0275 - precision_16: 0.9202 - recall_16: 0.8625 - val_loss: 0.1045 - val_precision_16: 0.7010 - val_recall_16: 0.6373\n",
      "Epoch 40/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0247 - precision_16: 0.9334 - recall_16: 0.8734\n",
      "Epoch 40: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0248 - precision_16: 0.9324 - recall_16: 0.8726 - val_loss: 0.1041 - val_precision_16: 0.6966 - val_recall_16: 0.6438\n",
      "Epoch 41/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0251 - precision_16: 0.9316 - recall_16: 0.8749\n",
      "Epoch 41: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0251 - precision_16: 0.9311 - recall_16: 0.8737 - val_loss: 0.1017 - val_precision_16: 0.6983 - val_recall_16: 0.6461\n",
      "Epoch 42/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0238 - precision_16: 0.9281 - recall_16: 0.8853\n",
      "Epoch 42: val_loss did not improve from 0.09976\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0238 - precision_16: 0.9285 - recall_16: 0.8842 - val_loss: 0.1019 - val_precision_16: 0.7077 - val_recall_16: 0.6392\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0158 - precision_16: 0.9678 - recall_16: 0.9418 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1003 - precision_16: 0.6811 - recall_16: 0.6011 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1089 - precision_16: 0.6986 - recall_16: 0.5989\n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5618 - precision_17: 0.0522 - recall_17: 0.2657\n",
      "Epoch 1: val_loss improved from inf to 0.21638, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.5354 - precision_17: 0.0523 - recall_17: 0.2377 - val_loss: 0.2164 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2392 - precision_17: 0.1608 - recall_17: 0.0357\n",
      "Epoch 2: val_loss improved from 0.21638 to 0.19566, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2375 - precision_17: 0.1607 - recall_17: 0.0367 - val_loss: 0.1957 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2118 - precision_17: 0.1703 - recall_17: 0.0052\n",
      "Epoch 3: val_loss improved from 0.19566 to 0.18833, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2091 - precision_17: 0.1735 - recall_17: 0.0050 - val_loss: 0.1883 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1802 - precision_17: 0.3272 - recall_17: 0.0041\n",
      "Epoch 4: val_loss improved from 0.18833 to 0.17669, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1791 - precision_17: 0.3310 - recall_17: 0.0040 - val_loss: 0.1767 - val_precision_17: 0.0000e+00 - val_recall_17: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1681 - precision_17: 0.4091 - recall_17: 0.0074\n",
      "Epoch 5: val_loss improved from 0.17669 to 0.15760, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1666 - precision_17: 0.4154 - recall_17: 0.0077 - val_loss: 0.1576 - val_precision_17: 0.7500 - val_recall_17: 4.9727e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1546 - precision_17: 0.4686 - recall_17: 0.0256\n",
      "Epoch 6: val_loss improved from 0.15760 to 0.14975, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1543 - precision_17: 0.4683 - recall_17: 0.0262 - val_loss: 0.1497 - val_precision_17: 0.6339 - val_recall_17: 0.0118\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1481 - precision_17: 0.4911 - recall_17: 0.0497\n",
      "Epoch 7: val_loss improved from 0.14975 to 0.14969, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1473 - precision_17: 0.4920 - recall_17: 0.0539 - val_loss: 0.1497 - val_precision_17: 0.5218 - val_recall_17: 0.0635\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1394 - precision_17: 0.5128 - recall_17: 0.0811\n",
      "Epoch 8: val_loss did not improve from 0.14969\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1388 - precision_17: 0.5166 - recall_17: 0.0831 - val_loss: 0.1502 - val_precision_17: 0.5144 - val_recall_17: 0.1185\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1338 - precision_17: 0.5527 - recall_17: 0.1296\n",
      "Epoch 9: val_loss improved from 0.14969 to 0.13985, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1331 - precision_17: 0.5567 - recall_17: 0.1300 - val_loss: 0.1398 - val_precision_17: 0.5424 - val_recall_17: 0.1102\n",
      "Epoch 10/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1252 - precision_17: 0.6288 - recall_17: 0.1671\n",
      "Epoch 10: val_loss improved from 0.13985 to 0.13661, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1248 - precision_17: 0.6293 - recall_17: 0.1707 - val_loss: 0.1366 - val_precision_17: 0.5869 - val_recall_17: 0.1495\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1170 - precision_17: 0.6908 - recall_17: 0.1998\n",
      "Epoch 11: val_loss did not improve from 0.13661\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1165 - precision_17: 0.6903 - recall_17: 0.2071 - val_loss: 0.1369 - val_precision_17: 0.5709 - val_recall_17: 0.2541\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1110 - precision_17: 0.7112 - recall_17: 0.2790\n",
      "Epoch 12: val_loss improved from 0.13661 to 0.13117, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1104 - precision_17: 0.7146 - recall_17: 0.2801 - val_loss: 0.1312 - val_precision_17: 0.6250 - val_recall_17: 0.2738\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1037 - precision_17: 0.7251 - recall_17: 0.3339\n",
      "Epoch 13: val_loss improved from 0.13117 to 0.12576, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1033 - precision_17: 0.7251 - recall_17: 0.3360 - val_loss: 0.1258 - val_precision_17: 0.6312 - val_recall_17: 0.2947\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0971 - precision_17: 0.7582 - recall_17: 0.3836\n",
      "Epoch 14: val_loss improved from 0.12576 to 0.12204, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0970 - precision_17: 0.7559 - recall_17: 0.3854 - val_loss: 0.1220 - val_precision_17: 0.6306 - val_recall_17: 0.3282\n",
      "Epoch 15/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0918 - precision_17: 0.7686 - recall_17: 0.4192\n",
      "Epoch 15: val_loss improved from 0.12204 to 0.12004, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0914 - precision_17: 0.7674 - recall_17: 0.4221 - val_loss: 0.1200 - val_precision_17: 0.6575 - val_recall_17: 0.3580\n",
      "Epoch 16/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0883 - precision_17: 0.7729 - recall_17: 0.4438\n",
      "Epoch 16: val_loss improved from 0.12004 to 0.11787, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0879 - precision_17: 0.7732 - recall_17: 0.4476 - val_loss: 0.1179 - val_precision_17: 0.6414 - val_recall_17: 0.4030\n",
      "Epoch 17/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0818 - precision_17: 0.7895 - recall_17: 0.5105\n",
      "Epoch 17: val_loss improved from 0.11787 to 0.11565, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0818 - precision_17: 0.7882 - recall_17: 0.5079 - val_loss: 0.1156 - val_precision_17: 0.6745 - val_recall_17: 0.4139\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0778 - precision_17: 0.8019 - recall_17: 0.5281\n",
      "Epoch 18: val_loss improved from 0.11565 to 0.11236, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0776 - precision_17: 0.7977 - recall_17: 0.5277 - val_loss: 0.1124 - val_precision_17: 0.6747 - val_recall_17: 0.4455\n",
      "Epoch 19/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0759 - precision_17: 0.8063 - recall_17: 0.5388\n",
      "Epoch 19: val_loss improved from 0.11236 to 0.11070, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0755 - precision_17: 0.8059 - recall_17: 0.5416 - val_loss: 0.1107 - val_precision_17: 0.6703 - val_recall_17: 0.4691\n",
      "Epoch 20/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0736 - precision_17: 0.8039 - recall_17: 0.5571\n",
      "Epoch 20: val_loss improved from 0.11070 to 0.11051, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0731 - precision_17: 0.8036 - recall_17: 0.5607 - val_loss: 0.1105 - val_precision_17: 0.6698 - val_recall_17: 0.4797\n",
      "Epoch 21/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0701 - precision_17: 0.8104 - recall_17: 0.5911\n",
      "Epoch 21: val_loss improved from 0.11051 to 0.10711, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0700 - precision_17: 0.8110 - recall_17: 0.5894 - val_loss: 0.1071 - val_precision_17: 0.6844 - val_recall_17: 0.4789\n",
      "Epoch 22/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0677 - precision_17: 0.8281 - recall_17: 0.6028\n",
      "Epoch 22: val_loss did not improve from 0.10711\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0674 - precision_17: 0.8272 - recall_17: 0.6047 - val_loss: 0.1077 - val_precision_17: 0.6670 - val_recall_17: 0.5109\n",
      "Epoch 23/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0646 - precision_17: 0.8262 - recall_17: 0.6315\n",
      "Epoch 23: val_loss improved from 0.10711 to 0.10575, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0644 - precision_17: 0.8272 - recall_17: 0.6316 - val_loss: 0.1057 - val_precision_17: 0.6762 - val_recall_17: 0.5188\n",
      "Epoch 24/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0627 - precision_17: 0.8370 - recall_17: 0.6402\n",
      "Epoch 24: val_loss improved from 0.10575 to 0.10440, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0624 - precision_17: 0.8364 - recall_17: 0.6416 - val_loss: 0.1044 - val_precision_17: 0.6740 - val_recall_17: 0.5248\n",
      "Epoch 25/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0605 - precision_17: 0.8447 - recall_17: 0.6476\n",
      "Epoch 25: val_loss did not improve from 0.10440\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0602 - precision_17: 0.8439 - recall_17: 0.6496 - val_loss: 0.1049 - val_precision_17: 0.6690 - val_recall_17: 0.5334\n",
      "Epoch 26/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0593 - precision_17: 0.8363 - recall_17: 0.6631\n",
      "Epoch 26: val_loss improved from 0.10440 to 0.10310, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0591 - precision_17: 0.8354 - recall_17: 0.6645 - val_loss: 0.1031 - val_precision_17: 0.6858 - val_recall_17: 0.5453\n",
      "Epoch 27/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0563 - precision_17: 0.8575 - recall_17: 0.6757\n",
      "Epoch 27: val_loss improved from 0.10310 to 0.10212, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0561 - precision_17: 0.8570 - recall_17: 0.6755 - val_loss: 0.1021 - val_precision_17: 0.6826 - val_recall_17: 0.5528\n",
      "Epoch 28/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0546 - precision_17: 0.8564 - recall_17: 0.6893\n",
      "Epoch 28: val_loss did not improve from 0.10212\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0543 - precision_17: 0.8554 - recall_17: 0.6910 - val_loss: 0.1034 - val_precision_17: 0.6841 - val_recall_17: 0.5538\n",
      "Epoch 29/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0531 - precision_17: 0.8651 - recall_17: 0.7060\n",
      "Epoch 29: val_loss improved from 0.10212 to 0.10099, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0528 - precision_17: 0.8648 - recall_17: 0.7069 - val_loss: 0.1010 - val_precision_17: 0.6826 - val_recall_17: 0.5783\n",
      "Epoch 30/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0529 - precision_17: 0.8467 - recall_17: 0.7118\n",
      "Epoch 30: val_loss improved from 0.10099 to 0.10093, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0526 - precision_17: 0.8478 - recall_17: 0.7127 - val_loss: 0.1009 - val_precision_17: 0.6991 - val_recall_17: 0.5712\n",
      "Epoch 31/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0491 - precision_17: 0.8675 - recall_17: 0.7184\n",
      "Epoch 31: val_loss improved from 0.10093 to 0.10027, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0490 - precision_17: 0.8667 - recall_17: 0.7196 - val_loss: 0.1003 - val_precision_17: 0.6888 - val_recall_17: 0.5821\n",
      "Epoch 32/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0497 - precision_17: 0.8666 - recall_17: 0.7274\n",
      "Epoch 32: val_loss improved from 0.10027 to 0.09889, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0493 - precision_17: 0.8672 - recall_17: 0.7276 - val_loss: 0.0989 - val_precision_17: 0.6913 - val_recall_17: 0.5984\n",
      "Epoch 33/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0456 - precision_17: 0.8724 - recall_17: 0.7511 \n",
      "Epoch 33: val_loss did not improve from 0.09889\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0455 - precision_17: 0.8716 - recall_17: 0.7520 - val_loss: 0.0994 - val_precision_17: 0.6863 - val_recall_17: 0.5904\n",
      "Epoch 34/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0448 - precision_17: 0.8753 - recall_17: 0.7589\n",
      "Epoch 34: val_loss improved from 0.09889 to 0.09865, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0447 - precision_17: 0.8759 - recall_17: 0.7570 - val_loss: 0.0987 - val_precision_17: 0.6864 - val_recall_17: 0.5912\n",
      "Epoch 35/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0447 - precision_17: 0.8802 - recall_17: 0.7551\n",
      "Epoch 35: val_loss did not improve from 0.09865\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0447 - precision_17: 0.8792 - recall_17: 0.7559 - val_loss: 0.0994 - val_precision_17: 0.6890 - val_recall_17: 0.5972\n",
      "Epoch 36/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0427 - precision_17: 0.8880 - recall_17: 0.7650\n",
      "Epoch 36: val_loss improved from 0.09865 to 0.09793, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0426 - precision_17: 0.8870 - recall_17: 0.7657 - val_loss: 0.0979 - val_precision_17: 0.6998 - val_recall_17: 0.5992\n",
      "Epoch 37/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0426 - precision_17: 0.8818 - recall_17: 0.7633\n",
      "Epoch 37: val_loss improved from 0.09793 to 0.09781, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0425 - precision_17: 0.8797 - recall_17: 0.7670 - val_loss: 0.0978 - val_precision_17: 0.6942 - val_recall_17: 0.5980\n",
      "Epoch 38/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0430 - precision_17: 0.8814 - recall_17: 0.7653\n",
      "Epoch 38: val_loss improved from 0.09781 to 0.09741, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0427 - precision_17: 0.8812 - recall_17: 0.7654 - val_loss: 0.0974 - val_precision_17: 0.6824 - val_recall_17: 0.6121\n",
      "Epoch 39/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0416 - precision_17: 0.8831 - recall_17: 0.7731\n",
      "Epoch 39: val_loss improved from 0.09741 to 0.09709, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0413 - precision_17: 0.8817 - recall_17: 0.7760 - val_loss: 0.0971 - val_precision_17: 0.6810 - val_recall_17: 0.6193\n",
      "Epoch 40/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0386 - precision_17: 0.8934 - recall_17: 0.7888\n",
      "Epoch 40: val_loss improved from 0.09709 to 0.09697, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0384 - precision_17: 0.8932 - recall_17: 0.7906 - val_loss: 0.0970 - val_precision_17: 0.6940 - val_recall_17: 0.6206\n",
      "Epoch 41/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0404 - precision_17: 0.8887 - recall_17: 0.7775\n",
      "Epoch 41: val_loss did not improve from 0.09697\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0397 - precision_17: 0.8892 - recall_17: 0.7825 - val_loss: 0.0982 - val_precision_17: 0.6817 - val_recall_17: 0.6156\n",
      "Epoch 42/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0374 - precision_17: 0.8888 - recall_17: 0.8132\n",
      "Epoch 42: val_loss did not improve from 0.09697\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0373 - precision_17: 0.8892 - recall_17: 0.8111 - val_loss: 0.0985 - val_precision_17: 0.6820 - val_recall_17: 0.6199\n",
      "Epoch 43/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0386 - precision_17: 0.8828 - recall_17: 0.8048\n",
      "Epoch 43: val_loss did not improve from 0.09697\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0382 - precision_17: 0.8841 - recall_17: 0.8059 - val_loss: 0.0972 - val_precision_17: 0.6953 - val_recall_17: 0.6179\n",
      "Epoch 44/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0371 - precision_17: 0.9021 - recall_17: 0.8043\n",
      "Epoch 44: val_loss did not improve from 0.09697\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0368 - precision_17: 0.9018 - recall_17: 0.8034 - val_loss: 0.0976 - val_precision_17: 0.6859 - val_recall_17: 0.6410\n",
      "Epoch 45/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0344 - precision_17: 0.8960 - recall_17: 0.8279\n",
      "Epoch 45: val_loss improved from 0.09697 to 0.09624, saving model to 62sec_2layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0344 - precision_17: 0.8947 - recall_17: 0.8272 - val_loss: 0.0962 - val_precision_17: 0.6915 - val_recall_17: 0.6387\n",
      "Epoch 46/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0350 - precision_17: 0.9041 - recall_17: 0.8176\n",
      "Epoch 46: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0347 - precision_17: 0.9045 - recall_17: 0.8178 - val_loss: 0.0964 - val_precision_17: 0.6905 - val_recall_17: 0.6438\n",
      "Epoch 47/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0340 - precision_17: 0.8983 - recall_17: 0.8230\n",
      "Epoch 47: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0339 - precision_17: 0.8980 - recall_17: 0.8240 - val_loss: 0.0983 - val_precision_17: 0.6880 - val_recall_17: 0.6393\n",
      "Epoch 48/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0330 - precision_17: 0.9014 - recall_17: 0.8296\n",
      "Epoch 48: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0329 - precision_17: 0.9013 - recall_17: 0.8299 - val_loss: 0.0963 - val_precision_17: 0.7042 - val_recall_17: 0.6360\n",
      "Epoch 49/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0323 - precision_17: 0.9057 - recall_17: 0.8244\n",
      "Epoch 49: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0320 - precision_17: 0.9055 - recall_17: 0.8270 - val_loss: 0.0996 - val_precision_17: 0.6915 - val_recall_17: 0.6401\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0314 - precision_17: 0.9054 - recall_17: 0.8382\n",
      "Epoch 50: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0313 - precision_17: 0.9054 - recall_17: 0.8383 - val_loss: 0.0975 - val_precision_17: 0.6976 - val_recall_17: 0.6395\n",
      "Epoch 51/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0309 - precision_17: 0.9113 - recall_17: 0.8394\n",
      "Epoch 51: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0309 - precision_17: 0.9112 - recall_17: 0.8391 - val_loss: 0.0994 - val_precision_17: 0.6877 - val_recall_17: 0.6478\n",
      "Epoch 52/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0319 - precision_17: 0.9087 - recall_17: 0.8331\n",
      "Epoch 52: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0316 - precision_17: 0.9086 - recall_17: 0.8350 - val_loss: 0.0981 - val_precision_17: 0.6909 - val_recall_17: 0.6536\n",
      "Epoch 53/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0302 - precision_17: 0.9052 - recall_17: 0.8508\n",
      "Epoch 53: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0300 - precision_17: 0.9061 - recall_17: 0.8512 - val_loss: 0.0987 - val_precision_17: 0.6891 - val_recall_17: 0.6504\n",
      "Epoch 54/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0290 - precision_17: 0.9201 - recall_17: 0.8507\n",
      "Epoch 54: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0292 - precision_17: 0.9179 - recall_17: 0.8499 - val_loss: 0.0975 - val_precision_17: 0.6972 - val_recall_17: 0.6531\n",
      "Epoch 55/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0306 - precision_17: 0.9100 - recall_17: 0.8418\n",
      "Epoch 55: val_loss did not improve from 0.09624\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0303 - precision_17: 0.9094 - recall_17: 0.8437 - val_loss: 0.0969 - val_precision_17: 0.6948 - val_recall_17: 0.6501\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - precision_17: 0.9683 - recall_17: 0.9535\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0984 - precision_17: 0.6815 - recall_17: 0.6314 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1032 - precision_17: 0.6986 - recall_17: 0.6095 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5040 - precision_18: 0.0499 - recall_18: 0.1884\n",
      "Epoch 1: val_loss improved from inf to 0.23655, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4773 - precision_18: 0.0509 - recall_18: 0.1675 - val_loss: 0.2365 - val_precision_18: 0.2601 - val_recall_18: 0.0161\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2230 - precision_18: 0.1794 - recall_18: 0.0458\n",
      "Epoch 2: val_loss improved from 0.23655 to 0.18174, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2198 - precision_18: 0.1792 - recall_18: 0.0408 - val_loss: 0.1817 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1804 - precision_18: 0.3022 - recall_18: 0.0011      \n",
      "Epoch 3: val_loss did not improve from 0.18174\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1799 - precision_18: 0.3263 - recall_18: 0.0012 - val_loss: 0.1858 - val_precision_18: 0.0000e+00 - val_recall_18: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1729 - precision_18: 0.5032 - recall_18: 0.0334\n",
      "Epoch 4: val_loss improved from 0.18174 to 0.15654, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1723 - precision_18: 0.4922 - recall_18: 0.0412 - val_loss: 0.1565 - val_precision_18: 0.7333 - val_recall_18: 0.0055\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1604 - precision_18: 0.5209 - recall_18: 0.0472\n",
      "Epoch 5: val_loss did not improve from 0.15654\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1596 - precision_18: 0.5063 - recall_18: 0.0626 - val_loss: 0.1729 - val_precision_18: 0.4233 - val_recall_18: 0.2098\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1433 - precision_18: 0.5429 - recall_18: 0.1639\n",
      "Epoch 6: val_loss improved from 0.15654 to 0.14933, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1418 - precision_18: 0.5511 - recall_18: 0.1552 - val_loss: 0.1493 - val_precision_18: 0.5024 - val_recall_18: 0.1727\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1223 - precision_18: 0.6095 - recall_18: 0.2690\n",
      "Epoch 7: val_loss improved from 0.14933 to 0.13503, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1213 - precision_18: 0.6157 - recall_18: 0.2653 - val_loss: 0.1350 - val_precision_18: 0.6271 - val_recall_18: 0.1059\n",
      "Epoch 8/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1056 - precision_18: 0.7621 - recall_18: 0.2720\n",
      "Epoch 8: val_loss improved from 0.13503 to 0.12805, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1047 - precision_18: 0.7536 - recall_18: 0.2896 - val_loss: 0.1281 - val_precision_18: 0.6390 - val_recall_18: 0.2145\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0911 - precision_18: 0.8336 - recall_18: 0.3577\n",
      "Epoch 9: val_loss improved from 0.12805 to 0.12650, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0904 - precision_18: 0.8281 - recall_18: 0.3689 - val_loss: 0.1265 - val_precision_18: 0.5979 - val_recall_18: 0.3739\n",
      "Epoch 10/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0769 - precision_18: 0.8328 - recall_18: 0.5208\n",
      "Epoch 10: val_loss improved from 0.12650 to 0.11871, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0764 - precision_18: 0.8352 - recall_18: 0.5198 - val_loss: 0.1187 - val_precision_18: 0.6122 - val_recall_18: 0.4238\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0645 - precision_18: 0.8390 - recall_18: 0.6475\n",
      "Epoch 11: val_loss improved from 0.11871 to 0.11087, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0644 - precision_18: 0.8401 - recall_18: 0.6464 - val_loss: 0.1109 - val_precision_18: 0.6942 - val_recall_18: 0.4109\n",
      "Epoch 12/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0550 - precision_18: 0.8857 - recall_18: 0.6750\n",
      "Epoch 12: val_loss improved from 0.11087 to 0.10655, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0545 - precision_18: 0.8829 - recall_18: 0.6820 - val_loss: 0.1065 - val_precision_18: 0.7282 - val_recall_18: 0.4197\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0486 - precision_18: 0.9100 - recall_18: 0.6957\n",
      "Epoch 13: val_loss improved from 0.10655 to 0.10326, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0482 - precision_18: 0.9067 - recall_18: 0.7024 - val_loss: 0.1033 - val_precision_18: 0.6964 - val_recall_18: 0.5152\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0426 - precision_18: 0.9100 - recall_18: 0.7580\n",
      "Epoch 14: val_loss did not improve from 0.10326\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0423 - precision_18: 0.9109 - recall_18: 0.7579 - val_loss: 0.1040 - val_precision_18: 0.6842 - val_recall_18: 0.5662\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0370 - precision_18: 0.9074 - recall_18: 0.8200\n",
      "Epoch 15: val_loss improved from 0.10326 to 0.10190, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0368 - precision_18: 0.9099 - recall_18: 0.8173 - val_loss: 0.1019 - val_precision_18: 0.7129 - val_recall_18: 0.5433\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0323 - precision_18: 0.9301 - recall_18: 0.8286\n",
      "Epoch 16: val_loss improved from 0.10190 to 0.09921, saving model to 62sec_2layers_1024units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0321 - precision_18: 0.9290 - recall_18: 0.8304 - val_loss: 0.0992 - val_precision_18: 0.7412 - val_recall_18: 0.5530\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0285 - precision_18: 0.9483 - recall_18: 0.8366\n",
      "Epoch 17: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0283 - precision_18: 0.9474 - recall_18: 0.8391 - val_loss: 0.0998 - val_precision_18: 0.7288 - val_recall_18: 0.6040\n",
      "Epoch 18/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0262 - precision_18: 0.9452 - recall_18: 0.8547\n",
      "Epoch 18: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0259 - precision_18: 0.9453 - recall_18: 0.8569 - val_loss: 0.0998 - val_precision_18: 0.7183 - val_recall_18: 0.6083\n",
      "Epoch 19/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0220 - precision_18: 0.9455 - recall_18: 0.9019\n",
      "Epoch 19: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0219 - precision_18: 0.9467 - recall_18: 0.8993 - val_loss: 0.1016 - val_precision_18: 0.7201 - val_recall_18: 0.6101\n",
      "Epoch 20/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0205 - precision_18: 0.9481 - recall_18: 0.9052\n",
      "Epoch 20: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0203 - precision_18: 0.9479 - recall_18: 0.9057 - val_loss: 0.1038 - val_precision_18: 0.7419 - val_recall_18: 0.6138\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0185 - precision_18: 0.9647 - recall_18: 0.9087\n",
      "Epoch 21: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0183 - precision_18: 0.9633 - recall_18: 0.9101 - val_loss: 0.1044 - val_precision_18: 0.7226 - val_recall_18: 0.6373\n",
      "Epoch 22/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0170 - precision_18: 0.9590 - recall_18: 0.9167\n",
      "Epoch 22: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0169 - precision_18: 0.9597 - recall_18: 0.9171 - val_loss: 0.1040 - val_precision_18: 0.7325 - val_recall_18: 0.6246\n",
      "Epoch 23/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - precision_18: 0.9627 - recall_18: 0.9389\n",
      "Epoch 23: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0143 - precision_18: 0.9629 - recall_18: 0.9382 - val_loss: 0.1046 - val_precision_18: 0.7383 - val_recall_18: 0.6314\n",
      "Epoch 24/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0137 - precision_18: 0.9661 - recall_18: 0.9350\n",
      "Epoch 24: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0137 - precision_18: 0.9665 - recall_18: 0.9353 - val_loss: 0.1069 - val_precision_18: 0.7402 - val_recall_18: 0.6375\n",
      "Epoch 25/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131 - precision_18: 0.9666 - recall_18: 0.9442\n",
      "Epoch 25: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0130 - precision_18: 0.9665 - recall_18: 0.9447 - val_loss: 0.1096 - val_precision_18: 0.7363 - val_recall_18: 0.6370\n",
      "Epoch 26/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - precision_18: 0.9674 - recall_18: 0.9483\n",
      "Epoch 26: val_loss did not improve from 0.09921\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0124 - precision_18: 0.9673 - recall_18: 0.9481 - val_loss: 0.1071 - val_precision_18: 0.7363 - val_recall_18: 0.6441\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - precision_18: 0.9772 - recall_18: 0.9121 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0994 - precision_18: 0.7277 - recall_18: 0.5428 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1066 - precision_18: 0.7370 - recall_18: 0.5435 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5002 - precision_19: 0.0530 - recall_19: 0.1996\n",
      "Epoch 1: val_loss improved from inf to 0.23563, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4739 - precision_19: 0.0539 - recall_19: 0.1778 - val_loss: 0.2356 - val_precision_19: 0.2703 - val_recall_19: 0.0149\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2221 - precision_19: 0.1758 - recall_19: 0.0492\n",
      "Epoch 2: val_loss improved from 0.23563 to 0.17955, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2190 - precision_19: 0.1763 - recall_19: 0.0442 - val_loss: 0.1796 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1820 - precision_19: 0.4916 - recall_19: 0.0023      \n",
      "Epoch 3: val_loss did not improve from 0.17955\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1813 - precision_19: 0.4813 - recall_19: 0.0025 - val_loss: 0.1908 - val_precision_19: 0.0000e+00 - val_recall_19: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1804 - precision_19: 0.4876 - recall_19: 0.0300\n",
      "Epoch 4: val_loss improved from 0.17955 to 0.15272, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1793 - precision_19: 0.4748 - recall_19: 0.0394 - val_loss: 0.1527 - val_precision_19: 0.4543 - val_recall_19: 0.0330\n",
      "Epoch 5/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1550 - precision_19: 0.4865 - recall_19: 0.0524\n",
      "Epoch 5: val_loss did not improve from 0.15272\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1543 - precision_19: 0.4796 - recall_19: 0.0632 - val_loss: 0.1687 - val_precision_19: 0.4195 - val_recall_19: 0.2171\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1428 - precision_19: 0.5165 - recall_19: 0.1856\n",
      "Epoch 6: val_loss improved from 0.15272 to 0.14038, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1413 - precision_19: 0.5228 - recall_19: 0.1751 - val_loss: 0.1404 - val_precision_19: 0.5447 - val_recall_19: 0.0869\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1226 - precision_19: 0.6327 - recall_19: 0.1984\n",
      "Epoch 7: val_loss improved from 0.14038 to 0.13328, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1219 - precision_19: 0.6330 - recall_19: 0.2040 - val_loss: 0.1333 - val_precision_19: 0.5897 - val_recall_19: 0.1096\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1111 - precision_19: 0.7637 - recall_19: 0.2347\n",
      "Epoch 8: val_loss improved from 0.13328 to 0.13171, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1103 - precision_19: 0.7554 - recall_19: 0.2462 - val_loss: 0.1317 - val_precision_19: 0.5648 - val_recall_19: 0.2551\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0969 - precision_19: 0.7887 - recall_19: 0.3469\n",
      "Epoch 9: val_loss improved from 0.13171 to 0.12764, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0962 - precision_19: 0.7886 - recall_19: 0.3510 - val_loss: 0.1276 - val_precision_19: 0.5958 - val_recall_19: 0.3519\n",
      "Epoch 10/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0843 - precision_19: 0.8105 - recall_19: 0.4789\n",
      "Epoch 10: val_loss improved from 0.12764 to 0.11741, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0834 - precision_19: 0.8153 - recall_19: 0.4767 - val_loss: 0.1174 - val_precision_19: 0.6389 - val_recall_19: 0.3766\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0727 - precision_19: 0.8277 - recall_19: 0.5717\n",
      "Epoch 11: val_loss improved from 0.11741 to 0.11031, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0723 - precision_19: 0.8291 - recall_19: 0.5729 - val_loss: 0.1103 - val_precision_19: 0.6952 - val_recall_19: 0.3829\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0635 - precision_19: 0.8711 - recall_19: 0.6001\n",
      "Epoch 12: val_loss improved from 0.11031 to 0.10749, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0632 - precision_19: 0.8672 - recall_19: 0.6055 - val_loss: 0.1075 - val_precision_19: 0.6929 - val_recall_19: 0.4563\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0580 - precision_19: 0.8805 - recall_19: 0.6360\n",
      "Epoch 13: val_loss improved from 0.10749 to 0.10690, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0575 - precision_19: 0.8798 - recall_19: 0.6402 - val_loss: 0.1069 - val_precision_19: 0.6648 - val_recall_19: 0.5405\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0501 - precision_19: 0.8857 - recall_19: 0.7174\n",
      "Epoch 14: val_loss improved from 0.10690 to 0.10403, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0498 - precision_19: 0.8870 - recall_19: 0.7166 - val_loss: 0.1040 - val_precision_19: 0.6971 - val_recall_19: 0.5367\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0444 - precision_19: 0.8999 - recall_19: 0.7520\n",
      "Epoch 15: val_loss improved from 0.10403 to 0.10084, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0442 - precision_19: 0.8986 - recall_19: 0.7533 - val_loss: 0.1008 - val_precision_19: 0.7160 - val_recall_19: 0.5286\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0407 - precision_19: 0.9076 - recall_19: 0.7641\n",
      "Epoch 16: val_loss improved from 0.10084 to 0.09873, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0405 - precision_19: 0.9067 - recall_19: 0.7666 - val_loss: 0.0987 - val_precision_19: 0.7049 - val_recall_19: 0.5667\n",
      "Epoch 17/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0369 - precision_19: 0.9149 - recall_19: 0.7931\n",
      "Epoch 17: val_loss did not improve from 0.09873\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0366 - precision_19: 0.9156 - recall_19: 0.7939 - val_loss: 0.1001 - val_precision_19: 0.6972 - val_recall_19: 0.5912\n",
      "Epoch 18/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0339 - precision_19: 0.9182 - recall_19: 0.8181\n",
      "Epoch 18: val_loss did not improve from 0.09873\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0335 - precision_19: 0.9187 - recall_19: 0.8198 - val_loss: 0.1001 - val_precision_19: 0.7051 - val_recall_19: 0.5934\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0312 - precision_19: 0.9290 - recall_19: 0.8315\n",
      "Epoch 19: val_loss improved from 0.09873 to 0.09871, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0310 - precision_19: 0.9282 - recall_19: 0.8335 - val_loss: 0.0987 - val_precision_19: 0.7090 - val_recall_19: 0.6101\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0280 - precision_19: 0.9331 - recall_19: 0.8522\n",
      "Epoch 20: val_loss improved from 0.09871 to 0.09837, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0280 - precision_19: 0.9326 - recall_19: 0.8523 - val_loss: 0.0984 - val_precision_19: 0.7241 - val_recall_19: 0.6176\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0260 - precision_19: 0.9359 - recall_19: 0.8650\n",
      "Epoch 21: val_loss did not improve from 0.09837\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0258 - precision_19: 0.9359 - recall_19: 0.8666 - val_loss: 0.0987 - val_precision_19: 0.7163 - val_recall_19: 0.6208\n",
      "Epoch 22/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0234 - precision_19: 0.9426 - recall_19: 0.8807\n",
      "Epoch 22: val_loss improved from 0.09837 to 0.09815, saving model to 62sec_2layers_1024units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0233 - precision_19: 0.9424 - recall_19: 0.8810 - val_loss: 0.0982 - val_precision_19: 0.7140 - val_recall_19: 0.6310\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0223 - precision_19: 0.9419 - recall_19: 0.8890\n",
      "Epoch 23: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0222 - precision_19: 0.9422 - recall_19: 0.8892 - val_loss: 0.1010 - val_precision_19: 0.7162 - val_recall_19: 0.6441\n",
      "Epoch 24/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0201 - precision_19: 0.9440 - recall_19: 0.9044\n",
      "Epoch 24: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0199 - precision_19: 0.9439 - recall_19: 0.9049 - val_loss: 0.1023 - val_precision_19: 0.7310 - val_recall_19: 0.6406\n",
      "Epoch 25/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0185 - precision_19: 0.9533 - recall_19: 0.9089\n",
      "Epoch 25: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0185 - precision_19: 0.9526 - recall_19: 0.9093 - val_loss: 0.1027 - val_precision_19: 0.7219 - val_recall_19: 0.6484\n",
      "Epoch 26/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0178 - precision_19: 0.9541 - recall_19: 0.9148\n",
      "Epoch 26: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0177 - precision_19: 0.9543 - recall_19: 0.9148 - val_loss: 0.1023 - val_precision_19: 0.7235 - val_recall_19: 0.6489\n",
      "Epoch 27/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0170 - precision_19: 0.9578 - recall_19: 0.9178\n",
      "Epoch 27: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0168 - precision_19: 0.9576 - recall_19: 0.9191 - val_loss: 0.1025 - val_precision_19: 0.7184 - val_recall_19: 0.6605\n",
      "Epoch 28/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0160 - precision_19: 0.9521 - recall_19: 0.9330\n",
      "Epoch 28: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0158 - precision_19: 0.9537 - recall_19: 0.9324 - val_loss: 0.1062 - val_precision_19: 0.7149 - val_recall_19: 0.6484\n",
      "Epoch 29/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - precision_19: 0.9597 - recall_19: 0.9349\n",
      "Epoch 29: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0147 - precision_19: 0.9595 - recall_19: 0.9347 - val_loss: 0.1052 - val_precision_19: 0.7183 - val_recall_19: 0.6461\n",
      "Epoch 30/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0134 - precision_19: 0.9673 - recall_19: 0.9363\n",
      "Epoch 30: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0134 - precision_19: 0.9665 - recall_19: 0.9362 - val_loss: 0.1053 - val_precision_19: 0.7168 - val_recall_19: 0.6579\n",
      "Epoch 31/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0129 - precision_19: 0.9647 - recall_19: 0.9425\n",
      "Epoch 31: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0129 - precision_19: 0.9645 - recall_19: 0.9423 - val_loss: 0.1063 - val_precision_19: 0.7205 - val_recall_19: 0.6559\n",
      "Epoch 32/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - precision_19: 0.9675 - recall_19: 0.9447\n",
      "Epoch 32: val_loss did not improve from 0.09815\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0124 - precision_19: 0.9672 - recall_19: 0.9450 - val_loss: 0.1105 - val_precision_19: 0.7191 - val_recall_19: 0.6607\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - precision_19: 0.9793 - recall_19: 0.9665\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0994 - precision_19: 0.7041 - recall_19: 0.6297 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1066 - precision_19: 0.7077 - recall_19: 0.6078 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5143 - precision_20: 0.0520 - recall_20: 0.2160\n",
      "Epoch 1: val_loss improved from inf to 0.22493, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4876 - precision_20: 0.0526 - recall_20: 0.1921 - val_loss: 0.2249 - val_precision_20: 0.3158 - val_recall_20: 0.0060\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2264 - precision_20: 0.1716 - recall_20: 0.0565\n",
      "Epoch 2: val_loss improved from 0.22493 to 0.18751, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2234 - precision_20: 0.1721 - recall_20: 0.0518 - val_loss: 0.1875 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1930 - precision_20: 0.3890 - recall_20: 0.0028   \n",
      "Epoch 3: val_loss improved from 0.18751 to 0.18259, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1918 - precision_20: 0.3840 - recall_20: 0.0032 - val_loss: 0.1826 - val_precision_20: 0.0000e+00 - val_recall_20: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1883 - precision_20: 0.4800 - recall_20: 0.0135\n",
      "Epoch 4: val_loss improved from 0.18259 to 0.17330, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1866 - precision_20: 0.4626 - recall_20: 0.0198 - val_loss: 0.1733 - val_precision_20: 0.4709 - val_recall_20: 0.0564\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1584 - precision_20: 0.4235 - recall_20: 0.0611\n",
      "Epoch 5: val_loss improved from 0.17330 to 0.15870, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1574 - precision_20: 0.4275 - recall_20: 0.0605 - val_loss: 0.1587 - val_precision_20: 0.4646 - val_recall_20: 0.1067\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1449 - precision_20: 0.4756 - recall_20: 0.1241\n",
      "Epoch 6: val_loss improved from 0.15870 to 0.14101, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1439 - precision_20: 0.4787 - recall_20: 0.1220 - val_loss: 0.1410 - val_precision_20: 0.5714 - val_recall_20: 0.0471\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1322 - precision_20: 0.5897 - recall_20: 0.1201\n",
      "Epoch 7: val_loss improved from 0.14101 to 0.13865, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1314 - precision_20: 0.5892 - recall_20: 0.1261 - val_loss: 0.1386 - val_precision_20: 0.5649 - val_recall_20: 0.1175\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1193 - precision_20: 0.6823 - recall_20: 0.1670\n",
      "Epoch 8: val_loss did not improve from 0.13865\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1187 - precision_20: 0.6822 - recall_20: 0.1744 - val_loss: 0.1396 - val_precision_20: 0.5293 - val_recall_20: 0.2442\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1077 - precision_20: 0.7138 - recall_20: 0.2904\n",
      "Epoch 9: val_loss improved from 0.13865 to 0.12857, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1069 - precision_20: 0.7190 - recall_20: 0.2910 - val_loss: 0.1286 - val_precision_20: 0.6013 - val_recall_20: 0.2750\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0970 - precision_20: 0.7507 - recall_20: 0.3709\n",
      "Epoch 10: val_loss improved from 0.12857 to 0.12153, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0964 - precision_20: 0.7528 - recall_20: 0.3745 - val_loss: 0.1215 - val_precision_20: 0.6232 - val_recall_20: 0.3202\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0858 - precision_20: 0.8111 - recall_20: 0.4389\n",
      "Epoch 11: val_loss improved from 0.12153 to 0.11844, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0853 - precision_20: 0.8094 - recall_20: 0.4440 - val_loss: 0.1184 - val_precision_20: 0.6334 - val_recall_20: 0.4025\n",
      "Epoch 12/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0777 - precision_20: 0.8246 - recall_20: 0.5142\n",
      "Epoch 12: val_loss improved from 0.11844 to 0.11350, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0771 - precision_20: 0.8253 - recall_20: 0.5159 - val_loss: 0.1135 - val_precision_20: 0.6446 - val_recall_20: 0.4446\n",
      "Epoch 13/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0690 - precision_20: 0.8266 - recall_20: 0.6019\n",
      "Epoch 13: val_loss improved from 0.11350 to 0.10922, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0687 - precision_20: 0.8275 - recall_20: 0.5991 - val_loss: 0.1092 - val_precision_20: 0.6795 - val_recall_20: 0.4731\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0649 - precision_20: 0.8442 - recall_20: 0.6010\n",
      "Epoch 14: val_loss improved from 0.10922 to 0.10765, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0645 - precision_20: 0.8428 - recall_20: 0.6052 - val_loss: 0.1077 - val_precision_20: 0.6717 - val_recall_20: 0.4830\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0578 - precision_20: 0.8635 - recall_20: 0.6544\n",
      "Epoch 15: val_loss improved from 0.10765 to 0.10592, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0575 - precision_20: 0.8633 - recall_20: 0.6559 - val_loss: 0.1059 - val_precision_20: 0.6595 - val_recall_20: 0.5198\n",
      "Epoch 16/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0537 - precision_20: 0.8634 - recall_20: 0.7071\n",
      "Epoch 16: val_loss improved from 0.10592 to 0.10130, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0532 - precision_20: 0.8653 - recall_20: 0.7053 - val_loss: 0.1013 - val_precision_20: 0.6839 - val_recall_20: 0.5404\n",
      "Epoch 17/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0485 - precision_20: 0.8786 - recall_20: 0.7275\n",
      "Epoch 17: val_loss did not improve from 0.10130\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0483 - precision_20: 0.8786 - recall_20: 0.7278 - val_loss: 0.1015 - val_precision_20: 0.6757 - val_recall_20: 0.5646\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0468 - precision_20: 0.8776 - recall_20: 0.7456\n",
      "Epoch 18: val_loss improved from 0.10130 to 0.10092, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0467 - precision_20: 0.8778 - recall_20: 0.7461 - val_loss: 0.1009 - val_precision_20: 0.6886 - val_recall_20: 0.5692\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0444 - precision_20: 0.8885 - recall_20: 0.7494\n",
      "Epoch 19: val_loss improved from 0.10092 to 0.09929, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0441 - precision_20: 0.8887 - recall_20: 0.7508 - val_loss: 0.0993 - val_precision_20: 0.6921 - val_recall_20: 0.5984\n",
      "Epoch 20/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0400 - precision_20: 0.8991 - recall_20: 0.7820\n",
      "Epoch 20: val_loss improved from 0.09929 to 0.09713, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0396 - precision_20: 0.8995 - recall_20: 0.7833 - val_loss: 0.0971 - val_precision_20: 0.6916 - val_recall_20: 0.5921\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0389 - precision_20: 0.8998 - recall_20: 0.7895\n",
      "Epoch 21: val_loss improved from 0.09713 to 0.09694, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0385 - precision_20: 0.9004 - recall_20: 0.7913 - val_loss: 0.0969 - val_precision_20: 0.6819 - val_recall_20: 0.6045\n",
      "Epoch 22/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0352 - precision_20: 0.9006 - recall_20: 0.8150\n",
      "Epoch 22: val_loss did not improve from 0.09694\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0349 - precision_20: 0.9029 - recall_20: 0.8144 - val_loss: 0.0979 - val_precision_20: 0.6862 - val_recall_20: 0.6246\n",
      "Epoch 23/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0331 - precision_20: 0.9186 - recall_20: 0.8214\n",
      "Epoch 23: val_loss did not improve from 0.09694\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0329 - precision_20: 0.9185 - recall_20: 0.8233 - val_loss: 0.0978 - val_precision_20: 0.6993 - val_recall_20: 0.6188\n",
      "Epoch 24/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0324 - precision_20: 0.9130 - recall_20: 0.8252\n",
      "Epoch 24: val_loss improved from 0.09694 to 0.09640, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0321 - precision_20: 0.9129 - recall_20: 0.8276 - val_loss: 0.0964 - val_precision_20: 0.7126 - val_recall_20: 0.6350\n",
      "Epoch 25/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0299 - precision_20: 0.9198 - recall_20: 0.8370\n",
      "Epoch 25: val_loss improved from 0.09640 to 0.09368, saving model to 62sec_2layers_1024units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0296 - precision_20: 0.9203 - recall_20: 0.8390 - val_loss: 0.0937 - val_precision_20: 0.7049 - val_recall_20: 0.6383\n",
      "Epoch 26/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0288 - precision_20: 0.9253 - recall_20: 0.8485\n",
      "Epoch 26: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0286 - precision_20: 0.9253 - recall_20: 0.8495 - val_loss: 0.0942 - val_precision_20: 0.6981 - val_recall_20: 0.6416\n",
      "Epoch 27/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0266 - precision_20: 0.9274 - recall_20: 0.8693\n",
      "Epoch 27: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0264 - precision_20: 0.9278 - recall_20: 0.8700 - val_loss: 0.0957 - val_precision_20: 0.7130 - val_recall_20: 0.6406\n",
      "Epoch 28/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0258 - precision_20: 0.9312 - recall_20: 0.8637\n",
      "Epoch 28: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0256 - precision_20: 0.9311 - recall_20: 0.8660 - val_loss: 0.0960 - val_precision_20: 0.7023 - val_recall_20: 0.6506\n",
      "Epoch 29/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0235 - precision_20: 0.9387 - recall_20: 0.8775\n",
      "Epoch 29: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0234 - precision_20: 0.9385 - recall_20: 0.8782 - val_loss: 0.0962 - val_precision_20: 0.6941 - val_recall_20: 0.6576\n",
      "Epoch 30/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0240 - precision_20: 0.9385 - recall_20: 0.8782\n",
      "Epoch 30: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0237 - precision_20: 0.9385 - recall_20: 0.8792 - val_loss: 0.0980 - val_precision_20: 0.6966 - val_recall_20: 0.6562\n",
      "Epoch 31/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0216 - precision_20: 0.9418 - recall_20: 0.8991\n",
      "Epoch 31: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0215 - precision_20: 0.9415 - recall_20: 0.8981 - val_loss: 0.0968 - val_precision_20: 0.6936 - val_recall_20: 0.6579\n",
      "Epoch 32/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0212 - precision_20: 0.9395 - recall_20: 0.8944\n",
      "Epoch 32: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0211 - precision_20: 0.9401 - recall_20: 0.8946 - val_loss: 0.0965 - val_precision_20: 0.6922 - val_recall_20: 0.6612\n",
      "Epoch 33/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0202 - precision_20: 0.9432 - recall_20: 0.9031\n",
      "Epoch 33: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0201 - precision_20: 0.9427 - recall_20: 0.9031 - val_loss: 0.0986 - val_precision_20: 0.7018 - val_recall_20: 0.6546\n",
      "Epoch 34/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0187 - precision_20: 0.9470 - recall_20: 0.9078\n",
      "Epoch 34: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0186 - precision_20: 0.9470 - recall_20: 0.9084 - val_loss: 0.1004 - val_precision_20: 0.6914 - val_recall_20: 0.6509\n",
      "Epoch 35/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0191 - precision_20: 0.9412 - recall_20: 0.9113\n",
      "Epoch 35: val_loss did not improve from 0.09368\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0190 - precision_20: 0.9414 - recall_20: 0.9125 - val_loss: 0.0989 - val_precision_20: 0.7070 - val_recall_20: 0.6552\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - precision_20: 0.9754 - recall_20: 0.9598\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0953 - precision_20: 0.6932 - recall_20: 0.6325 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1057 - precision_20: 0.6891 - recall_20: 0.6053 \n",
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4266 - precision_21: 0.0590 - recall_21: 0.1450\n",
      "Epoch 1: val_loss improved from inf to 0.19330, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4199 - precision_21: 0.0598 - recall_21: 0.1405 - val_loss: 0.1933 - val_precision_21: 0.3750 - val_recall_21: 4.9727e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1961 - precision_21: 0.2667 - recall_21: 0.0015\n",
      "Epoch 2: val_loss improved from 0.19330 to 0.17633, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1943 - precision_21: 0.2717 - recall_21: 0.0015 - val_loss: 0.1763 - val_precision_21: 0.0000e+00 - val_recall_21: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1569 - precision_21: 0.5876 - recall_21: 0.0148\n",
      "Epoch 3: val_loss improved from 0.17633 to 0.15549, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1565 - precision_21: 0.5857 - recall_21: 0.0156 - val_loss: 0.1555 - val_precision_21: 0.4346 - val_recall_21: 0.0963\n",
      "Epoch 4/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1374 - precision_21: 0.5472 - recall_21: 0.1340\n",
      "Epoch 4: val_loss improved from 0.15549 to 0.13887, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1369 - precision_21: 0.5525 - recall_21: 0.1317 - val_loss: 0.1389 - val_precision_21: 0.5098 - val_recall_21: 0.1082\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1179 - precision_21: 0.6631 - recall_21: 0.2645\n",
      "Epoch 5: val_loss did not improve from 0.13887\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1177 - precision_21: 0.6631 - recall_21: 0.2646 - val_loss: 0.1423 - val_precision_21: 0.7095 - val_recall_21: 0.0632\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1034 - precision_21: 0.7781 - recall_21: 0.3436\n",
      "Epoch 6: val_loss improved from 0.13887 to 0.13290, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1032 - precision_21: 0.7745 - recall_21: 0.3506 - val_loss: 0.1329 - val_precision_21: 0.7392 - val_recall_21: 0.1188\n",
      "Epoch 7/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0874 - precision_21: 0.8748 - recall_21: 0.3919\n",
      "Epoch 7: val_loss improved from 0.13290 to 0.12445, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0872 - precision_21: 0.8685 - recall_21: 0.4000 - val_loss: 0.1244 - val_precision_21: 0.5860 - val_recall_21: 0.4704\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0703 - precision_21: 0.8508 - recall_21: 0.6111\n",
      "Epoch 8: val_loss did not improve from 0.12445\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0698 - precision_21: 0.8554 - recall_21: 0.6031 - val_loss: 0.1325 - val_precision_21: 0.5257 - val_recall_21: 0.5964\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0616 - precision_21: 0.7982 - recall_21: 0.8009\n",
      "Epoch 9: val_loss improved from 0.12445 to 0.10255, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0613 - precision_21: 0.8011 - recall_21: 0.7964 - val_loss: 0.1026 - val_precision_21: 0.7048 - val_recall_21: 0.4543\n",
      "Epoch 10/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0434 - precision_21: 0.9003 - recall_21: 0.7728\n",
      "Epoch 10: val_loss improved from 0.10255 to 0.09767, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0432 - precision_21: 0.8980 - recall_21: 0.7784 - val_loss: 0.0977 - val_precision_21: 0.7369 - val_recall_21: 0.4842\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0354 - precision_21: 0.9520 - recall_21: 0.7654\n",
      "Epoch 11: val_loss did not improve from 0.09767\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0353 - precision_21: 0.9509 - recall_21: 0.7677 - val_loss: 0.1040 - val_precision_21: 0.6503 - val_recall_21: 0.6133\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0283 - precision_21: 0.9270 - recall_21: 0.8714\n",
      "Epoch 12: val_loss did not improve from 0.09767\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0279 - precision_21: 0.9299 - recall_21: 0.8688 - val_loss: 0.1030 - val_precision_21: 0.7026 - val_recall_21: 0.5952\n",
      "Epoch 13/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0230 - precision_21: 0.9441 - recall_21: 0.8886\n",
      "Epoch 13: val_loss improved from 0.09767 to 0.09505, saving model to 62sec_2layers_2048units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0229 - precision_21: 0.9440 - recall_21: 0.8902 - val_loss: 0.0950 - val_precision_21: 0.7335 - val_recall_21: 0.6113\n",
      "Epoch 14/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0186 - precision_21: 0.9634 - recall_21: 0.8998\n",
      "Epoch 14: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0183 - precision_21: 0.9635 - recall_21: 0.9014 - val_loss: 0.0962 - val_precision_21: 0.7036 - val_recall_21: 0.6355\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0167 - precision_21: 0.9531 - recall_21: 0.9330\n",
      "Epoch 15: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0166 - precision_21: 0.9542 - recall_21: 0.9314 - val_loss: 0.1039 - val_precision_21: 0.7227 - val_recall_21: 0.6337\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0141 - precision_21: 0.9641 - recall_21: 0.9416\n",
      "Epoch 16: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0139 - precision_21: 0.9639 - recall_21: 0.9428 - val_loss: 0.1039 - val_precision_21: 0.7420 - val_recall_21: 0.6401\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0113 - precision_21: 0.9790 - recall_21: 0.9415\n",
      "Epoch 17: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0112 - precision_21: 0.9786 - recall_21: 0.9427 - val_loss: 0.1003 - val_precision_21: 0.7326 - val_recall_21: 0.6539\n",
      "Epoch 18/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - precision_21: 0.9777 - recall_21: 0.9678\n",
      "Epoch 18: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - precision_21: 0.9783 - recall_21: 0.9668 - val_loss: 0.1058 - val_precision_21: 0.7348 - val_recall_21: 0.6532\n",
      "Epoch 19/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0081 - precision_21: 0.9771 - recall_21: 0.9739\n",
      "Epoch 19: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0081 - precision_21: 0.9772 - recall_21: 0.9737 - val_loss: 0.1115 - val_precision_21: 0.7434 - val_recall_21: 0.6401\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - precision_21: 0.9824 - recall_21: 0.9697\n",
      "Epoch 20: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - precision_21: 0.9821 - recall_21: 0.9700 - val_loss: 0.1121 - val_precision_21: 0.7369 - val_recall_21: 0.6566\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - precision_21: 0.9814 - recall_21: 0.9770\n",
      "Epoch 21: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0067 - precision_21: 0.9815 - recall_21: 0.9769 - val_loss: 0.1155 - val_precision_21: 0.7458 - val_recall_21: 0.6473\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0064 - precision_21: 0.9817 - recall_21: 0.9800\n",
      "Epoch 22: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0064 - precision_21: 0.9818 - recall_21: 0.9800 - val_loss: 0.1177 - val_precision_21: 0.7446 - val_recall_21: 0.6489\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - precision_21: 0.9862 - recall_21: 0.9802\n",
      "Epoch 23: val_loss did not improve from 0.09505\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - precision_21: 0.9862 - recall_21: 0.9801 - val_loss: 0.1200 - val_precision_21: 0.7414 - val_recall_21: 0.6443\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - precision_21: 0.9832 - recall_21: 0.9438\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0961 - precision_21: 0.7200 - recall_21: 0.6078 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1062 - precision_21: 0.7364 - recall_21: 0.5774 \n",
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4289 - precision_22: 0.0584 - recall_22: 0.1468\n",
      "Epoch 1: val_loss improved from inf to 0.19565, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.4221 - precision_22: 0.0593 - recall_22: 0.1425 - val_loss: 0.1956 - val_precision_22: 0.2308 - val_recall_22: 0.0020\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1960 - precision_22: 0.2255 - recall_22: 0.0039\n",
      "Epoch 2: val_loss improved from 0.19565 to 0.18048, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1951 - precision_22: 0.2279 - recall_22: 0.0038 - val_loss: 0.1805 - val_precision_22: 1.0000 - val_recall_22: 1.6576e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1607 - precision_22: 0.5929 - recall_22: 0.0139\n",
      "Epoch 3: val_loss improved from 0.18048 to 0.15670, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1597 - precision_22: 0.5823 - recall_22: 0.0154 - val_loss: 0.1567 - val_precision_22: 0.4318 - val_recall_22: 0.0882\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1411 - precision_22: 0.5225 - recall_22: 0.1406\n",
      "Epoch 4: val_loss improved from 0.15670 to 0.14237, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1410 - precision_22: 0.5239 - recall_22: 0.1393 - val_loss: 0.1424 - val_precision_22: 0.5663 - val_recall_22: 0.0524\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1267 - precision_22: 0.6305 - recall_22: 0.2222\n",
      "Epoch 5: val_loss did not improve from 0.14237\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1265 - precision_22: 0.6300 - recall_22: 0.2254 - val_loss: 0.1497 - val_precision_22: 0.7133 - val_recall_22: 0.0330\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1175 - precision_22: 0.7733 - recall_22: 0.2418\n",
      "Epoch 6: val_loss improved from 0.14237 to 0.12973, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1171 - precision_22: 0.7667 - recall_22: 0.2505 - val_loss: 0.1297 - val_precision_22: 0.5973 - val_recall_22: 0.2687\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0906 - precision_22: 0.8593 - recall_22: 0.3830\n",
      "Epoch 7: val_loss did not improve from 0.12973\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0902 - precision_22: 0.8528 - recall_22: 0.3890 - val_loss: 0.1437 - val_precision_22: 0.5085 - val_recall_22: 0.5196\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0769 - precision_22: 0.7941 - recall_22: 0.6558\n",
      "Epoch 8: val_loss improved from 0.12973 to 0.11544, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0766 - precision_22: 0.7969 - recall_22: 0.6511 - val_loss: 0.1154 - val_precision_22: 0.6292 - val_recall_22: 0.4573\n",
      "Epoch 9/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0587 - precision_22: 0.8283 - recall_22: 0.7311\n",
      "Epoch 9: val_loss improved from 0.11544 to 0.10792, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0583 - precision_22: 0.8300 - recall_22: 0.7307 - val_loss: 0.1079 - val_precision_22: 0.7336 - val_recall_22: 0.3816\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0488 - precision_22: 0.9253 - recall_22: 0.6821\n",
      "Epoch 10: val_loss improved from 0.10792 to 0.10401, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0486 - precision_22: 0.9233 - recall_22: 0.6861 - val_loss: 0.1040 - val_precision_22: 0.6821 - val_recall_22: 0.5531\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0391 - precision_22: 0.9316 - recall_22: 0.7629\n",
      "Epoch 11: val_loss did not improve from 0.10401\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0389 - precision_22: 0.9318 - recall_22: 0.7632 - val_loss: 0.1060 - val_precision_22: 0.6538 - val_recall_22: 0.6002\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0322 - precision_22: 0.9166 - recall_22: 0.8550\n",
      "Epoch 12: val_loss improved from 0.10401 to 0.09794, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0320 - precision_22: 0.9174 - recall_22: 0.8544 - val_loss: 0.0979 - val_precision_22: 0.7249 - val_recall_22: 0.5848\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0265 - precision_22: 0.9419 - recall_22: 0.8636\n",
      "Epoch 13: val_loss improved from 0.09794 to 0.09553, saving model to 62sec_2layers_2048units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0263 - precision_22: 0.9409 - recall_22: 0.8653 - val_loss: 0.0955 - val_precision_22: 0.7275 - val_recall_22: 0.6106\n",
      "Epoch 14/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0226 - precision_22: 0.9522 - recall_22: 0.8757\n",
      "Epoch 14: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0224 - precision_22: 0.9519 - recall_22: 0.8770 - val_loss: 0.0982 - val_precision_22: 0.7113 - val_recall_22: 0.6411\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0190 - precision_22: 0.9552 - recall_22: 0.9080\n",
      "Epoch 15: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0188 - precision_22: 0.9554 - recall_22: 0.9083 - val_loss: 0.1004 - val_precision_22: 0.7195 - val_recall_22: 0.6428\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0167 - precision_22: 0.9599 - recall_22: 0.9228\n",
      "Epoch 16: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0167 - precision_22: 0.9600 - recall_22: 0.9230 - val_loss: 0.0959 - val_precision_22: 0.7365 - val_recall_22: 0.6443\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0139 - precision_22: 0.9708 - recall_22: 0.9346\n",
      "Epoch 17: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0138 - precision_22: 0.9706 - recall_22: 0.9348 - val_loss: 0.0972 - val_precision_22: 0.7217 - val_recall_22: 0.6532\n",
      "Epoch 18/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0130 - precision_22: 0.9657 - recall_22: 0.9442\n",
      "Epoch 18: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0130 - precision_22: 0.9661 - recall_22: 0.9440 - val_loss: 0.1052 - val_precision_22: 0.7107 - val_recall_22: 0.6557\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0110 - precision_22: 0.9718 - recall_22: 0.9553\n",
      "Epoch 19: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0110 - precision_22: 0.9719 - recall_22: 0.9553 - val_loss: 0.1036 - val_precision_22: 0.7183 - val_recall_22: 0.6463\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - precision_22: 0.9735 - recall_22: 0.9561\n",
      "Epoch 20: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - precision_22: 0.9735 - recall_22: 0.9563 - val_loss: 0.1040 - val_precision_22: 0.7279 - val_recall_22: 0.6607\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - precision_22: 0.9793 - recall_22: 0.9625\n",
      "Epoch 21: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - precision_22: 0.9791 - recall_22: 0.9625 - val_loss: 0.1054 - val_precision_22: 0.7165 - val_recall_22: 0.6690\n",
      "Epoch 22/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0086 - precision_22: 0.9791 - recall_22: 0.9661\n",
      "Epoch 22: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - precision_22: 0.9791 - recall_22: 0.9661 - val_loss: 0.1078 - val_precision_22: 0.7136 - val_recall_22: 0.6632\n",
      "Epoch 23/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0079 - precision_22: 0.9799 - recall_22: 0.9683\n",
      "Epoch 23: val_loss did not improve from 0.09553\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - precision_22: 0.9798 - recall_22: 0.9686 - val_loss: 0.1079 - val_precision_22: 0.7170 - val_recall_22: 0.6619\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0141 - precision_22: 0.9716 - recall_22: 0.9399\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0972 - precision_22: 0.7174 - recall_22: 0.6064 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1025 - precision_22: 0.7265 - recall_22: 0.5847 \n",
      "Epoch 1/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.4362 - precision_23: 0.0568 - recall_23: 0.1569\n",
      "Epoch 1: val_loss improved from inf to 0.20514, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.4292 - precision_23: 0.0575 - recall_23: 0.1521 - val_loss: 0.2051 - val_precision_23: 0.3273 - val_recall_23: 0.0030\n",
      "Epoch 2/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1982 - precision_23: 0.2214 - recall_23: 0.0126\n",
      "Epoch 2: val_loss improved from 0.20514 to 0.18590, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1974 - precision_23: 0.2216 - recall_23: 0.0121 - val_loss: 0.1859 - val_precision_23: 0.0000e+00 - val_recall_23: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1654 - precision_23: 0.5454 - recall_23: 0.0068\n",
      "Epoch 3: val_loss improved from 0.18590 to 0.15305, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.1652 - precision_23: 0.5435 - recall_23: 0.0070 - val_loss: 0.1531 - val_precision_23: 0.4930 - val_recall_23: 0.0350\n",
      "Epoch 4/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1487 - precision_23: 0.4997 - recall_23: 0.1019\n",
      "Epoch 4: val_loss did not improve from 0.15305\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1486 - precision_23: 0.5004 - recall_23: 0.1021 - val_loss: 0.1585 - val_precision_23: 0.6400 - val_recall_23: 0.0080\n",
      "Epoch 5/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1460 - precision_23: 0.5802 - recall_23: 0.1456\n",
      "Epoch 5: val_loss improved from 0.15305 to 0.13625, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1457 - precision_23: 0.5773 - recall_23: 0.1513 - val_loss: 0.1363 - val_precision_23: 0.6178 - val_recall_23: 0.0887\n",
      "Epoch 6/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1229 - precision_23: 0.7270 - recall_23: 0.1644\n",
      "Epoch 6: val_loss did not improve from 0.13625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1226 - precision_23: 0.7240 - recall_23: 0.1697 - val_loss: 0.1578 - val_precision_23: 0.4816 - val_recall_23: 0.3909\n",
      "Epoch 7/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1064 - precision_23: 0.7140 - recall_23: 0.4258\n",
      "Epoch 7: val_loss improved from 0.13625 to 0.13149, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.1053 - precision_23: 0.7242 - recall_23: 0.4135 - val_loss: 0.1315 - val_precision_23: 0.5774 - val_recall_23: 0.3814\n",
      "Epoch 8/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0847 - precision_23: 0.7547 - recall_23: 0.5487\n",
      "Epoch 8: val_loss improved from 0.13149 to 0.11555, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0840 - precision_23: 0.7583 - recall_23: 0.5472 - val_loss: 0.1155 - val_precision_23: 0.6804 - val_recall_23: 0.2894\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0711 - precision_23: 0.8639 - recall_23: 0.5370\n",
      "Epoch 9: val_loss improved from 0.11555 to 0.11135, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0708 - precision_23: 0.8620 - recall_23: 0.5417 - val_loss: 0.1114 - val_precision_23: 0.6594 - val_recall_23: 0.4631\n",
      "Epoch 10/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0570 - precision_23: 0.8915 - recall_23: 0.6462\n",
      "Epoch 10: val_loss did not improve from 0.11135\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0567 - precision_23: 0.8915 - recall_23: 0.6473 - val_loss: 0.1121 - val_precision_23: 0.6299 - val_recall_23: 0.5690\n",
      "Epoch 11/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0483 - precision_23: 0.8699 - recall_23: 0.7657\n",
      "Epoch 11: val_loss improved from 0.11135 to 0.09954, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0480 - precision_23: 0.8741 - recall_23: 0.7598 - val_loss: 0.0995 - val_precision_23: 0.6938 - val_recall_23: 0.5488\n",
      "Epoch 12/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0416 - precision_23: 0.9098 - recall_23: 0.7720\n",
      "Epoch 12: val_loss improved from 0.09954 to 0.09615, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0414 - precision_23: 0.9072 - recall_23: 0.7757 - val_loss: 0.0961 - val_precision_23: 0.7266 - val_recall_23: 0.5639\n",
      "Epoch 13/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0363 - precision_23: 0.9304 - recall_23: 0.7779\n",
      "Epoch 13: val_loss did not improve from 0.09615\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0360 - precision_23: 0.9295 - recall_23: 0.7816 - val_loss: 0.0969 - val_precision_23: 0.6920 - val_recall_23: 0.6222\n",
      "Epoch 14/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0319 - precision_23: 0.9198 - recall_23: 0.8339\n",
      "Epoch 14: val_loss improved from 0.09615 to 0.09520, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0317 - precision_23: 0.9213 - recall_23: 0.8337 - val_loss: 0.0952 - val_precision_23: 0.7085 - val_recall_23: 0.6357\n",
      "Epoch 15/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0272 - precision_23: 0.9333 - recall_23: 0.8591\n",
      "Epoch 15: val_loss did not improve from 0.09520\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0272 - precision_23: 0.9332 - recall_23: 0.8597 - val_loss: 0.0969 - val_precision_23: 0.7168 - val_recall_23: 0.6324\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0238 - precision_23: 0.9491 - recall_23: 0.8714\n",
      "Epoch 16: val_loss improved from 0.09520 to 0.09430, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0237 - precision_23: 0.9481 - recall_23: 0.8732 - val_loss: 0.0943 - val_precision_23: 0.7113 - val_recall_23: 0.6574\n",
      "Epoch 17/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0207 - precision_23: 0.9472 - recall_23: 0.8991\n",
      "Epoch 17: val_loss improved from 0.09430 to 0.09343, saving model to 62sec_2layers_2048units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0206 - precision_23: 0.9474 - recall_23: 0.8993 - val_loss: 0.0934 - val_precision_23: 0.7189 - val_recall_23: 0.6561\n",
      "Epoch 18/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0189 - precision_23: 0.9531 - recall_23: 0.9099\n",
      "Epoch 18: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0188 - precision_23: 0.9532 - recall_23: 0.9100 - val_loss: 0.0959 - val_precision_23: 0.7105 - val_recall_23: 0.6647\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0177 - precision_23: 0.9519 - recall_23: 0.9182\n",
      "Epoch 19: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0177 - precision_23: 0.9521 - recall_23: 0.9183 - val_loss: 0.0976 - val_precision_23: 0.7157 - val_recall_23: 0.6680\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0151 - precision_23: 0.9598 - recall_23: 0.9325\n",
      "Epoch 20: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0151 - precision_23: 0.9598 - recall_23: 0.9326 - val_loss: 0.0964 - val_precision_23: 0.7178 - val_recall_23: 0.6610\n",
      "Epoch 21/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0142 - precision_23: 0.9668 - recall_23: 0.9363\n",
      "Epoch 21: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0140 - precision_23: 0.9665 - recall_23: 0.9370 - val_loss: 0.0995 - val_precision_23: 0.7187 - val_recall_23: 0.6657\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0124 - precision_23: 0.9684 - recall_23: 0.9443\n",
      "Epoch 22: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0124 - precision_23: 0.9684 - recall_23: 0.9444 - val_loss: 0.1014 - val_precision_23: 0.7027 - val_recall_23: 0.6657\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0116 - precision_23: 0.9708 - recall_23: 0.9533\n",
      "Epoch 23: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0116 - precision_23: 0.9708 - recall_23: 0.9532 - val_loss: 0.0986 - val_precision_23: 0.7150 - val_recall_23: 0.6675\n",
      "Epoch 24/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0110 - precision_23: 0.9705 - recall_23: 0.9540\n",
      "Epoch 24: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0110 - precision_23: 0.9706 - recall_23: 0.9541 - val_loss: 0.1047 - val_precision_23: 0.7097 - val_recall_23: 0.6721\n",
      "Epoch 25/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - precision_23: 0.9726 - recall_23: 0.9629\n",
      "Epoch 25: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0103 - precision_23: 0.9727 - recall_23: 0.9627 - val_loss: 0.1034 - val_precision_23: 0.7131 - val_recall_23: 0.6728\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0098 - precision_23: 0.9730 - recall_23: 0.9602\n",
      "Epoch 26: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0098 - precision_23: 0.9730 - recall_23: 0.9604 - val_loss: 0.1064 - val_precision_23: 0.7120 - val_recall_23: 0.6731\n",
      "Epoch 27/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - precision_23: 0.9755 - recall_23: 0.9629\n",
      "Epoch 27: val_loss did not improve from 0.09343\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0092 - precision_23: 0.9754 - recall_23: 0.9629 - val_loss: 0.1047 - val_precision_23: 0.7116 - val_recall_23: 0.6726\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - precision_23: 0.9802 - recall_23: 0.9757\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0944 - precision_23: 0.7103 - recall_23: 0.6540 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1026 - precision_23: 0.7194 - recall_23: 0.6266 \n",
      "Epoch 1/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6276 - precision_24: 0.0497 - recall_24: 0.3173  \n",
      "Epoch 1: val_loss improved from inf to 0.24783, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5810 - precision_24: 0.0496 - recall_24: 0.2643 - val_loss: 0.2478 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2624 - precision_24: 0.1391 - recall_24: 0.0139 \n",
      "Epoch 2: val_loss improved from 0.24783 to 0.20155, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2542 - precision_24: 0.1416 - recall_24: 0.0190 - val_loss: 0.2015 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2163 - precision_24: 0.1698 - recall_24: 0.0060 \n",
      "Epoch 3: val_loss improved from 0.20155 to 0.19930, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2130 - precision_24: 0.1729 - recall_24: 0.0052 - val_loss: 0.1993 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1925 - precision_24: 0.1665 - recall_24: 7.8707e-04 \n",
      "Epoch 4: val_loss improved from 0.19930 to 0.18522, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1892 - precision_24: 0.1911 - recall_24: 7.7923e-04 - val_loss: 0.1852 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1759 - precision_24: 0.2807 - recall_24: 4.2524e-04 \n",
      "Epoch 5: val_loss improved from 0.18522 to 0.17374, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1737 - precision_24: 0.2966 - recall_24: 3.7437e-04 - val_loss: 0.1737 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1668 - precision_24: 0.4290 - recall_24: 4.9911e-04 \n",
      "Epoch 6: val_loss improved from 0.17374 to 0.16248, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1656 - precision_24: 0.3937 - recall_24: 5.7363e-04 - val_loss: 0.1625 - val_precision_24: 0.0000e+00 - val_recall_24: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1601 - precision_24: 0.4143 - recall_24: 0.0031     \n",
      "Epoch 7: val_loss improved from 0.16248 to 0.15474, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1581 - precision_24: 0.4090 - recall_24: 0.0047 - val_loss: 0.1547 - val_precision_24: 0.4286 - val_recall_24: 4.9727e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1556 - precision_24: 0.4100 - recall_24: 0.0145 \n",
      "Epoch 8: val_loss improved from 0.15474 to 0.14970, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1533 - precision_24: 0.4190 - recall_24: 0.0182 - val_loss: 0.1497 - val_precision_24: 0.4545 - val_recall_24: 0.0075\n",
      "Epoch 9/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1467 - precision_24: 0.4094 - recall_24: 0.0326\n",
      "Epoch 9: val_loss did not improve from 0.14970\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1465 - precision_24: 0.4104 - recall_24: 0.0334 - val_loss: 0.1539 - val_precision_24: 0.4522 - val_recall_24: 0.0525\n",
      "Epoch 10/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1446 - precision_24: 0.4159 - recall_24: 0.0541 \n",
      "Epoch 10: val_loss did not improve from 0.14970\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1429 - precision_24: 0.4303 - recall_24: 0.0573 - val_loss: 0.1614 - val_precision_24: 0.4569 - val_recall_24: 0.0983\n",
      "Epoch 11/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1434 - precision_24: 0.4000 - recall_24: 0.0759 \n",
      "Epoch 11: val_loss did not improve from 0.14970\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1409 - precision_24: 0.4287 - recall_24: 0.0722 - val_loss: 0.1517 - val_precision_24: 0.4515 - val_recall_24: 0.0995\n",
      "Epoch 12/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1372 - precision_24: 0.4822 - recall_24: 0.1076\n",
      "Epoch 12: val_loss improved from 0.14970 to 0.14010, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1369 - precision_24: 0.4851 - recall_24: 0.1069 - val_loss: 0.1401 - val_precision_24: 0.5015 - val_recall_24: 0.0537\n",
      "Epoch 13/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1348 - precision_24: 0.5190 - recall_24: 0.1005\n",
      "Epoch 13: val_loss improved from 0.14010 to 0.14001, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1344 - precision_24: 0.5206 - recall_24: 0.1051 - val_loss: 0.1400 - val_precision_24: 0.5124 - val_recall_24: 0.0822\n",
      "Epoch 14/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1299 - precision_24: 0.5705 - recall_24: 0.1057\n",
      "Epoch 14: val_loss did not improve from 0.14001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1295 - precision_24: 0.5726 - recall_24: 0.1104 - val_loss: 0.1481 - val_precision_24: 0.4717 - val_recall_24: 0.1797\n",
      "Epoch 15/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1242 - precision_24: 0.6037 - recall_24: 0.1664\n",
      "Epoch 15: val_loss did not improve from 0.14001\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1236 - precision_24: 0.6056 - recall_24: 0.1679 - val_loss: 0.1484 - val_precision_24: 0.4700 - val_recall_24: 0.2219\n",
      "Epoch 16/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1190 - precision_24: 0.6293 - recall_24: 0.2431\n",
      "Epoch 16: val_loss improved from 0.14001 to 0.13591, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1186 - precision_24: 0.6322 - recall_24: 0.2407 - val_loss: 0.1359 - val_precision_24: 0.5286 - val_recall_24: 0.1959\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1119 - precision_24: 0.6865 - recall_24: 0.2606\n",
      "Epoch 17: val_loss improved from 0.13591 to 0.13251, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1117 - precision_24: 0.6849 - recall_24: 0.2639 - val_loss: 0.1325 - val_precision_24: 0.5726 - val_recall_24: 0.2347\n",
      "Epoch 18/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1074 - precision_24: 0.7159 - recall_24: 0.2844 \n",
      "Epoch 18: val_loss improved from 0.13251 to 0.13101, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1069 - precision_24: 0.7081 - recall_24: 0.2958 - val_loss: 0.1310 - val_precision_24: 0.5570 - val_recall_24: 0.2841\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1022 - precision_24: 0.7221 - recall_24: 0.3226\n",
      "Epoch 19: val_loss did not improve from 0.13101\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1022 - precision_24: 0.7210 - recall_24: 0.3239 - val_loss: 0.1352 - val_precision_24: 0.5391 - val_recall_24: 0.3567\n",
      "Epoch 20/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0986 - precision_24: 0.7134 - recall_24: 0.3877\n",
      "Epoch 20: val_loss improved from 0.13101 to 0.12838, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0984 - precision_24: 0.7150 - recall_24: 0.3863 - val_loss: 0.1284 - val_precision_24: 0.5784 - val_recall_24: 0.3466\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0968 - precision_24: 0.7163 - recall_24: 0.4186\n",
      "Epoch 21: val_loss improved from 0.12838 to 0.12196, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0966 - precision_24: 0.7167 - recall_24: 0.4188 - val_loss: 0.1220 - val_precision_24: 0.6083 - val_recall_24: 0.3413\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0932 - precision_24: 0.7437 - recall_24: 0.4142\n",
      "Epoch 22: val_loss improved from 0.12196 to 0.12162, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0931 - precision_24: 0.7430 - recall_24: 0.4157 - val_loss: 0.1216 - val_precision_24: 0.5825 - val_recall_24: 0.3688\n",
      "Epoch 23/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0894 - precision_24: 0.7595 - recall_24: 0.4501\n",
      "Epoch 23: val_loss did not improve from 0.12162\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0893 - precision_24: 0.7587 - recall_24: 0.4504 - val_loss: 0.1237 - val_precision_24: 0.5734 - val_recall_24: 0.4034\n",
      "Epoch 24/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0875 - precision_24: 0.7576 - recall_24: 0.4802\n",
      "Epoch 24: val_loss improved from 0.12162 to 0.11915, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0873 - precision_24: 0.7578 - recall_24: 0.4801 - val_loss: 0.1192 - val_precision_24: 0.6147 - val_recall_24: 0.4096\n",
      "Epoch 25/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0862 - precision_24: 0.7529 - recall_24: 0.4766\n",
      "Epoch 25: val_loss improved from 0.11915 to 0.11864, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0859 - precision_24: 0.7523 - recall_24: 0.4779 - val_loss: 0.1186 - val_precision_24: 0.6077 - val_recall_24: 0.4194\n",
      "Epoch 26/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0820 - precision_24: 0.7822 - recall_24: 0.4998\n",
      "Epoch 26: val_loss did not improve from 0.11864\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - precision_24: 0.7813 - recall_24: 0.5016 - val_loss: 0.1198 - val_precision_24: 0.5903 - val_recall_24: 0.4452\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0803 - precision_24: 0.7767 - recall_24: 0.5233\n",
      "Epoch 27: val_loss did not improve from 0.11864\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0802 - precision_24: 0.7759 - recall_24: 0.5235 - val_loss: 0.1194 - val_precision_24: 0.6023 - val_recall_24: 0.4412\n",
      "Epoch 28/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0780 - precision_24: 0.7796 - recall_24: 0.5330\n",
      "Epoch 28: val_loss improved from 0.11864 to 0.11798, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0780 - precision_24: 0.7795 - recall_24: 0.5326 - val_loss: 0.1180 - val_precision_24: 0.6185 - val_recall_24: 0.4606\n",
      "Epoch 29/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0769 - precision_24: 0.7947 - recall_24: 0.5429\n",
      "Epoch 29: val_loss improved from 0.11798 to 0.11727, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0767 - precision_24: 0.7935 - recall_24: 0.5443 - val_loss: 0.1173 - val_precision_24: 0.6211 - val_recall_24: 0.4697\n",
      "Epoch 30/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0746 - precision_24: 0.7975 - recall_24: 0.5721 \n",
      "Epoch 30: val_loss improved from 0.11727 to 0.11596, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0743 - precision_24: 0.7930 - recall_24: 0.5706 - val_loss: 0.1160 - val_precision_24: 0.6198 - val_recall_24: 0.4807\n",
      "Epoch 31/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0735 - precision_24: 0.7917 - recall_24: 0.5678\n",
      "Epoch 31: val_loss improved from 0.11596 to 0.11386, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0735 - precision_24: 0.7914 - recall_24: 0.5680 - val_loss: 0.1139 - val_precision_24: 0.6299 - val_recall_24: 0.4721\n",
      "Epoch 32/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0734 - precision_24: 0.8071 - recall_24: 0.5619\n",
      "Epoch 32: val_loss did not improve from 0.11386\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0731 - precision_24: 0.8051 - recall_24: 0.5640 - val_loss: 0.1147 - val_precision_24: 0.6128 - val_recall_24: 0.4848\n",
      "Epoch 33/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0704 - precision_24: 0.7950 - recall_24: 0.5852\n",
      "Epoch 33: val_loss improved from 0.11386 to 0.11371, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0703 - precision_24: 0.7944 - recall_24: 0.5865 - val_loss: 0.1137 - val_precision_24: 0.6381 - val_recall_24: 0.4867\n",
      "Epoch 34/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0687 - precision_24: 0.8195 - recall_24: 0.5853\n",
      "Epoch 34: val_loss improved from 0.11371 to 0.11274, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0687 - precision_24: 0.8177 - recall_24: 0.5868 - val_loss: 0.1127 - val_precision_24: 0.6336 - val_recall_24: 0.5004\n",
      "Epoch 35/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680 - precision_24: 0.8010 - recall_24: 0.6092\n",
      "Epoch 35: val_loss improved from 0.11274 to 0.11173, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0680 - precision_24: 0.8012 - recall_24: 0.6094 - val_loss: 0.1117 - val_precision_24: 0.6364 - val_recall_24: 0.5047\n",
      "Epoch 36/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0669 - precision_24: 0.8242 - recall_24: 0.6233 \n",
      "Epoch 36: val_loss did not improve from 0.11173\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0664 - precision_24: 0.8222 - recall_24: 0.6205 - val_loss: 0.1125 - val_precision_24: 0.6293 - val_recall_24: 0.5051\n",
      "Epoch 37/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0680 - precision_24: 0.8200 - recall_24: 0.6137 \n",
      "Epoch 37: val_loss improved from 0.11173 to 0.11007, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0667 - precision_24: 0.8158 - recall_24: 0.6208 - val_loss: 0.1101 - val_precision_24: 0.6433 - val_recall_24: 0.5175\n",
      "Epoch 38/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0652 - precision_24: 0.8289 - recall_24: 0.6290\n",
      "Epoch 38: val_loss did not improve from 0.11007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0649 - precision_24: 0.8275 - recall_24: 0.6299 - val_loss: 0.1122 - val_precision_24: 0.6306 - val_recall_24: 0.5286\n",
      "Epoch 39/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0636 - precision_24: 0.8138 - recall_24: 0.6469\n",
      "Epoch 39: val_loss did not improve from 0.11007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0635 - precision_24: 0.8141 - recall_24: 0.6468 - val_loss: 0.1130 - val_precision_24: 0.6273 - val_recall_24: 0.5165\n",
      "Epoch 40/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0621 - precision_24: 0.8329 - recall_24: 0.6496\n",
      "Epoch 40: val_loss did not improve from 0.11007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0618 - precision_24: 0.8311 - recall_24: 0.6513 - val_loss: 0.1111 - val_precision_24: 0.6303 - val_recall_24: 0.5268\n",
      "Epoch 41/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0626 - precision_24: 0.8250 - recall_24: 0.6370\n",
      "Epoch 41: val_loss improved from 0.11007 to 0.10914, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0622 - precision_24: 0.8259 - recall_24: 0.6399 - val_loss: 0.1091 - val_precision_24: 0.6431 - val_recall_24: 0.5226\n",
      "Epoch 42/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0595 - precision_24: 0.8432 - recall_24: 0.6573\n",
      "Epoch 42: val_loss did not improve from 0.10914\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0594 - precision_24: 0.8429 - recall_24: 0.6574 - val_loss: 0.1111 - val_precision_24: 0.6137 - val_recall_24: 0.5400\n",
      "Epoch 43/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0572 - precision_24: 0.8320 - recall_24: 0.6920\n",
      "Epoch 43: val_loss improved from 0.10914 to 0.10872, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0571 - precision_24: 0.8318 - recall_24: 0.6920 - val_loss: 0.1087 - val_precision_24: 0.6491 - val_recall_24: 0.5359\n",
      "Epoch 44/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0565 - precision_24: 0.8427 - recall_24: 0.6853\n",
      "Epoch 44: val_loss improved from 0.10872 to 0.10853, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0565 - precision_24: 0.8427 - recall_24: 0.6855 - val_loss: 0.1085 - val_precision_24: 0.6400 - val_recall_24: 0.5331\n",
      "Epoch 45/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0559 - precision_24: 0.8510 - recall_24: 0.6856\n",
      "Epoch 45: val_loss improved from 0.10853 to 0.10715, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0558 - precision_24: 0.8503 - recall_24: 0.6856 - val_loss: 0.1072 - val_precision_24: 0.6414 - val_recall_24: 0.5428\n",
      "Epoch 46/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0561 - precision_24: 0.8424 - recall_24: 0.6889\n",
      "Epoch 46: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0558 - precision_24: 0.8427 - recall_24: 0.6897 - val_loss: 0.1073 - val_precision_24: 0.6402 - val_recall_24: 0.5495\n",
      "Epoch 47/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0545 - precision_24: 0.8436 - recall_24: 0.6951\n",
      "Epoch 47: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0545 - precision_24: 0.8417 - recall_24: 0.6974 - val_loss: 0.1116 - val_precision_24: 0.6325 - val_recall_24: 0.5515\n",
      "Epoch 48/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0534 - precision_24: 0.8539 - recall_24: 0.6997\n",
      "Epoch 48: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0532 - precision_24: 0.8542 - recall_24: 0.7004 - val_loss: 0.1082 - val_precision_24: 0.6352 - val_recall_24: 0.5692\n",
      "Epoch 49/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0517 - precision_24: 0.8512 - recall_24: 0.7182\n",
      "Epoch 49: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0516 - precision_24: 0.8501 - recall_24: 0.7190 - val_loss: 0.1073 - val_precision_24: 0.6496 - val_recall_24: 0.5495\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0513 - precision_24: 0.8493 - recall_24: 0.7167\n",
      "Epoch 50: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0512 - precision_24: 0.8494 - recall_24: 0.7170 - val_loss: 0.1086 - val_precision_24: 0.6477 - val_recall_24: 0.5674\n",
      "Epoch 51/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0520 - precision_24: 0.8485 - recall_24: 0.7102\n",
      "Epoch 51: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0518 - precision_24: 0.8487 - recall_24: 0.7116 - val_loss: 0.1086 - val_precision_24: 0.6387 - val_recall_24: 0.5619\n",
      "Epoch 52/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0503 - precision_24: 0.8500 - recall_24: 0.7339\n",
      "Epoch 52: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0501 - precision_24: 0.8503 - recall_24: 0.7341 - val_loss: 0.1088 - val_precision_24: 0.6477 - val_recall_24: 0.5694\n",
      "Epoch 53/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0487 - precision_24: 0.8619 - recall_24: 0.7395\n",
      "Epoch 53: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0486 - precision_24: 0.8616 - recall_24: 0.7398 - val_loss: 0.1084 - val_precision_24: 0.6529 - val_recall_24: 0.5702\n",
      "Epoch 54/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0491 - precision_24: 0.8633 - recall_24: 0.7262\n",
      "Epoch 54: val_loss did not improve from 0.10715\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0488 - precision_24: 0.8629 - recall_24: 0.7286 - val_loss: 0.1077 - val_precision_24: 0.6444 - val_recall_24: 0.5919\n",
      "Epoch 55/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0490 - precision_24: 0.8506 - recall_24: 0.7344\n",
      "Epoch 55: val_loss improved from 0.10715 to 0.10697, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0488 - precision_24: 0.8514 - recall_24: 0.7352 - val_loss: 0.1070 - val_precision_24: 0.6573 - val_recall_24: 0.5803\n",
      "Epoch 56/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0473 - precision_24: 0.8635 - recall_24: 0.7342\n",
      "Epoch 56: val_loss improved from 0.10697 to 0.10612, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0471 - precision_24: 0.8635 - recall_24: 0.7361 - val_loss: 0.1061 - val_precision_24: 0.6648 - val_recall_24: 0.5820\n",
      "Epoch 57/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0461 - precision_24: 0.8634 - recall_24: 0.7523\n",
      "Epoch 57: val_loss improved from 0.10612 to 0.10583, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0460 - precision_24: 0.8636 - recall_24: 0.7526 - val_loss: 0.1058 - val_precision_24: 0.6565 - val_recall_24: 0.5863\n",
      "Epoch 58/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0456 - precision_24: 0.8677 - recall_24: 0.7562\n",
      "Epoch 58: val_loss improved from 0.10583 to 0.10535, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0455 - precision_24: 0.8675 - recall_24: 0.7564 - val_loss: 0.1053 - val_precision_24: 0.6569 - val_recall_24: 0.5815\n",
      "Epoch 59/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0456 - precision_24: 0.8697 - recall_24: 0.7488\n",
      "Epoch 59: val_loss improved from 0.10535 to 0.10250, saving model to 62sec_3layers_256units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0454 - precision_24: 0.8693 - recall_24: 0.7503 - val_loss: 0.1025 - val_precision_24: 0.6569 - val_recall_24: 0.5898\n",
      "Epoch 60/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0442 - precision_24: 0.8752 - recall_24: 0.7607\n",
      "Epoch 60: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0440 - precision_24: 0.8750 - recall_24: 0.7612 - val_loss: 0.1044 - val_precision_24: 0.6568 - val_recall_24: 0.5985\n",
      "Epoch 61/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0440 - precision_24: 0.8696 - recall_24: 0.7569\n",
      "Epoch 61: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0439 - precision_24: 0.8694 - recall_24: 0.7572 - val_loss: 0.1050 - val_precision_24: 0.6474 - val_recall_24: 0.5954\n",
      "Epoch 62/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0438 - precision_24: 0.8671 - recall_24: 0.7642\n",
      "Epoch 62: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0437 - precision_24: 0.8674 - recall_24: 0.7647 - val_loss: 0.1057 - val_precision_24: 0.6508 - val_recall_24: 0.5878\n",
      "Epoch 63/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0436 - precision_24: 0.8640 - recall_24: 0.7713 \n",
      "Epoch 63: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0427 - precision_24: 0.8669 - recall_24: 0.7738 - val_loss: 0.1058 - val_precision_24: 0.6489 - val_recall_24: 0.5903\n",
      "Epoch 64/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0412 - precision_24: 0.8827 - recall_24: 0.7819\n",
      "Epoch 64: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0411 - precision_24: 0.8823 - recall_24: 0.7823 - val_loss: 0.1051 - val_precision_24: 0.6488 - val_recall_24: 0.6029\n",
      "Epoch 65/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0427 - precision_24: 0.8759 - recall_24: 0.7692\n",
      "Epoch 65: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0426 - precision_24: 0.8759 - recall_24: 0.7697 - val_loss: 0.1052 - val_precision_24: 0.6545 - val_recall_24: 0.6035\n",
      "Epoch 66/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0405 - precision_24: 0.8906 - recall_24: 0.7825\n",
      "Epoch 66: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0404 - precision_24: 0.8899 - recall_24: 0.7835 - val_loss: 0.1040 - val_precision_24: 0.6519 - val_recall_24: 0.6045\n",
      "Epoch 67/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0412 - precision_24: 0.8735 - recall_24: 0.7796\n",
      "Epoch 67: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0411 - precision_24: 0.8736 - recall_24: 0.7798 - val_loss: 0.1053 - val_precision_24: 0.6639 - val_recall_24: 0.5956\n",
      "Epoch 68/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0403 - precision_24: 0.8747 - recall_24: 0.7885\n",
      "Epoch 68: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0402 - precision_24: 0.8752 - recall_24: 0.7891 - val_loss: 0.1057 - val_precision_24: 0.6494 - val_recall_24: 0.6140\n",
      "Epoch 69/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0393 - precision_24: 0.8804 - recall_24: 0.7962\n",
      "Epoch 69: val_loss did not improve from 0.10250\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0393 - precision_24: 0.8805 - recall_24: 0.7964 - val_loss: 0.1051 - val_precision_24: 0.6621 - val_recall_24: 0.6057\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0228 - precision_24: 0.9536 - recall_24: 0.8979 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1052 - precision_24: 0.6420 - recall_24: 0.5804 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1128 - precision_24: 0.6577 - recall_24: 0.5615\n",
      "Epoch 1/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6426 - precision_25: 0.0497 - recall_25: 0.3413  \n",
      "Epoch 1: val_loss improved from inf to 0.25743, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5863 - precision_25: 0.0493 - recall_25: 0.2746 - val_loss: 0.2574 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2712 - precision_25: 0.1533 - recall_25: 0.0125 \n",
      "Epoch 2: val_loss improved from 0.25743 to 0.20544, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2613 - precision_25: 0.1518 - recall_25: 0.0184 - val_loss: 0.2054 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2189 - precision_25: 0.1323 - recall_25: 0.0126 \n",
      "Epoch 3: val_loss improved from 0.20544 to 0.19981, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2148 - precision_25: 0.1346 - recall_25: 0.0103 - val_loss: 0.1998 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1933 - precision_25: 0.1341 - recall_25: 0.0018 \n",
      "Epoch 4: val_loss improved from 0.19981 to 0.18257, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1904 - precision_25: 0.1480 - recall_25: 0.0017 - val_loss: 0.1826 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1782 - precision_25: 0.1943 - recall_25: 5.7494e-04\n",
      "Epoch 5: val_loss improved from 0.18257 to 0.17243, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1765 - precision_25: 0.1966 - recall_25: 5.0592e-04 - val_loss: 0.1724 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1719 - precision_25: 0.5197 - recall_25: 5.1300e-04 \n",
      "Epoch 6: val_loss improved from 0.17243 to 0.16693, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1705 - precision_25: 0.5063 - recall_25: 5.2042e-04 - val_loss: 0.1669 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1687 - precision_25: 0.4216 - recall_25: 6.8566e-04 \n",
      "Epoch 7: val_loss improved from 0.16693 to 0.16380, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1671 - precision_25: 0.4365 - recall_25: 0.0011 - val_loss: 0.1638 - val_precision_25: 0.0000e+00 - val_recall_25: 0.0000e+00\n",
      "Epoch 8/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1628 - precision_25: 0.3570 - recall_25: 0.0044\n",
      "Epoch 8: val_loss improved from 0.16380 to 0.16309, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1626 - precision_25: 0.3589 - recall_25: 0.0045 - val_loss: 0.1631 - val_precision_25: 0.8000 - val_recall_25: 0.0013\n",
      "Epoch 9/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1569 - precision_25: 0.3710 - recall_25: 0.0135 \n",
      "Epoch 9: val_loss improved from 0.16309 to 0.16214, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1554 - precision_25: 0.3743 - recall_25: 0.0155 - val_loss: 0.1621 - val_precision_25: 0.5336 - val_recall_25: 0.0237\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1506 - precision_25: 0.3847 - recall_25: 0.0329\n",
      "Epoch 10: val_loss improved from 0.16214 to 0.15276, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1504 - precision_25: 0.3857 - recall_25: 0.0328 - val_loss: 0.1528 - val_precision_25: 0.4867 - val_recall_25: 0.0515\n",
      "Epoch 11/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1474 - precision_25: 0.4199 - recall_25: 0.0595\n",
      "Epoch 11: val_loss improved from 0.15276 to 0.14386, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1471 - precision_25: 0.4211 - recall_25: 0.0595 - val_loss: 0.1439 - val_precision_25: 0.5537 - val_recall_25: 0.0444\n",
      "Epoch 12/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1446 - precision_25: 0.4234 - recall_25: 0.0555\n",
      "Epoch 12: val_loss did not improve from 0.14386\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1444 - precision_25: 0.4240 - recall_25: 0.0562 - val_loss: 0.1454 - val_precision_25: 0.5151 - val_recall_25: 0.0708\n",
      "Epoch 13/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1416 - precision_25: 0.4525 - recall_25: 0.0652\n",
      "Epoch 13: val_loss did not improve from 0.14386\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1415 - precision_25: 0.4532 - recall_25: 0.0661 - val_loss: 0.1537 - val_precision_25: 0.4660 - val_recall_25: 0.0988\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1400 - precision_25: 0.4627 - recall_25: 0.0793\n",
      "Epoch 14: val_loss did not improve from 0.14386\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1398 - precision_25: 0.4646 - recall_25: 0.0792 - val_loss: 0.1508 - val_precision_25: 0.4662 - val_recall_25: 0.1074\n",
      "Epoch 15/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1369 - precision_25: 0.4952 - recall_25: 0.0957\n",
      "Epoch 15: val_loss improved from 0.14386 to 0.14005, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1366 - precision_25: 0.4978 - recall_25: 0.0956 - val_loss: 0.1401 - val_precision_25: 0.4735 - val_recall_25: 0.0991\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1351 - precision_25: 0.5260 - recall_25: 0.0988\n",
      "Epoch 16: val_loss did not improve from 0.14005\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1349 - precision_25: 0.5263 - recall_25: 0.0998 - val_loss: 0.1410 - val_precision_25: 0.4934 - val_recall_25: 0.1179\n",
      "Epoch 17/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1327 - precision_25: 0.5764 - recall_25: 0.1007\n",
      "Epoch 17: val_loss did not improve from 0.14005\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1325 - precision_25: 0.5742 - recall_25: 0.1035 - val_loss: 0.1466 - val_precision_25: 0.4715 - val_recall_25: 0.1810\n",
      "Epoch 18/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1286 - precision_25: 0.5848 - recall_25: 0.1494\n",
      "Epoch 18: val_loss did not improve from 0.14005\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1283 - precision_25: 0.5858 - recall_25: 0.1493 - val_loss: 0.1431 - val_precision_25: 0.4911 - val_recall_25: 0.1974\n",
      "Epoch 19/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1260 - precision_25: 0.5961 - recall_25: 0.1801\n",
      "Epoch 19: val_loss improved from 0.14005 to 0.13858, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1257 - precision_25: 0.5970 - recall_25: 0.1807 - val_loss: 0.1386 - val_precision_25: 0.5297 - val_recall_25: 0.2057\n",
      "Epoch 20/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1211 - precision_25: 0.6134 - recall_25: 0.1989\n",
      "Epoch 20: val_loss improved from 0.13858 to 0.13414, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1209 - precision_25: 0.6137 - recall_25: 0.2007 - val_loss: 0.1341 - val_precision_25: 0.5677 - val_recall_25: 0.2147\n",
      "Epoch 21/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1183 - precision_25: 0.6520 - recall_25: 0.2148\n",
      "Epoch 21: val_loss did not improve from 0.13414\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1180 - precision_25: 0.6521 - recall_25: 0.2179 - val_loss: 0.1351 - val_precision_25: 0.5587 - val_recall_25: 0.2657\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1144 - precision_25: 0.6669 - recall_25: 0.2521\n",
      "Epoch 22: val_loss improved from 0.13414 to 0.13358, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1142 - precision_25: 0.6670 - recall_25: 0.2528 - val_loss: 0.1336 - val_precision_25: 0.5544 - val_recall_25: 0.2667\n",
      "Epoch 23/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1118 - precision_25: 0.6674 - recall_25: 0.2802\n",
      "Epoch 23: val_loss improved from 0.13358 to 0.13117, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1115 - precision_25: 0.6698 - recall_25: 0.2815 - val_loss: 0.1312 - val_precision_25: 0.5669 - val_recall_25: 0.2710\n",
      "Epoch 24/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1079 - precision_25: 0.7080 - recall_25: 0.2993\n",
      "Epoch 24: val_loss improved from 0.13117 to 0.13015, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1076 - precision_25: 0.7067 - recall_25: 0.3029 - val_loss: 0.1301 - val_precision_25: 0.5548 - val_recall_25: 0.3254\n",
      "Epoch 25/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1069 - precision_25: 0.6721 - recall_25: 0.3328\n",
      "Epoch 25: val_loss improved from 0.13015 to 0.12458, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1066 - precision_25: 0.6729 - recall_25: 0.3336 - val_loss: 0.1246 - val_precision_25: 0.6138 - val_recall_25: 0.3262\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1010 - precision_25: 0.7221 - recall_25: 0.3539\n",
      "Epoch 26: val_loss did not improve from 0.12458\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1010 - precision_25: 0.7214 - recall_25: 0.3548 - val_loss: 0.1262 - val_precision_25: 0.5928 - val_recall_25: 0.3527\n",
      "Epoch 27/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1011 - precision_25: 0.7040 - recall_25: 0.3707\n",
      "Epoch 27: val_loss improved from 0.12458 to 0.12423, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1008 - precision_25: 0.7044 - recall_25: 0.3722 - val_loss: 0.1242 - val_precision_25: 0.6111 - val_recall_25: 0.3587\n",
      "Epoch 28/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0969 - precision_25: 0.7252 - recall_25: 0.3827\n",
      "Epoch 28: val_loss improved from 0.12423 to 0.12346, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0968 - precision_25: 0.7251 - recall_25: 0.3846 - val_loss: 0.1235 - val_precision_25: 0.5948 - val_recall_25: 0.3870\n",
      "Epoch 29/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0975 - precision_25: 0.7080 - recall_25: 0.4198 \n",
      "Epoch 29: val_loss improved from 0.12346 to 0.12262, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0969 - precision_25: 0.7115 - recall_25: 0.4193 - val_loss: 0.1226 - val_precision_25: 0.5973 - val_recall_25: 0.3705\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0933 - precision_25: 0.7332 - recall_25: 0.4327\n",
      "Epoch 30: val_loss did not improve from 0.12262\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0933 - precision_25: 0.7330 - recall_25: 0.4329 - val_loss: 0.1229 - val_precision_25: 0.5857 - val_recall_25: 0.3783\n",
      "Epoch 31/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0924 - precision_25: 0.7294 - recall_25: 0.4454\n",
      "Epoch 31: val_loss improved from 0.12262 to 0.11965, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0922 - precision_25: 0.7293 - recall_25: 0.4457 - val_loss: 0.1197 - val_precision_25: 0.6116 - val_recall_25: 0.4114\n",
      "Epoch 32/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0928 - precision_25: 0.7245 - recall_25: 0.4374\n",
      "Epoch 32: val_loss did not improve from 0.11965\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0927 - precision_25: 0.7245 - recall_25: 0.4383 - val_loss: 0.1212 - val_precision_25: 0.6152 - val_recall_25: 0.4356\n",
      "Epoch 33/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0903 - precision_25: 0.7349 - recall_25: 0.4565\n",
      "Epoch 33: val_loss did not improve from 0.11965\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0902 - precision_25: 0.7352 - recall_25: 0.4570 - val_loss: 0.1202 - val_precision_25: 0.6303 - val_recall_25: 0.4245\n",
      "Epoch 34/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0890 - precision_25: 0.7460 - recall_25: 0.4786\n",
      "Epoch 34: val_loss improved from 0.11965 to 0.11793, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0888 - precision_25: 0.7455 - recall_25: 0.4783 - val_loss: 0.1179 - val_precision_25: 0.6314 - val_recall_25: 0.4217\n",
      "Epoch 35/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0876 - precision_25: 0.7626 - recall_25: 0.4755\n",
      "Epoch 35: val_loss did not improve from 0.11793\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0875 - precision_25: 0.7604 - recall_25: 0.4761 - val_loss: 0.1216 - val_precision_25: 0.5967 - val_recall_25: 0.4615\n",
      "Epoch 36/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0863 - precision_25: 0.7430 - recall_25: 0.4960 \n",
      "Epoch 36: val_loss improved from 0.11793 to 0.11700, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0861 - precision_25: 0.7444 - recall_25: 0.4953 - val_loss: 0.1170 - val_precision_25: 0.6178 - val_recall_25: 0.4673\n",
      "Epoch 37/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0833 - precision_25: 0.7671 - recall_25: 0.4996\n",
      "Epoch 37: val_loss improved from 0.11700 to 0.11670, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0832 - precision_25: 0.7660 - recall_25: 0.5009 - val_loss: 0.1167 - val_precision_25: 0.6198 - val_recall_25: 0.4618\n",
      "Epoch 38/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0841 - precision_25: 0.7536 - recall_25: 0.5078\n",
      "Epoch 38: val_loss improved from 0.11670 to 0.11554, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0840 - precision_25: 0.7533 - recall_25: 0.5079 - val_loss: 0.1155 - val_precision_25: 0.6323 - val_recall_25: 0.4746\n",
      "Epoch 39/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0824 - precision_25: 0.7657 - recall_25: 0.5017\n",
      "Epoch 39: val_loss did not improve from 0.11554\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0823 - precision_25: 0.7656 - recall_25: 0.5028 - val_loss: 0.1161 - val_precision_25: 0.6229 - val_recall_25: 0.4842\n",
      "Epoch 40/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0816 - precision_25: 0.7667 - recall_25: 0.5243\n",
      "Epoch 40: val_loss improved from 0.11554 to 0.11481, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0816 - precision_25: 0.7654 - recall_25: 0.5232 - val_loss: 0.1148 - val_precision_25: 0.6262 - val_recall_25: 0.4560\n",
      "Epoch 41/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0819 - precision_25: 0.7589 - recall_25: 0.5118\n",
      "Epoch 41: val_loss did not improve from 0.11481\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - precision_25: 0.7595 - recall_25: 0.5146 - val_loss: 0.1155 - val_precision_25: 0.6122 - val_recall_25: 0.4843\n",
      "Epoch 42/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0799 - precision_25: 0.7544 - recall_25: 0.5495\n",
      "Epoch 42: val_loss improved from 0.11481 to 0.11395, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0798 - precision_25: 0.7552 - recall_25: 0.5488 - val_loss: 0.1140 - val_precision_25: 0.6439 - val_recall_25: 0.4746\n",
      "Epoch 43/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0787 - precision_25: 0.7712 - recall_25: 0.5355\n",
      "Epoch 43: val_loss improved from 0.11395 to 0.11090, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0786 - precision_25: 0.7713 - recall_25: 0.5365 - val_loss: 0.1109 - val_precision_25: 0.6169 - val_recall_25: 0.4921\n",
      "Epoch 44/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0772 - precision_25: 0.7709 - recall_25: 0.5538\n",
      "Epoch 44: val_loss did not improve from 0.11090\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0771 - precision_25: 0.7709 - recall_25: 0.5541 - val_loss: 0.1134 - val_precision_25: 0.6230 - val_recall_25: 0.4939\n",
      "Epoch 45/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0768 - precision_25: 0.7793 - recall_25: 0.5525\n",
      "Epoch 45: val_loss did not improve from 0.11090\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0767 - precision_25: 0.7792 - recall_25: 0.5531 - val_loss: 0.1124 - val_precision_25: 0.6271 - val_recall_25: 0.4878\n",
      "Epoch 46/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0753 - precision_25: 0.7775 - recall_25: 0.5620\n",
      "Epoch 46: val_loss did not improve from 0.11090\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0750 - precision_25: 0.7778 - recall_25: 0.5632 - val_loss: 0.1115 - val_precision_25: 0.6373 - val_recall_25: 0.4936\n",
      "Epoch 47/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0739 - precision_25: 0.7944 - recall_25: 0.5672\n",
      "Epoch 47: val_loss improved from 0.11090 to 0.11075, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0738 - precision_25: 0.7940 - recall_25: 0.5679 - val_loss: 0.1108 - val_precision_25: 0.6247 - val_recall_25: 0.4991\n",
      "Epoch 48/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0744 - precision_25: 0.7845 - recall_25: 0.5551\n",
      "Epoch 48: val_loss did not improve from 0.11075\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0742 - precision_25: 0.7845 - recall_25: 0.5561 - val_loss: 0.1112 - val_precision_25: 0.6283 - val_recall_25: 0.5100\n",
      "Epoch 49/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0739 - precision_25: 0.7728 - recall_25: 0.5850\n",
      "Epoch 49: val_loss improved from 0.11075 to 0.11075, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0736 - precision_25: 0.7738 - recall_25: 0.5862 - val_loss: 0.1108 - val_precision_25: 0.6209 - val_recall_25: 0.5198\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0730 - precision_25: 0.7977 - recall_25: 0.5813\n",
      "Epoch 50: val_loss did not improve from 0.11075\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0729 - precision_25: 0.7972 - recall_25: 0.5819 - val_loss: 0.1118 - val_precision_25: 0.6268 - val_recall_25: 0.5019\n",
      "Epoch 51/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0700 - precision_25: 0.8082 - recall_25: 0.6050\n",
      "Epoch 51: val_loss improved from 0.11075 to 0.10947, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0700 - precision_25: 0.8078 - recall_25: 0.6050 - val_loss: 0.1095 - val_precision_25: 0.6326 - val_recall_25: 0.5180\n",
      "Epoch 52/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0701 - precision_25: 0.7849 - recall_25: 0.5998\n",
      "Epoch 52: val_loss did not improve from 0.10947\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0700 - precision_25: 0.7847 - recall_25: 0.5995 - val_loss: 0.1118 - val_precision_25: 0.6064 - val_recall_25: 0.5180\n",
      "Epoch 53/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0716 - precision_25: 0.7763 - recall_25: 0.6007\n",
      "Epoch 53: val_loss improved from 0.10947 to 0.10907, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0715 - precision_25: 0.7767 - recall_25: 0.6012 - val_loss: 0.1091 - val_precision_25: 0.6325 - val_recall_25: 0.5017\n",
      "Epoch 54/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0686 - precision_25: 0.8159 - recall_25: 0.5934\n",
      "Epoch 54: val_loss did not improve from 0.10907\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0684 - precision_25: 0.8158 - recall_25: 0.5946 - val_loss: 0.1092 - val_precision_25: 0.6302 - val_recall_25: 0.5327\n",
      "Epoch 55/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0673 - precision_25: 0.8067 - recall_25: 0.6129\n",
      "Epoch 55: val_loss improved from 0.10907 to 0.10877, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0673 - precision_25: 0.8054 - recall_25: 0.6134 - val_loss: 0.1088 - val_precision_25: 0.6246 - val_recall_25: 0.5428\n",
      "Epoch 56/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0675 - precision_25: 0.7931 - recall_25: 0.6298\n",
      "Epoch 56: val_loss improved from 0.10877 to 0.10616, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0671 - precision_25: 0.7942 - recall_25: 0.6305 - val_loss: 0.1062 - val_precision_25: 0.6467 - val_recall_25: 0.5238\n",
      "Epoch 57/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0667 - precision_25: 0.8218 - recall_25: 0.6152\n",
      "Epoch 57: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0666 - precision_25: 0.8209 - recall_25: 0.6157 - val_loss: 0.1084 - val_precision_25: 0.6291 - val_recall_25: 0.5354\n",
      "Epoch 58/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0678 - precision_25: 0.8049 - recall_25: 0.6115\n",
      "Epoch 58: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0676 - precision_25: 0.8046 - recall_25: 0.6120 - val_loss: 0.1093 - val_precision_25: 0.6413 - val_recall_25: 0.5447\n",
      "Epoch 59/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0670 - precision_25: 0.8007 - recall_25: 0.6463 \n",
      "Epoch 59: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0660 - precision_25: 0.8019 - recall_25: 0.6423 - val_loss: 0.1076 - val_precision_25: 0.6511 - val_recall_25: 0.5228\n",
      "Epoch 60/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0659 - precision_25: 0.8106 - recall_25: 0.6188\n",
      "Epoch 60: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0658 - precision_25: 0.8099 - recall_25: 0.6197 - val_loss: 0.1105 - val_precision_25: 0.6311 - val_recall_25: 0.5417\n",
      "Epoch 61/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0649 - precision_25: 0.8066 - recall_25: 0.6362\n",
      "Epoch 61: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0648 - precision_25: 0.8062 - recall_25: 0.6368 - val_loss: 0.1070 - val_precision_25: 0.6519 - val_recall_25: 0.5306\n",
      "Epoch 62/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0658 - precision_25: 0.8052 - recall_25: 0.6204\n",
      "Epoch 62: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0656 - precision_25: 0.8052 - recall_25: 0.6216 - val_loss: 0.1100 - val_precision_25: 0.6246 - val_recall_25: 0.5453\n",
      "Epoch 63/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0653 - precision_25: 0.7904 - recall_25: 0.6348\n",
      "Epoch 63: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0651 - precision_25: 0.7913 - recall_25: 0.6352 - val_loss: 0.1070 - val_precision_25: 0.6467 - val_recall_25: 0.5276\n",
      "Epoch 64/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0627 - precision_25: 0.8204 - recall_25: 0.6383\n",
      "Epoch 64: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0626 - precision_25: 0.8204 - recall_25: 0.6389 - val_loss: 0.1073 - val_precision_25: 0.6473 - val_recall_25: 0.5419\n",
      "Epoch 65/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0620 - precision_25: 0.8168 - recall_25: 0.6535\n",
      "Epoch 65: val_loss did not improve from 0.10616\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0618 - precision_25: 0.8169 - recall_25: 0.6542 - val_loss: 0.1072 - val_precision_25: 0.6446 - val_recall_25: 0.5573\n",
      "Epoch 66/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0645 - precision_25: 0.7979 - recall_25: 0.6559 \n",
      "Epoch 66: val_loss improved from 0.10616 to 0.10456, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0627 - precision_25: 0.8042 - recall_25: 0.6601 - val_loss: 0.1046 - val_precision_25: 0.6605 - val_recall_25: 0.5480\n",
      "Epoch 67/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0605 - precision_25: 0.8266 - recall_25: 0.6651\n",
      "Epoch 67: val_loss did not improve from 0.10456\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0603 - precision_25: 0.8260 - recall_25: 0.6660 - val_loss: 0.1062 - val_precision_25: 0.6451 - val_recall_25: 0.5520\n",
      "Epoch 68/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0631 - precision_25: 0.8304 - recall_25: 0.6566 \n",
      "Epoch 68: val_loss improved from 0.10456 to 0.10417, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0617 - precision_25: 0.8282 - recall_25: 0.6615 - val_loss: 0.1042 - val_precision_25: 0.6477 - val_recall_25: 0.5379\n",
      "Epoch 69/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0588 - precision_25: 0.8395 - recall_25: 0.6613\n",
      "Epoch 69: val_loss did not improve from 0.10417\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0586 - precision_25: 0.8394 - recall_25: 0.6622 - val_loss: 0.1053 - val_precision_25: 0.6392 - val_recall_25: 0.5574\n",
      "Epoch 70/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0596 - precision_25: 0.8214 - recall_25: 0.6603\n",
      "Epoch 70: val_loss did not improve from 0.10417\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0595 - precision_25: 0.8218 - recall_25: 0.6614 - val_loss: 0.1044 - val_precision_25: 0.6390 - val_recall_25: 0.5491\n",
      "Epoch 71/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0587 - precision_25: 0.8290 - recall_25: 0.6710\n",
      "Epoch 71: val_loss did not improve from 0.10417\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0584 - precision_25: 0.8292 - recall_25: 0.6726 - val_loss: 0.1060 - val_precision_25: 0.6450 - val_recall_25: 0.5596\n",
      "Epoch 72/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0592 - precision_25: 0.8162 - recall_25: 0.6810\n",
      "Epoch 72: val_loss did not improve from 0.10417\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0591 - precision_25: 0.8162 - recall_25: 0.6817 - val_loss: 0.1060 - val_precision_25: 0.6435 - val_recall_25: 0.5496\n",
      "Epoch 73/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0580 - precision_25: 0.8256 - recall_25: 0.6866\n",
      "Epoch 73: val_loss improved from 0.10417 to 0.10321, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0577 - precision_25: 0.8268 - recall_25: 0.6871 - val_loss: 0.1032 - val_precision_25: 0.6577 - val_recall_25: 0.5581\n",
      "Epoch 74/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0573 - precision_25: 0.8381 - recall_25: 0.6729\n",
      "Epoch 74: val_loss did not improve from 0.10321\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0572 - precision_25: 0.8382 - recall_25: 0.6737 - val_loss: 0.1054 - val_precision_25: 0.6413 - val_recall_25: 0.5695\n",
      "Epoch 75/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0581 - precision_25: 0.8221 - recall_25: 0.6788\n",
      "Epoch 75: val_loss did not improve from 0.10321\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0580 - precision_25: 0.8224 - recall_25: 0.6792 - val_loss: 0.1046 - val_precision_25: 0.6552 - val_recall_25: 0.5629\n",
      "Epoch 76/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0564 - precision_25: 0.8205 - recall_25: 0.6964\n",
      "Epoch 76: val_loss did not improve from 0.10321\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0564 - precision_25: 0.8209 - recall_25: 0.6968 - val_loss: 0.1047 - val_precision_25: 0.6547 - val_recall_25: 0.5612\n",
      "Epoch 77/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0551 - precision_25: 0.8401 - recall_25: 0.6876 \n",
      "Epoch 77: val_loss did not improve from 0.10321\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0552 - precision_25: 0.8375 - recall_25: 0.6848 - val_loss: 0.1043 - val_precision_25: 0.6505 - val_recall_25: 0.5714\n",
      "Epoch 78/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0550 - precision_25: 0.8285 - recall_25: 0.7094\n",
      "Epoch 78: val_loss improved from 0.10321 to 0.10244, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0549 - precision_25: 0.8287 - recall_25: 0.7098 - val_loss: 0.1024 - val_precision_25: 0.6528 - val_recall_25: 0.5710\n",
      "Epoch 79/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0570 - precision_25: 0.8264 - recall_25: 0.6843\n",
      "Epoch 79: val_loss improved from 0.10244 to 0.10210, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0566 - precision_25: 0.8283 - recall_25: 0.6853 - val_loss: 0.1021 - val_precision_25: 0.6662 - val_recall_25: 0.5677\n",
      "Epoch 80/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0553 - precision_25: 0.8295 - recall_25: 0.6996\n",
      "Epoch 80: val_loss improved from 0.10210 to 0.10183, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0552 - precision_25: 0.8294 - recall_25: 0.7002 - val_loss: 0.1018 - val_precision_25: 0.6631 - val_recall_25: 0.5780\n",
      "Epoch 81/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0559 - precision_25: 0.8386 - recall_25: 0.6770\n",
      "Epoch 81: val_loss improved from 0.10183 to 0.10149, saving model to 62sec_3layers_256units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0558 - precision_25: 0.8378 - recall_25: 0.6786 - val_loss: 0.1015 - val_precision_25: 0.6736 - val_recall_25: 0.5846\n",
      "Epoch 82/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0541 - precision_25: 0.8399 - recall_25: 0.7097\n",
      "Epoch 82: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0540 - precision_25: 0.8396 - recall_25: 0.7099 - val_loss: 0.1024 - val_precision_25: 0.6643 - val_recall_25: 0.5800\n",
      "Epoch 83/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0519 - precision_25: 0.8519 - recall_25: 0.7199\n",
      "Epoch 83: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0519 - precision_25: 0.8507 - recall_25: 0.7204 - val_loss: 0.1026 - val_precision_25: 0.6678 - val_recall_25: 0.5798\n",
      "Epoch 84/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0537 - precision_25: 0.8367 - recall_25: 0.7076\n",
      "Epoch 84: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0535 - precision_25: 0.8387 - recall_25: 0.7081 - val_loss: 0.1021 - val_precision_25: 0.6633 - val_recall_25: 0.5818\n",
      "Epoch 85/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0534 - precision_25: 0.8416 - recall_25: 0.7084\n",
      "Epoch 85: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0533 - precision_25: 0.8417 - recall_25: 0.7088 - val_loss: 0.1016 - val_precision_25: 0.6718 - val_recall_25: 0.5788\n",
      "Epoch 86/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0539 - precision_25: 0.8300 - recall_25: 0.7066\n",
      "Epoch 86: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0539 - precision_25: 0.8303 - recall_25: 0.7068 - val_loss: 0.1024 - val_precision_25: 0.6689 - val_recall_25: 0.5848\n",
      "Epoch 87/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0501 - precision_25: 0.8562 - recall_25: 0.7287 \n",
      "Epoch 87: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0503 - precision_25: 0.8515 - recall_25: 0.7278 - val_loss: 0.1022 - val_precision_25: 0.6635 - val_recall_25: 0.5841\n",
      "Epoch 88/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0512 - precision_25: 0.8509 - recall_25: 0.7215\n",
      "Epoch 88: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0512 - precision_25: 0.8508 - recall_25: 0.7221 - val_loss: 0.1022 - val_precision_25: 0.6640 - val_recall_25: 0.5823\n",
      "Epoch 89/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0511 - precision_25: 0.8610 - recall_25: 0.7143 \n",
      "Epoch 89: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0506 - precision_25: 0.8592 - recall_25: 0.7167 - val_loss: 0.1039 - val_precision_25: 0.6575 - val_recall_25: 0.5906\n",
      "Epoch 90/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0513 - precision_25: 0.8366 - recall_25: 0.7256\n",
      "Epoch 90: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0513 - precision_25: 0.8374 - recall_25: 0.7254 - val_loss: 0.1035 - val_precision_25: 0.6663 - val_recall_25: 0.5864\n",
      "Epoch 91/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0510 - precision_25: 0.8391 - recall_25: 0.7261\n",
      "Epoch 91: val_loss did not improve from 0.10149\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0509 - precision_25: 0.8397 - recall_25: 0.7265 - val_loss: 0.1031 - val_precision_25: 0.6735 - val_recall_25: 0.5904\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0274 - precision_25: 0.9365 - recall_25: 0.8784 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1030 - precision_25: 0.6596 - recall_25: 0.5800 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1070 - precision_25: 0.6744 - recall_25: 0.5675 \n",
      "Epoch 1/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6308 - precision_26: 0.0510 - recall_26: 0.3423  \n",
      "Epoch 1: val_loss improved from inf to 0.25556, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5861 - precision_26: 0.0509 - recall_26: 0.2901 - val_loss: 0.2556 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2801 - precision_26: 0.1563 - recall_26: 0.0156 \n",
      "Epoch 2: val_loss improved from 0.25556 to 0.21055, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2688 - precision_26: 0.1551 - recall_26: 0.0214 - val_loss: 0.2106 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2201 - precision_26: 0.1486 - recall_26: 0.0196 \n",
      "Epoch 3: val_loss improved from 0.21055 to 0.20554, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2170 - precision_26: 0.1516 - recall_26: 0.0172 - val_loss: 0.2055 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1994 - precision_26: 0.1660 - recall_26: 0.0042 \n",
      "Epoch 4: val_loss improved from 0.20554 to 0.18067, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1956 - precision_26: 0.1634 - recall_26: 0.0035 - val_loss: 0.1807 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1819 - precision_26: 0.3172 - recall_26: 9.8906e-04\n",
      "Epoch 5: val_loss improved from 0.18067 to 0.17264, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1805 - precision_26: 0.3007 - recall_26: 8.8641e-04 - val_loss: 0.1726 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 6/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1794 - precision_26: 0.5055 - recall_26: 5.7183e-04 \n",
      "Epoch 6: val_loss did not improve from 0.17264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1781 - precision_26: 0.4341 - recall_26: 6.1526e-04 - val_loss: 0.1770 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1769 - precision_26: 0.3486 - recall_26: 6.2892e-04 \n",
      "Epoch 7: val_loss did not improve from 0.17264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1755 - precision_26: 0.3433 - recall_26: 6.4471e-04 - val_loss: 0.1822 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 8/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1747 - precision_26: 0.2987 - recall_26: 6.6177e-04 \n",
      "Epoch 8: val_loss did not improve from 0.17264\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1732 - precision_26: 0.3177 - recall_26: 7.7567e-04 - val_loss: 0.1746 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 9/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1702 - precision_26: 0.2747 - recall_26: 0.0013     \n",
      "Epoch 9: val_loss improved from 0.17264 to 0.16642, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1687 - precision_26: 0.3149 - recall_26: 0.0016 - val_loss: 0.1664 - val_precision_26: 0.0000e+00 - val_recall_26: 0.0000e+00\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1656 - precision_26: 0.3395 - recall_26: 0.0040   \n",
      "Epoch 10: val_loss improved from 0.16642 to 0.16269, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1655 - precision_26: 0.3393 - recall_26: 0.0041 - val_loss: 0.1627 - val_precision_26: 0.6667 - val_recall_26: 0.0030\n",
      "Epoch 11/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1632 - precision_26: 0.3575 - recall_26: 0.0089 \n",
      "Epoch 11: val_loss improved from 0.16269 to 0.16242, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1611 - precision_26: 0.3773 - recall_26: 0.0109 - val_loss: 0.1624 - val_precision_26: 0.5417 - val_recall_26: 0.0151\n",
      "Epoch 12/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1593 - precision_26: 0.3695 - recall_26: 0.0223 \n",
      "Epoch 12: val_loss improved from 0.16242 to 0.16179, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1576 - precision_26: 0.3781 - recall_26: 0.0239 - val_loss: 0.1618 - val_precision_26: 0.4575 - val_recall_26: 0.0375\n",
      "Epoch 13/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1573 - precision_26: 0.3911 - recall_26: 0.0336 \n",
      "Epoch 13: val_loss improved from 0.16179 to 0.15591, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1549 - precision_26: 0.4000 - recall_26: 0.0361 - val_loss: 0.1559 - val_precision_26: 0.4526 - val_recall_26: 0.0419\n",
      "Epoch 14/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1518 - precision_26: 0.4005 - recall_26: 0.0361\n",
      "Epoch 14: val_loss did not improve from 0.15591\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1517 - precision_26: 0.4018 - recall_26: 0.0365 - val_loss: 0.1560 - val_precision_26: 0.4643 - val_recall_26: 0.0625\n",
      "Epoch 15/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1482 - precision_26: 0.4150 - recall_26: 0.0464\n",
      "Epoch 15: val_loss did not improve from 0.15591\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1479 - precision_26: 0.4168 - recall_26: 0.0474 - val_loss: 0.1563 - val_precision_26: 0.4438 - val_recall_26: 0.0937\n",
      "Epoch 16/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1462 - precision_26: 0.4094 - recall_26: 0.0672 \n",
      "Epoch 16: val_loss improved from 0.15591 to 0.15222, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1451 - precision_26: 0.4191 - recall_26: 0.0684 - val_loss: 0.1522 - val_precision_26: 0.4389 - val_recall_26: 0.0839\n",
      "Epoch 17/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1434 - precision_26: 0.3979 - recall_26: 0.0601\n",
      "Epoch 17: val_loss improved from 0.15222 to 0.14952, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1432 - precision_26: 0.4002 - recall_26: 0.0606 - val_loss: 0.1495 - val_precision_26: 0.4796 - val_recall_26: 0.0701\n",
      "Epoch 18/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1421 - precision_26: 0.4650 - recall_26: 0.0689\n",
      "Epoch 18: val_loss did not improve from 0.14952\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1419 - precision_26: 0.4661 - recall_26: 0.0689 - val_loss: 0.1523 - val_precision_26: 0.4868 - val_recall_26: 0.1038\n",
      "Epoch 19/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1410 - precision_26: 0.4772 - recall_26: 0.0800\n",
      "Epoch 19: val_loss improved from 0.14952 to 0.14950, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1409 - precision_26: 0.4782 - recall_26: 0.0803 - val_loss: 0.1495 - val_precision_26: 0.4764 - val_recall_26: 0.1019\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1402 - precision_26: 0.4560 - recall_26: 0.0777\n",
      "Epoch 20: val_loss improved from 0.14950 to 0.14807, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1400 - precision_26: 0.4578 - recall_26: 0.0780 - val_loss: 0.1481 - val_precision_26: 0.5090 - val_recall_26: 0.0980\n",
      "Epoch 21/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1385 - precision_26: 0.5206 - recall_26: 0.0886 \n",
      "Epoch 21: val_loss improved from 0.14807 to 0.14451, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1368 - precision_26: 0.5310 - recall_26: 0.0944 - val_loss: 0.1445 - val_precision_26: 0.5205 - val_recall_26: 0.1159\n",
      "Epoch 22/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1340 - precision_26: 0.5180 - recall_26: 0.0967\n",
      "Epoch 22: val_loss did not improve from 0.14451\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1340 - precision_26: 0.5199 - recall_26: 0.0976 - val_loss: 0.1453 - val_precision_26: 0.5210 - val_recall_26: 0.1354\n",
      "Epoch 23/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1352 - precision_26: 0.5317 - recall_26: 0.0949 \n",
      "Epoch 23: val_loss improved from 0.14451 to 0.14086, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1335 - precision_26: 0.5402 - recall_26: 0.1066 - val_loss: 0.1409 - val_precision_26: 0.5400 - val_recall_26: 0.1275\n",
      "Epoch 24/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1320 - precision_26: 0.5518 - recall_26: 0.1068 \n",
      "Epoch 24: val_loss did not improve from 0.14086\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1308 - precision_26: 0.5555 - recall_26: 0.1181 - val_loss: 0.1453 - val_precision_26: 0.5151 - val_recall_26: 0.1692\n",
      "Epoch 25/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1294 - precision_26: 0.5985 - recall_26: 0.1612 \n",
      "Epoch 25: val_loss did not improve from 0.14086\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1287 - precision_26: 0.5983 - recall_26: 0.1568 - val_loss: 0.1440 - val_precision_26: 0.5345 - val_recall_26: 0.1774\n",
      "Epoch 26/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1279 - precision_26: 0.5772 - recall_26: 0.1503 \n",
      "Epoch 26: val_loss improved from 0.14086 to 0.13897, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1265 - precision_26: 0.5893 - recall_26: 0.1657 - val_loss: 0.1390 - val_precision_26: 0.5898 - val_recall_26: 0.1835\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1242 - precision_26: 0.6174 - recall_26: 0.1781\n",
      "Epoch 27: val_loss did not improve from 0.13897\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1241 - precision_26: 0.6170 - recall_26: 0.1784 - val_loss: 0.1391 - val_precision_26: 0.5562 - val_recall_26: 0.2223\n",
      "Epoch 28/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1229 - precision_26: 0.6231 - recall_26: 0.2023\n",
      "Epoch 28: val_loss improved from 0.13897 to 0.13712, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1226 - precision_26: 0.6239 - recall_26: 0.2060 - val_loss: 0.1371 - val_precision_26: 0.5667 - val_recall_26: 0.2423\n",
      "Epoch 29/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1215 - precision_26: 0.6167 - recall_26: 0.2067 \n",
      "Epoch 29: val_loss improved from 0.13712 to 0.13423, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1208 - precision_26: 0.6251 - recall_26: 0.2123 - val_loss: 0.1342 - val_precision_26: 0.5694 - val_recall_26: 0.2523\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1191 - precision_26: 0.6451 - recall_26: 0.2259\n",
      "Epoch 30: val_loss did not improve from 0.13423\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1190 - precision_26: 0.6440 - recall_26: 0.2274 - val_loss: 0.1362 - val_precision_26: 0.5701 - val_recall_26: 0.2859\n",
      "Epoch 31/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1176 - precision_26: 0.6453 - recall_26: 0.2359\n",
      "Epoch 31: val_loss did not improve from 0.13423\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1174 - precision_26: 0.6465 - recall_26: 0.2377 - val_loss: 0.1360 - val_precision_26: 0.5565 - val_recall_26: 0.2839\n",
      "Epoch 32/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1150 - precision_26: 0.6638 - recall_26: 0.2583\n",
      "Epoch 32: val_loss improved from 0.13423 to 0.13117, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1149 - precision_26: 0.6631 - recall_26: 0.2594 - val_loss: 0.1312 - val_precision_26: 0.5666 - val_recall_26: 0.2912\n",
      "Epoch 33/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1150 - precision_26: 0.6551 - recall_26: 0.2696\n",
      "Epoch 33: val_loss did not improve from 0.13117\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1149 - precision_26: 0.6551 - recall_26: 0.2710 - val_loss: 0.1330 - val_precision_26: 0.5821 - val_recall_26: 0.3138\n",
      "Epoch 34/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1140 - precision_26: 0.6371 - recall_26: 0.2860\n",
      "Epoch 34: val_loss did not improve from 0.13117\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1139 - precision_26: 0.6382 - recall_26: 0.2867 - val_loss: 0.1326 - val_precision_26: 0.5706 - val_recall_26: 0.3249\n",
      "Epoch 35/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1110 - precision_26: 0.6721 - recall_26: 0.2796 \n",
      "Epoch 35: val_loss improved from 0.13117 to 0.12951, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1105 - precision_26: 0.6708 - recall_26: 0.2904 - val_loss: 0.1295 - val_precision_26: 0.5724 - val_recall_26: 0.3323\n",
      "Epoch 36/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1093 - precision_26: 0.6854 - recall_26: 0.3085\n",
      "Epoch 36: val_loss improved from 0.12951 to 0.12925, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1093 - precision_26: 0.6852 - recall_26: 0.3094 - val_loss: 0.1292 - val_precision_26: 0.5793 - val_recall_26: 0.3464\n",
      "Epoch 37/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1086 - precision_26: 0.6422 - recall_26: 0.3381 \n",
      "Epoch 37: val_loss improved from 0.12925 to 0.12814, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1082 - precision_26: 0.6468 - recall_26: 0.3321 - val_loss: 0.1281 - val_precision_26: 0.5975 - val_recall_26: 0.3443\n",
      "Epoch 38/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1077 - precision_26: 0.6824 - recall_26: 0.3184\n",
      "Epoch 38: val_loss improved from 0.12814 to 0.12566, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1075 - precision_26: 0.6829 - recall_26: 0.3192 - val_loss: 0.1257 - val_precision_26: 0.5911 - val_recall_26: 0.3688\n",
      "Epoch 39/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1061 - precision_26: 0.6706 - recall_26: 0.3485\n",
      "Epoch 39: val_loss did not improve from 0.12566\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1060 - precision_26: 0.6708 - recall_26: 0.3488 - val_loss: 0.1276 - val_precision_26: 0.5987 - val_recall_26: 0.3842\n",
      "Epoch 40/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1066 - precision_26: 0.6857 - recall_26: 0.3574 \n",
      "Epoch 40: val_loss did not improve from 0.12566\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1057 - precision_26: 0.6850 - recall_26: 0.3534 - val_loss: 0.1279 - val_precision_26: 0.5701 - val_recall_26: 0.3713\n",
      "Epoch 41/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1050 - precision_26: 0.6984 - recall_26: 0.3549\n",
      "Epoch 41: val_loss improved from 0.12566 to 0.12487, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1049 - precision_26: 0.6979 - recall_26: 0.3557 - val_loss: 0.1249 - val_precision_26: 0.5777 - val_recall_26: 0.3759\n",
      "Epoch 42/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1027 - precision_26: 0.6983 - recall_26: 0.3718\n",
      "Epoch 42: val_loss did not improve from 0.12487\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1025 - precision_26: 0.6985 - recall_26: 0.3734 - val_loss: 0.1280 - val_precision_26: 0.5711 - val_recall_26: 0.4081\n",
      "Epoch 43/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1040 - precision_26: 0.6831 - recall_26: 0.3711\n",
      "Epoch 43: val_loss improved from 0.12487 to 0.12249, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1037 - precision_26: 0.6844 - recall_26: 0.3727 - val_loss: 0.1225 - val_precision_26: 0.6077 - val_recall_26: 0.3947\n",
      "Epoch 44/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1017 - precision_26: 0.6982 - recall_26: 0.3529\n",
      "Epoch 44: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1016 - precision_26: 0.6980 - recall_26: 0.3551 - val_loss: 0.1240 - val_precision_26: 0.5723 - val_recall_26: 0.4059\n",
      "Epoch 45/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1025 - precision_26: 0.7099 - recall_26: 0.3721 \n",
      "Epoch 45: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1009 - precision_26: 0.7081 - recall_26: 0.3831 - val_loss: 0.1234 - val_precision_26: 0.5804 - val_recall_26: 0.4199\n",
      "Epoch 46/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1006 - precision_26: 0.6986 - recall_26: 0.3995\n",
      "Epoch 46: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1004 - precision_26: 0.6983 - recall_26: 0.3997 - val_loss: 0.1234 - val_precision_26: 0.5776 - val_recall_26: 0.4308\n",
      "Epoch 47/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0988 - precision_26: 0.6964 - recall_26: 0.4017\n",
      "Epoch 47: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0988 - precision_26: 0.6961 - recall_26: 0.4018 - val_loss: 0.1237 - val_precision_26: 0.5827 - val_recall_26: 0.4293\n",
      "Epoch 48/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0974 - precision_26: 0.7116 - recall_26: 0.4020\n",
      "Epoch 48: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0973 - precision_26: 0.7113 - recall_26: 0.4025 - val_loss: 0.1233 - val_precision_26: 0.5740 - val_recall_26: 0.4263\n",
      "Epoch 49/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0962 - precision_26: 0.6943 - recall_26: 0.4223\n",
      "Epoch 49: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0961 - precision_26: 0.6948 - recall_26: 0.4230 - val_loss: 0.1230 - val_precision_26: 0.5932 - val_recall_26: 0.4346\n",
      "Epoch 50/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0975 - precision_26: 0.6998 - recall_26: 0.4106\n",
      "Epoch 50: val_loss did not improve from 0.12249\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0974 - precision_26: 0.7006 - recall_26: 0.4109 - val_loss: 0.1235 - val_precision_26: 0.5907 - val_recall_26: 0.4572\n",
      "Epoch 51/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0962 - precision_26: 0.7113 - recall_26: 0.4415\n",
      "Epoch 51: val_loss improved from 0.12249 to 0.12007, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0959 - precision_26: 0.7116 - recall_26: 0.4415 - val_loss: 0.1201 - val_precision_26: 0.6024 - val_recall_26: 0.4383\n",
      "Epoch 52/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0958 - precision_26: 0.7163 - recall_26: 0.4160\n",
      "Epoch 52: val_loss did not improve from 0.12007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0957 - precision_26: 0.7161 - recall_26: 0.4167 - val_loss: 0.1236 - val_precision_26: 0.5882 - val_recall_26: 0.4560\n",
      "Epoch 53/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0935 - precision_26: 0.7311 - recall_26: 0.4475\n",
      "Epoch 53: val_loss did not improve from 0.12007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0934 - precision_26: 0.7296 - recall_26: 0.4477 - val_loss: 0.1208 - val_precision_26: 0.5942 - val_recall_26: 0.4338\n",
      "Epoch 54/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0943 - precision_26: 0.7158 - recall_26: 0.4435 \n",
      "Epoch 54: val_loss did not improve from 0.12007\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0933 - precision_26: 0.7165 - recall_26: 0.4460 - val_loss: 0.1206 - val_precision_26: 0.6039 - val_recall_26: 0.4383\n",
      "Epoch 55/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0935 - precision_26: 0.7194 - recall_26: 0.4400\n",
      "Epoch 55: val_loss improved from 0.12007 to 0.11966, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0934 - precision_26: 0.7198 - recall_26: 0.4408 - val_loss: 0.1197 - val_precision_26: 0.5996 - val_recall_26: 0.4487\n",
      "Epoch 56/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0929 - precision_26: 0.7176 - recall_26: 0.4548\n",
      "Epoch 56: val_loss improved from 0.11966 to 0.11843, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0928 - precision_26: 0.7180 - recall_26: 0.4553 - val_loss: 0.1184 - val_precision_26: 0.5949 - val_recall_26: 0.4376\n",
      "Epoch 57/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0920 - precision_26: 0.7270 - recall_26: 0.4509\n",
      "Epoch 57: val_loss did not improve from 0.11843\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0919 - precision_26: 0.7268 - recall_26: 0.4516 - val_loss: 0.1205 - val_precision_26: 0.5894 - val_recall_26: 0.4575\n",
      "Epoch 58/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0905 - precision_26: 0.7293 - recall_26: 0.4736 \n",
      "Epoch 58: val_loss improved from 0.11843 to 0.11745, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0904 - precision_26: 0.7216 - recall_26: 0.4692 - val_loss: 0.1174 - val_precision_26: 0.6126 - val_recall_26: 0.4562\n",
      "Epoch 59/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0916 - precision_26: 0.7512 - recall_26: 0.4360 \n",
      "Epoch 59: val_loss improved from 0.11745 to 0.11590, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0902 - precision_26: 0.7464 - recall_26: 0.4451 - val_loss: 0.1159 - val_precision_26: 0.6177 - val_recall_26: 0.4548\n",
      "Epoch 60/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0915 - precision_26: 0.7353 - recall_26: 0.4505 \n",
      "Epoch 60: val_loss did not improve from 0.11590\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0902 - precision_26: 0.7339 - recall_26: 0.4581 - val_loss: 0.1193 - val_precision_26: 0.6051 - val_recall_26: 0.4721\n",
      "Epoch 61/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0916 - precision_26: 0.7260 - recall_26: 0.4791 \n",
      "Epoch 61: val_loss did not improve from 0.11590\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0908 - precision_26: 0.7260 - recall_26: 0.4824 - val_loss: 0.1185 - val_precision_26: 0.6008 - val_recall_26: 0.4639\n",
      "Epoch 62/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0907 - precision_26: 0.7417 - recall_26: 0.4712 \n",
      "Epoch 62: val_loss did not improve from 0.11590\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0898 - precision_26: 0.7414 - recall_26: 0.4743 - val_loss: 0.1175 - val_precision_26: 0.6122 - val_recall_26: 0.4676\n",
      "Epoch 63/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0906 - precision_26: 0.7457 - recall_26: 0.4816 \n",
      "Epoch 63: val_loss improved from 0.11590 to 0.11578, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0896 - precision_26: 0.7402 - recall_26: 0.4808 - val_loss: 0.1158 - val_precision_26: 0.6132 - val_recall_26: 0.4621\n",
      "Epoch 64/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0891 - precision_26: 0.7464 - recall_26: 0.4692 \n",
      "Epoch 64: val_loss did not improve from 0.11578\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0876 - precision_26: 0.7466 - recall_26: 0.4760 - val_loss: 0.1160 - val_precision_26: 0.6005 - val_recall_26: 0.4666\n",
      "Epoch 65/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0883 - precision_26: 0.7502 - recall_26: 0.4929 \n",
      "Epoch 65: val_loss improved from 0.11578 to 0.11484, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0869 - precision_26: 0.7461 - recall_26: 0.4933 - val_loss: 0.1148 - val_precision_26: 0.6161 - val_recall_26: 0.4668\n",
      "Epoch 66/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0885 - precision_26: 0.7208 - recall_26: 0.4798\n",
      "Epoch 66: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0883 - precision_26: 0.7215 - recall_26: 0.4806 - val_loss: 0.1158 - val_precision_26: 0.6079 - val_recall_26: 0.4757\n",
      "Epoch 67/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0846 - precision_26: 0.7591 - recall_26: 0.5053 \n",
      "Epoch 67: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0843 - precision_26: 0.7510 - recall_26: 0.5098 - val_loss: 0.1149 - val_precision_26: 0.6114 - val_recall_26: 0.4704\n",
      "Epoch 68/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - precision_26: 0.7483 - recall_26: 0.4878\n",
      "Epoch 68: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0852 - precision_26: 0.7478 - recall_26: 0.4883 - val_loss: 0.1155 - val_precision_26: 0.6008 - val_recall_26: 0.4842\n",
      "Epoch 69/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0842 - precision_26: 0.7325 - recall_26: 0.5043 \n",
      "Epoch 69: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0839 - precision_26: 0.7315 - recall_26: 0.5091 - val_loss: 0.1160 - val_precision_26: 0.6137 - val_recall_26: 0.4853\n",
      "Epoch 70/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0863 - precision_26: 0.7494 - recall_26: 0.5055 \n",
      "Epoch 70: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0855 - precision_26: 0.7432 - recall_26: 0.5041 - val_loss: 0.1157 - val_precision_26: 0.6203 - val_recall_26: 0.4928\n",
      "Epoch 71/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0829 - precision_26: 0.7471 - recall_26: 0.5142 \n",
      "Epoch 71: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0830 - precision_26: 0.7470 - recall_26: 0.5122 - val_loss: 0.1151 - val_precision_26: 0.6135 - val_recall_26: 0.4815\n",
      "Epoch 72/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0853 - precision_26: 0.7425 - recall_26: 0.5033\n",
      "Epoch 72: val_loss did not improve from 0.11484\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0851 - precision_26: 0.7427 - recall_26: 0.5040 - val_loss: 0.1152 - val_precision_26: 0.6100 - val_recall_26: 0.4951\n",
      "Epoch 73/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0828 - precision_26: 0.7353 - recall_26: 0.5221\n",
      "Epoch 73: val_loss improved from 0.11484 to 0.11366, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0827 - precision_26: 0.7356 - recall_26: 0.5221 - val_loss: 0.1137 - val_precision_26: 0.6215 - val_recall_26: 0.4832\n",
      "Epoch 74/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0822 - precision_26: 0.7597 - recall_26: 0.5247\n",
      "Epoch 74: val_loss did not improve from 0.11366\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0820 - precision_26: 0.7598 - recall_26: 0.5259 - val_loss: 0.1150 - val_precision_26: 0.6149 - val_recall_26: 0.4888\n",
      "Epoch 75/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0818 - precision_26: 0.7496 - recall_26: 0.5440\n",
      "Epoch 75: val_loss improved from 0.11366 to 0.11332, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0817 - precision_26: 0.7498 - recall_26: 0.5444 - val_loss: 0.1133 - val_precision_26: 0.6078 - val_recall_26: 0.4719\n",
      "Epoch 76/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0826 - precision_26: 0.7448 - recall_26: 0.5139\n",
      "Epoch 76: val_loss did not improve from 0.11332\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0825 - precision_26: 0.7453 - recall_26: 0.5147 - val_loss: 0.1141 - val_precision_26: 0.6052 - val_recall_26: 0.4764\n",
      "Epoch 77/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0805 - precision_26: 0.7619 - recall_26: 0.5193\n",
      "Epoch 77: val_loss did not improve from 0.11332\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0803 - precision_26: 0.7616 - recall_26: 0.5209 - val_loss: 0.1136 - val_precision_26: 0.6080 - val_recall_26: 0.4815\n",
      "Epoch 78/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0799 - precision_26: 0.7651 - recall_26: 0.5210 \n",
      "Epoch 78: val_loss did not improve from 0.11332\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0794 - precision_26: 0.7636 - recall_26: 0.5260 - val_loss: 0.1145 - val_precision_26: 0.6017 - val_recall_26: 0.4983\n",
      "Epoch 79/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - precision_26: 0.7583 - recall_26: 0.5467\n",
      "Epoch 79: val_loss did not improve from 0.11332\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0802 - precision_26: 0.7584 - recall_26: 0.5461 - val_loss: 0.1144 - val_precision_26: 0.6008 - val_recall_26: 0.5042\n",
      "Epoch 80/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0812 - precision_26: 0.7383 - recall_26: 0.5383\n",
      "Epoch 80: val_loss improved from 0.11332 to 0.11329, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0811 - precision_26: 0.7384 - recall_26: 0.5382 - val_loss: 0.1133 - val_precision_26: 0.6156 - val_recall_26: 0.4961\n",
      "Epoch 81/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0812 - precision_26: 0.7487 - recall_26: 0.5225 \n",
      "Epoch 81: val_loss improved from 0.11329 to 0.11203, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0800 - precision_26: 0.7495 - recall_26: 0.5302 - val_loss: 0.1120 - val_precision_26: 0.6278 - val_recall_26: 0.5001\n",
      "Epoch 82/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0815 - precision_26: 0.7620 - recall_26: 0.5362 \n",
      "Epoch 82: val_loss improved from 0.11203 to 0.11108, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0807 - precision_26: 0.7584 - recall_26: 0.5385 - val_loss: 0.1111 - val_precision_26: 0.6348 - val_recall_26: 0.5042\n",
      "Epoch 83/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0812 - precision_26: 0.7904 - recall_26: 0.5188 \n",
      "Epoch 83: val_loss did not improve from 0.11108\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0798 - precision_26: 0.7823 - recall_26: 0.5289 - val_loss: 0.1111 - val_precision_26: 0.6258 - val_recall_26: 0.5057\n",
      "Epoch 84/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0790 - precision_26: 0.7698 - recall_26: 0.5506\n",
      "Epoch 84: val_loss improved from 0.11108 to 0.11063, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0789 - precision_26: 0.7696 - recall_26: 0.5503 - val_loss: 0.1106 - val_precision_26: 0.6334 - val_recall_26: 0.5017\n",
      "Epoch 85/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0773 - precision_26: 0.7646 - recall_26: 0.5582\n",
      "Epoch 85: val_loss improved from 0.11063 to 0.11054, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0773 - precision_26: 0.7644 - recall_26: 0.5584 - val_loss: 0.1105 - val_precision_26: 0.6200 - val_recall_26: 0.4953\n",
      "Epoch 86/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0785 - precision_26: 0.7503 - recall_26: 0.5530\n",
      "Epoch 86: val_loss did not improve from 0.11054\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0783 - precision_26: 0.7507 - recall_26: 0.5539 - val_loss: 0.1112 - val_precision_26: 0.6090 - val_recall_26: 0.4964\n",
      "Epoch 87/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0813 - precision_26: 0.7550 - recall_26: 0.5339 \n",
      "Epoch 87: val_loss improved from 0.11054 to 0.10978, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0797 - precision_26: 0.7577 - recall_26: 0.5404 - val_loss: 0.1098 - val_precision_26: 0.6301 - val_recall_26: 0.5138\n",
      "Epoch 88/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0769 - precision_26: 0.7686 - recall_26: 0.5571\n",
      "Epoch 88: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0769 - precision_26: 0.7688 - recall_26: 0.5572 - val_loss: 0.1098 - val_precision_26: 0.6269 - val_recall_26: 0.5211\n",
      "Epoch 89/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0782 - precision_26: 0.7666 - recall_26: 0.5474\n",
      "Epoch 89: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0780 - precision_26: 0.7667 - recall_26: 0.5483 - val_loss: 0.1103 - val_precision_26: 0.6297 - val_recall_26: 0.5218\n",
      "Epoch 90/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0778 - precision_26: 0.7550 - recall_26: 0.5602\n",
      "Epoch 90: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0776 - precision_26: 0.7555 - recall_26: 0.5603 - val_loss: 0.1115 - val_precision_26: 0.6245 - val_recall_26: 0.5089\n",
      "Epoch 91/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0764 - precision_26: 0.7557 - recall_26: 0.5725\n",
      "Epoch 91: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0763 - precision_26: 0.7564 - recall_26: 0.5732 - val_loss: 0.1102 - val_precision_26: 0.6374 - val_recall_26: 0.4988\n",
      "Epoch 92/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0763 - precision_26: 0.7674 - recall_26: 0.5495\n",
      "Epoch 92: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0760 - precision_26: 0.7678 - recall_26: 0.5518 - val_loss: 0.1101 - val_precision_26: 0.6255 - val_recall_26: 0.5039\n",
      "Epoch 93/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0774 - precision_26: 0.7564 - recall_26: 0.5576\n",
      "Epoch 93: val_loss did not improve from 0.10978\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0770 - precision_26: 0.7578 - recall_26: 0.5589 - val_loss: 0.1099 - val_precision_26: 0.6218 - val_recall_26: 0.5034\n",
      "Epoch 94/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0770 - precision_26: 0.7503 - recall_26: 0.5590\n",
      "Epoch 94: val_loss improved from 0.10978 to 0.10946, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0768 - precision_26: 0.7506 - recall_26: 0.5600 - val_loss: 0.1095 - val_precision_26: 0.6310 - val_recall_26: 0.4998\n",
      "Epoch 95/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0744 - precision_26: 0.7816 - recall_26: 0.5550\n",
      "Epoch 95: val_loss did not improve from 0.10946\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0743 - precision_26: 0.7813 - recall_26: 0.5563 - val_loss: 0.1104 - val_precision_26: 0.6304 - val_recall_26: 0.5036\n",
      "Epoch 96/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0754 - precision_26: 0.7500 - recall_26: 0.5854 \n",
      "Epoch 96: val_loss did not improve from 0.10946\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0747 - precision_26: 0.7560 - recall_26: 0.5836 - val_loss: 0.1112 - val_precision_26: 0.6211 - val_recall_26: 0.5012\n",
      "Epoch 97/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0764 - precision_26: 0.7797 - recall_26: 0.5601\n",
      "Epoch 97: val_loss improved from 0.10946 to 0.10894, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0763 - precision_26: 0.7794 - recall_26: 0.5614 - val_loss: 0.1089 - val_precision_26: 0.6337 - val_recall_26: 0.5107\n",
      "Epoch 98/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0737 - precision_26: 0.7832 - recall_26: 0.5803\n",
      "Epoch 98: val_loss did not improve from 0.10894\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0736 - precision_26: 0.7835 - recall_26: 0.5803 - val_loss: 0.1092 - val_precision_26: 0.6229 - val_recall_26: 0.5168\n",
      "Epoch 99/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0739 - precision_26: 0.7842 - recall_26: 0.5927 \n",
      "Epoch 99: val_loss improved from 0.10894 to 0.10843, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0728 - precision_26: 0.7835 - recall_26: 0.5953 - val_loss: 0.1084 - val_precision_26: 0.6230 - val_recall_26: 0.5029\n",
      "Epoch 100/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0755 - precision_26: 0.7835 - recall_26: 0.5624 \n",
      "Epoch 100: val_loss did not improve from 0.10843\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0740 - precision_26: 0.7820 - recall_26: 0.5701 - val_loss: 0.1089 - val_precision_26: 0.6308 - val_recall_26: 0.5216\n",
      "Epoch 101/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0776 - precision_26: 0.7443 - recall_26: 0.5857\n",
      "Epoch 101: val_loss improved from 0.10843 to 0.10762, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0773 - precision_26: 0.7451 - recall_26: 0.5863 - val_loss: 0.1076 - val_precision_26: 0.6485 - val_recall_26: 0.5193\n",
      "Epoch 102/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0764 - precision_26: 0.7680 - recall_26: 0.5498 \n",
      "Epoch 102: val_loss did not improve from 0.10762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - precision_26: 0.7718 - recall_26: 0.5650 - val_loss: 0.1086 - val_precision_26: 0.6389 - val_recall_26: 0.5130\n",
      "Epoch 103/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0748 - precision_26: 0.7818 - recall_26: 0.5793 \n",
      "Epoch 103: val_loss did not improve from 0.10762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0733 - precision_26: 0.7816 - recall_26: 0.5878 - val_loss: 0.1083 - val_precision_26: 0.6401 - val_recall_26: 0.5032\n",
      "Epoch 104/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0712 - precision_26: 0.7821 - recall_26: 0.6036\n",
      "Epoch 104: val_loss did not improve from 0.10762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0711 - precision_26: 0.7823 - recall_26: 0.6037 - val_loss: 0.1082 - val_precision_26: 0.6492 - val_recall_26: 0.5095\n",
      "Epoch 105/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0709 - precision_26: 0.7721 - recall_26: 0.6054\n",
      "Epoch 105: val_loss improved from 0.10762 to 0.10627, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0708 - precision_26: 0.7722 - recall_26: 0.6056 - val_loss: 0.1063 - val_precision_26: 0.6523 - val_recall_26: 0.5140\n",
      "Epoch 106/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0731 - precision_26: 0.7730 - recall_26: 0.5950\n",
      "Epoch 106: val_loss improved from 0.10627 to 0.10541, saving model to 62sec_3layers_256units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0729 - precision_26: 0.7736 - recall_26: 0.5960 - val_loss: 0.1054 - val_precision_26: 0.6541 - val_recall_26: 0.5104\n",
      "Epoch 107/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0757 - precision_26: 0.7718 - recall_26: 0.5743 \n",
      "Epoch 107: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0744 - precision_26: 0.7767 - recall_26: 0.5781 - val_loss: 0.1067 - val_precision_26: 0.6462 - val_recall_26: 0.5220\n",
      "Epoch 108/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0723 - precision_26: 0.7709 - recall_26: 0.6016\n",
      "Epoch 108: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0721 - precision_26: 0.7716 - recall_26: 0.6028 - val_loss: 0.1056 - val_precision_26: 0.6560 - val_recall_26: 0.5061\n",
      "Epoch 109/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0698 - precision_26: 0.8002 - recall_26: 0.5977\n",
      "Epoch 109: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0699 - precision_26: 0.7996 - recall_26: 0.5975 - val_loss: 0.1062 - val_precision_26: 0.6480 - val_recall_26: 0.5095\n",
      "Epoch 110/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0685 - precision_26: 0.7956 - recall_26: 0.6086\n",
      "Epoch 110: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0685 - precision_26: 0.7950 - recall_26: 0.6090 - val_loss: 0.1061 - val_precision_26: 0.6375 - val_recall_26: 0.5125\n",
      "Epoch 111/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0727 - precision_26: 0.7608 - recall_26: 0.5990\n",
      "Epoch 111: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0725 - precision_26: 0.7615 - recall_26: 0.5993 - val_loss: 0.1062 - val_precision_26: 0.6414 - val_recall_26: 0.5109\n",
      "Epoch 112/200\n",
      "\u001b[1m 9/15\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0695 - precision_26: 0.7939 - recall_26: 0.6136 \n",
      "Epoch 112: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0690 - precision_26: 0.7930 - recall_26: 0.6135 - val_loss: 0.1054 - val_precision_26: 0.6484 - val_recall_26: 0.5178\n",
      "Epoch 113/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0702 - precision_26: 0.7832 - recall_26: 0.6000\n",
      "Epoch 113: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0700 - precision_26: 0.7834 - recall_26: 0.6009 - val_loss: 0.1062 - val_precision_26: 0.6360 - val_recall_26: 0.5138\n",
      "Epoch 114/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0694 - precision_26: 0.7906 - recall_26: 0.6107\n",
      "Epoch 114: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0692 - precision_26: 0.7906 - recall_26: 0.6115 - val_loss: 0.1062 - val_precision_26: 0.6280 - val_recall_26: 0.5143\n",
      "Epoch 115/200\n",
      "\u001b[1m 8/15\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0752 - precision_26: 0.7694 - recall_26: 0.5786 \n",
      "Epoch 115: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0728 - precision_26: 0.7736 - recall_26: 0.5906 - val_loss: 0.1064 - val_precision_26: 0.6262 - val_recall_26: 0.5153\n",
      "Epoch 116/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0719 - precision_26: 0.7774 - recall_26: 0.5923\n",
      "Epoch 116: val_loss did not improve from 0.10541\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0717 - precision_26: 0.7774 - recall_26: 0.5935 - val_loss: 0.1073 - val_precision_26: 0.6400 - val_recall_26: 0.5087\n",
      "Epoch 116: early stopping\n",
      "Restoring model weights from the end of the best epoch: 106.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0402 - precision_26: 0.9011 - recall_26: 0.8132 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1082 - precision_26: 0.6384 - recall_26: 0.4983 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1120 - precision_26: 0.6586 - recall_26: 0.4923\n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5513 - precision_27: 0.0513 - recall_27: 0.2405 \n",
      "Epoch 1: val_loss improved from inf to 0.24202, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.5235 - precision_27: 0.0515 - recall_27: 0.2146 - val_loss: 0.2420 - val_precision_27: 0.2000 - val_recall_27: 1.6576e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2394 - precision_27: 0.1508 - recall_27: 0.0395\n",
      "Epoch 2: val_loss improved from 0.24202 to 0.18743, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2343 - precision_27: 0.1513 - recall_27: 0.0356 - val_loss: 0.1874 - val_precision_27: 0.0000e+00 - val_recall_27: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1948 - precision_27: 0.1189 - recall_27: 4.8980e-04   \n",
      "Epoch 3: val_loss did not improve from 0.18743\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1931 - precision_27: 0.1380 - recall_27: 5.1842e-04 - val_loss: 0.1952 - val_precision_27: 0.0000e+00 - val_recall_27: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1905 - precision_27: 0.3272 - recall_27: 4.9533e-04\n",
      "Epoch 4: val_loss improved from 0.18743 to 0.17610, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1895 - precision_27: 0.3293 - recall_27: 6.7317e-04 - val_loss: 0.1761 - val_precision_27: 0.0000e+00 - val_recall_27: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1888 - precision_27: 0.3354 - recall_27: 0.0023       \n",
      "Epoch 5: val_loss did not improve from 0.17610\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1882 - precision_27: 0.3398 - recall_27: 0.0039 - val_loss: 0.1951 - val_precision_27: 0.4545 - val_recall_27: 0.0050\n",
      "Epoch 6/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1728 - precision_27: 0.3840 - recall_27: 0.0170\n",
      "Epoch 6: val_loss did not improve from 0.17610\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1712 - precision_27: 0.3892 - recall_27: 0.0178 - val_loss: 0.1792 - val_precision_27: 0.3867 - val_recall_27: 0.0444\n",
      "Epoch 7/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1619 - precision_27: 0.3881 - recall_27: 0.0764\n",
      "Epoch 7: val_loss improved from 0.17610 to 0.14722, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1596 - precision_27: 0.3916 - recall_27: 0.0694 - val_loss: 0.1472 - val_precision_27: 0.4569 - val_recall_27: 0.0176\n",
      "Epoch 8/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1459 - precision_27: 0.4335 - recall_27: 0.0678\n",
      "Epoch 8: val_loss improved from 0.14722 to 0.14496, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1450 - precision_27: 0.4338 - recall_27: 0.0712 - val_loss: 0.1450 - val_precision_27: 0.5231 - val_recall_27: 0.0244\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1417 - precision_27: 0.4590 - recall_27: 0.0431\n",
      "Epoch 9: val_loss did not improve from 0.14496\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1404 - precision_27: 0.4667 - recall_27: 0.0527 - val_loss: 0.1513 - val_precision_27: 0.4432 - val_recall_27: 0.0874\n",
      "Epoch 10/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1345 - precision_27: 0.5071 - recall_27: 0.0870\n",
      "Epoch 10: val_loss did not improve from 0.14496\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1343 - precision_27: 0.5088 - recall_27: 0.0876 - val_loss: 0.1506 - val_precision_27: 0.4363 - val_recall_27: 0.1232\n",
      "Epoch 11/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1303 - precision_27: 0.5434 - recall_27: 0.1356\n",
      "Epoch 11: val_loss improved from 0.14496 to 0.14079, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1288 - precision_27: 0.5574 - recall_27: 0.1326 - val_loss: 0.1408 - val_precision_27: 0.4888 - val_recall_27: 0.1343\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1221 - precision_27: 0.6131 - recall_27: 0.1799\n",
      "Epoch 12: val_loss improved from 0.14079 to 0.13469, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1209 - precision_27: 0.6150 - recall_27: 0.1866 - val_loss: 0.1347 - val_precision_27: 0.5251 - val_recall_27: 0.1664\n",
      "Epoch 13/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1141 - precision_27: 0.6905 - recall_27: 0.2273\n",
      "Epoch 13: val_loss improved from 0.13469 to 0.13038, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1130 - precision_27: 0.6851 - recall_27: 0.2380 - val_loss: 0.1304 - val_precision_27: 0.5504 - val_recall_27: 0.2145\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1041 - precision_27: 0.7251 - recall_27: 0.2870\n",
      "Epoch 14: val_loss did not improve from 0.13038\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1036 - precision_27: 0.7207 - recall_27: 0.3008 - val_loss: 0.1315 - val_precision_27: 0.5318 - val_recall_27: 0.3045\n",
      "Epoch 15/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0980 - precision_27: 0.7419 - recall_27: 0.3593\n",
      "Epoch 15: val_loss did not improve from 0.13038\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0977 - precision_27: 0.7426 - recall_27: 0.3623 - val_loss: 0.1324 - val_precision_27: 0.5304 - val_recall_27: 0.3789\n",
      "Epoch 16/200\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0892 - precision_27: 0.7394 - recall_27: 0.4637\n",
      "Epoch 16: val_loss improved from 0.13038 to 0.12688, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0890 - precision_27: 0.7422 - recall_27: 0.4619 - val_loss: 0.1269 - val_precision_27: 0.5451 - val_recall_27: 0.4151\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0850 - precision_27: 0.7453 - recall_27: 0.5173\n",
      "Epoch 17: val_loss improved from 0.12688 to 0.12094, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0844 - precision_27: 0.7486 - recall_27: 0.5132 - val_loss: 0.1209 - val_precision_27: 0.5916 - val_recall_27: 0.3981\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0830 - precision_27: 0.7539 - recall_27: 0.5084\n",
      "Epoch 18: val_loss improved from 0.12094 to 0.11509, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0821 - precision_27: 0.7547 - recall_27: 0.5152 - val_loss: 0.1151 - val_precision_27: 0.6088 - val_recall_27: 0.3877\n",
      "Epoch 19/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0768 - precision_27: 0.7950 - recall_27: 0.5327\n",
      "Epoch 19: val_loss improved from 0.11509 to 0.11216, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0762 - precision_27: 0.7896 - recall_27: 0.5423 - val_loss: 0.1122 - val_precision_27: 0.6285 - val_recall_27: 0.4389\n",
      "Epoch 20/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0724 - precision_27: 0.8138 - recall_27: 0.5638\n",
      "Epoch 20: val_loss did not improve from 0.11216\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0720 - precision_27: 0.8132 - recall_27: 0.5653 - val_loss: 0.1182 - val_precision_27: 0.5903 - val_recall_27: 0.4823\n",
      "Epoch 21/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0682 - precision_27: 0.8091 - recall_27: 0.5934\n",
      "Epoch 21: val_loss did not improve from 0.11216\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0681 - precision_27: 0.8097 - recall_27: 0.5934 - val_loss: 0.1186 - val_precision_27: 0.5830 - val_recall_27: 0.4777\n",
      "Epoch 22/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0666 - precision_27: 0.8028 - recall_27: 0.6393\n",
      "Epoch 22: val_loss improved from 0.11216 to 0.10798, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0657 - precision_27: 0.8049 - recall_27: 0.6403 - val_loss: 0.1080 - val_precision_27: 0.6489 - val_recall_27: 0.4696\n",
      "Epoch 23/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0620 - precision_27: 0.8402 - recall_27: 0.6308\n",
      "Epoch 23: val_loss did not improve from 0.10798\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0619 - precision_27: 0.8389 - recall_27: 0.6325 - val_loss: 0.1099 - val_precision_27: 0.6171 - val_recall_27: 0.5122\n",
      "Epoch 24/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0586 - precision_27: 0.8395 - recall_27: 0.6612\n",
      "Epoch 24: val_loss did not improve from 0.10798\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0585 - precision_27: 0.8400 - recall_27: 0.6614 - val_loss: 0.1133 - val_precision_27: 0.6117 - val_recall_27: 0.5480\n",
      "Epoch 25/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0574 - precision_27: 0.8152 - recall_27: 0.7111\n",
      "Epoch 25: val_loss did not improve from 0.10798\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0568 - precision_27: 0.8225 - recall_27: 0.7056 - val_loss: 0.1107 - val_precision_27: 0.6394 - val_recall_27: 0.5163\n",
      "Epoch 26/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0534 - precision_27: 0.8540 - recall_27: 0.7073\n",
      "Epoch 26: val_loss improved from 0.10798 to 0.10589, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0533 - precision_27: 0.8536 - recall_27: 0.7082 - val_loss: 0.1059 - val_precision_27: 0.6727 - val_recall_27: 0.5140\n",
      "Epoch 27/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0514 - precision_27: 0.8706 - recall_27: 0.6949\n",
      "Epoch 27: val_loss improved from 0.10589 to 0.10516, saving model to 62sec_3layers_512units_0.3drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0513 - precision_27: 0.8697 - recall_27: 0.6965 - val_loss: 0.1052 - val_precision_27: 0.6515 - val_recall_27: 0.5583\n",
      "Epoch 28/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0487 - precision_27: 0.8686 - recall_27: 0.7276\n",
      "Epoch 28: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0483 - precision_27: 0.8701 - recall_27: 0.7274 - val_loss: 0.1079 - val_precision_27: 0.6242 - val_recall_27: 0.5762\n",
      "Epoch 29/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0464 - precision_27: 0.8618 - recall_27: 0.7553\n",
      "Epoch 29: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0461 - precision_27: 0.8631 - recall_27: 0.7529 - val_loss: 0.1058 - val_precision_27: 0.6472 - val_recall_27: 0.5836\n",
      "Epoch 30/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0461 - precision_27: 0.8785 - recall_27: 0.7460\n",
      "Epoch 30: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0452 - precision_27: 0.8765 - recall_27: 0.7537 - val_loss: 0.1061 - val_precision_27: 0.6603 - val_recall_27: 0.5642\n",
      "Epoch 31/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0438 - precision_27: 0.8910 - recall_27: 0.7504\n",
      "Epoch 31: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0434 - precision_27: 0.8882 - recall_27: 0.7548 - val_loss: 0.1066 - val_precision_27: 0.6416 - val_recall_27: 0.5835\n",
      "Epoch 32/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0427 - precision_27: 0.8806 - recall_27: 0.7669\n",
      "Epoch 32: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0426 - precision_27: 0.8807 - recall_27: 0.7675 - val_loss: 0.1058 - val_precision_27: 0.6511 - val_recall_27: 0.5926\n",
      "Epoch 33/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0391 - precision_27: 0.8950 - recall_27: 0.7895\n",
      "Epoch 33: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0389 - precision_27: 0.8946 - recall_27: 0.7890 - val_loss: 0.1065 - val_precision_27: 0.6373 - val_recall_27: 0.6047\n",
      "Epoch 34/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0380 - precision_27: 0.8891 - recall_27: 0.7967\n",
      "Epoch 34: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0374 - precision_27: 0.8909 - recall_27: 0.7998 - val_loss: 0.1060 - val_precision_27: 0.6624 - val_recall_27: 0.6042\n",
      "Epoch 35/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0376 - precision_27: 0.8954 - recall_27: 0.7917\n",
      "Epoch 35: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0368 - precision_27: 0.8963 - recall_27: 0.7978 - val_loss: 0.1053 - val_precision_27: 0.6611 - val_recall_27: 0.6143\n",
      "Epoch 36/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0372 - precision_27: 0.8981 - recall_27: 0.7967\n",
      "Epoch 36: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0362 - precision_27: 0.8996 - recall_27: 0.8022 - val_loss: 0.1060 - val_precision_27: 0.6617 - val_recall_27: 0.6193\n",
      "Epoch 37/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0353 - precision_27: 0.8952 - recall_27: 0.8193\n",
      "Epoch 37: val_loss did not improve from 0.10516\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0348 - precision_27: 0.8959 - recall_27: 0.8212 - val_loss: 0.1073 - val_precision_27: 0.6523 - val_recall_27: 0.6038\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0314 - precision_27: 0.9236 - recall_27: 0.8684 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1070 - precision_27: 0.6408 - recall_27: 0.5548 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1123 - precision_27: 0.6707 - recall_27: 0.5606 \n",
      "Epoch 1/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5561 - precision_28: 0.0522 - recall_28: 0.2556\n",
      "Epoch 1: val_loss improved from inf to 0.23797, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.5284 - precision_28: 0.0524 - recall_28: 0.2284 - val_loss: 0.2380 - val_precision_28: 0.0000e+00 - val_recall_28: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2352 - precision_28: 0.1447 - recall_28: 0.0390 \n",
      "Epoch 2: val_loss improved from 0.23797 to 0.18680, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2321 - precision_28: 0.1463 - recall_28: 0.0368 - val_loss: 0.1868 - val_precision_28: 0.0000e+00 - val_recall_28: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1984 - precision_28: 0.2485 - recall_28: 0.0017\n",
      "Epoch 3: val_loss did not improve from 0.18680\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1962 - precision_28: 0.2355 - recall_28: 0.0016 - val_loss: 0.1940 - val_precision_28: 0.0000e+00 - val_recall_28: 0.0000e+00\n",
      "Epoch 4/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1979 - precision_28: 0.3557 - recall_28: 9.6732e-04   \n",
      "Epoch 4: val_loss improved from 0.18680 to 0.17061, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1971 - precision_28: 0.3440 - recall_28: 0.0012 - val_loss: 0.1706 - val_precision_28: 0.0000e+00 - val_recall_28: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1809 - precision_28: 0.3088 - recall_28: 0.0013    \n",
      "Epoch 5: val_loss did not improve from 0.17061\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1803 - precision_28: 0.3075 - recall_28: 0.0021 - val_loss: 0.2121 - val_precision_28: 0.5200 - val_recall_28: 0.0022\n",
      "Epoch 6/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1792 - precision_28: 0.3366 - recall_28: 0.0136\n",
      "Epoch 6: val_loss improved from 0.17061 to 0.16410, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1776 - precision_28: 0.3428 - recall_28: 0.0133 - val_loss: 0.1641 - val_precision_28: 0.4145 - val_recall_28: 0.0104\n",
      "Epoch 7/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1611 - precision_28: 0.3487 - recall_28: 0.0402\n",
      "Epoch 7: val_loss improved from 0.16410 to 0.14820, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1596 - precision_28: 0.3614 - recall_28: 0.0410 - val_loss: 0.1482 - val_precision_28: 0.4607 - val_recall_28: 0.0068\n",
      "Epoch 8/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1531 - precision_28: 0.3884 - recall_28: 0.0293\n",
      "Epoch 8: val_loss did not improve from 0.14820\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1518 - precision_28: 0.3929 - recall_28: 0.0371 - val_loss: 0.1574 - val_precision_28: 0.4843 - val_recall_28: 0.0716\n",
      "Epoch 9/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1451 - precision_28: 0.3939 - recall_28: 0.0572\n",
      "Epoch 9: val_loss did not improve from 0.14820\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1441 - precision_28: 0.4052 - recall_28: 0.0596 - val_loss: 0.1615 - val_precision_28: 0.4230 - val_recall_28: 0.1233\n",
      "Epoch 10/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1426 - precision_28: 0.4074 - recall_28: 0.0872\n",
      "Epoch 10: val_loss improved from 0.14820 to 0.14724, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1413 - precision_28: 0.4197 - recall_28: 0.0840 - val_loss: 0.1472 - val_precision_28: 0.4690 - val_recall_28: 0.0890\n",
      "Epoch 11/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1359 - precision_28: 0.4899 - recall_28: 0.0950\n",
      "Epoch 11: val_loss improved from 0.14724 to 0.14696, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1357 - precision_28: 0.4912 - recall_28: 0.0959 - val_loss: 0.1470 - val_precision_28: 0.4718 - val_recall_28: 0.0986\n",
      "Epoch 12/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1316 - precision_28: 0.5496 - recall_28: 0.0974\n",
      "Epoch 12: val_loss improved from 0.14696 to 0.14678, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1308 - precision_28: 0.5547 - recall_28: 0.1045 - val_loss: 0.1468 - val_precision_28: 0.4743 - val_recall_28: 0.1422\n",
      "Epoch 13/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1265 - precision_28: 0.5937 - recall_28: 0.1356\n",
      "Epoch 13: val_loss did not improve from 0.14678\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1256 - precision_28: 0.5937 - recall_28: 0.1419 - val_loss: 0.1472 - val_precision_28: 0.4463 - val_recall_28: 0.2137\n",
      "Epoch 14/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1208 - precision_28: 0.6116 - recall_28: 0.1995\n",
      "Epoch 14: val_loss improved from 0.14678 to 0.14170, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1197 - precision_28: 0.6202 - recall_28: 0.2029 - val_loss: 0.1417 - val_precision_28: 0.4997 - val_recall_28: 0.2485\n",
      "Epoch 15/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1130 - precision_28: 0.6591 - recall_28: 0.2649\n",
      "Epoch 15: val_loss improved from 0.14170 to 0.13453, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1123 - precision_28: 0.6610 - recall_28: 0.2677 - val_loss: 0.1345 - val_precision_28: 0.5369 - val_recall_28: 0.2654\n",
      "Epoch 16/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1075 - precision_28: 0.6987 - recall_28: 0.3057\n",
      "Epoch 16: val_loss improved from 0.13453 to 0.13420, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1073 - precision_28: 0.6988 - recall_28: 0.3075 - val_loss: 0.1342 - val_precision_28: 0.5392 - val_recall_28: 0.3360\n",
      "Epoch 17/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1017 - precision_28: 0.7145 - recall_28: 0.3382\n",
      "Epoch 17: val_loss improved from 0.13420 to 0.13347, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1012 - precision_28: 0.7132 - recall_28: 0.3433 - val_loss: 0.1335 - val_precision_28: 0.5414 - val_recall_28: 0.3502\n",
      "Epoch 18/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0984 - precision_28: 0.7260 - recall_28: 0.3774\n",
      "Epoch 18: val_loss improved from 0.13347 to 0.12641, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0976 - precision_28: 0.7244 - recall_28: 0.3845 - val_loss: 0.1264 - val_precision_28: 0.5693 - val_recall_28: 0.3681\n",
      "Epoch 19/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0922 - precision_28: 0.7506 - recall_28: 0.4299\n",
      "Epoch 19: val_loss improved from 0.12641 to 0.12518, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0917 - precision_28: 0.7500 - recall_28: 0.4332 - val_loss: 0.1252 - val_precision_28: 0.5731 - val_recall_28: 0.4134\n",
      "Epoch 20/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0894 - precision_28: 0.7335 - recall_28: 0.4637\n",
      "Epoch 20: val_loss improved from 0.12518 to 0.12358, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0894 - precision_28: 0.7338 - recall_28: 0.4636 - val_loss: 0.1236 - val_precision_28: 0.5876 - val_recall_28: 0.4179\n",
      "Epoch 21/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0860 - precision_28: 0.7498 - recall_28: 0.4844\n",
      "Epoch 21: val_loss improved from 0.12358 to 0.12091, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0856 - precision_28: 0.7516 - recall_28: 0.4839 - val_loss: 0.1209 - val_precision_28: 0.5924 - val_recall_28: 0.4416\n",
      "Epoch 22/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0827 - precision_28: 0.7628 - recall_28: 0.5164\n",
      "Epoch 22: val_loss improved from 0.12091 to 0.11772, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0823 - precision_28: 0.7630 - recall_28: 0.5158 - val_loss: 0.1177 - val_precision_28: 0.5990 - val_recall_28: 0.4507\n",
      "Epoch 23/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0798 - precision_28: 0.7770 - recall_28: 0.5197\n",
      "Epoch 23: val_loss did not improve from 0.11772\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0792 - precision_28: 0.7755 - recall_28: 0.5247 - val_loss: 0.1179 - val_precision_28: 0.5851 - val_recall_28: 0.4679\n",
      "Epoch 24/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0778 - precision_28: 0.7776 - recall_28: 0.5454\n",
      "Epoch 24: val_loss did not improve from 0.11772\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0774 - precision_28: 0.7766 - recall_28: 0.5474 - val_loss: 0.1180 - val_precision_28: 0.6173 - val_recall_28: 0.4706\n",
      "Epoch 25/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0758 - precision_28: 0.8010 - recall_28: 0.5519\n",
      "Epoch 25: val_loss improved from 0.11772 to 0.11531, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0754 - precision_28: 0.7975 - recall_28: 0.5550 - val_loss: 0.1153 - val_precision_28: 0.6142 - val_recall_28: 0.4959\n",
      "Epoch 26/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0719 - precision_28: 0.7948 - recall_28: 0.5885\n",
      "Epoch 26: val_loss improved from 0.11531 to 0.11353, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0721 - precision_28: 0.7929 - recall_28: 0.5867 - val_loss: 0.1135 - val_precision_28: 0.6292 - val_recall_28: 0.5022\n",
      "Epoch 27/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0701 - precision_28: 0.8124 - recall_28: 0.5873\n",
      "Epoch 27: val_loss improved from 0.11353 to 0.11265, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0698 - precision_28: 0.8100 - recall_28: 0.5904 - val_loss: 0.1126 - val_precision_28: 0.6183 - val_recall_28: 0.4964\n",
      "Epoch 28/200\n",
      "\u001b[1m10/15\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0675 - precision_28: 0.8151 - recall_28: 0.6110\n",
      "Epoch 28: val_loss improved from 0.11265 to 0.11121, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0671 - precision_28: 0.8149 - recall_28: 0.6108 - val_loss: 0.1112 - val_precision_28: 0.6409 - val_recall_28: 0.5090\n",
      "Epoch 29/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0661 - precision_28: 0.8197 - recall_28: 0.6138\n",
      "Epoch 29: val_loss improved from 0.11121 to 0.11116, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0656 - precision_28: 0.8172 - recall_28: 0.6190 - val_loss: 0.1112 - val_precision_28: 0.6257 - val_recall_28: 0.5327\n",
      "Epoch 30/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0636 - precision_28: 0.8144 - recall_28: 0.6359\n",
      "Epoch 30: val_loss improved from 0.11116 to 0.11100, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0635 - precision_28: 0.8149 - recall_28: 0.6363 - val_loss: 0.1110 - val_precision_28: 0.6223 - val_recall_28: 0.5347\n",
      "Epoch 31/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0616 - precision_28: 0.8294 - recall_28: 0.6465\n",
      "Epoch 31: val_loss did not improve from 0.11100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0614 - precision_28: 0.8272 - recall_28: 0.6497 - val_loss: 0.1121 - val_precision_28: 0.6250 - val_recall_28: 0.5395\n",
      "Epoch 32/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0600 - precision_28: 0.8272 - recall_28: 0.6600\n",
      "Epoch 32: val_loss did not improve from 0.11100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0595 - precision_28: 0.8289 - recall_28: 0.6603 - val_loss: 0.1123 - val_precision_28: 0.6274 - val_recall_28: 0.5515\n",
      "Epoch 33/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0581 - precision_28: 0.8303 - recall_28: 0.6781\n",
      "Epoch 33: val_loss improved from 0.11100 to 0.11057, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0578 - precision_28: 0.8306 - recall_28: 0.6789 - val_loss: 0.1106 - val_precision_28: 0.6390 - val_recall_28: 0.5326\n",
      "Epoch 34/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0565 - precision_28: 0.8444 - recall_28: 0.6811\n",
      "Epoch 34: val_loss improved from 0.11057 to 0.10840, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0560 - precision_28: 0.8426 - recall_28: 0.6837 - val_loss: 0.1084 - val_precision_28: 0.6296 - val_recall_28: 0.5599\n",
      "Epoch 35/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0564 - precision_28: 0.8363 - recall_28: 0.6868\n",
      "Epoch 35: val_loss did not improve from 0.10840\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0560 - precision_28: 0.8371 - recall_28: 0.6871 - val_loss: 0.1093 - val_precision_28: 0.6230 - val_recall_28: 0.5616\n",
      "Epoch 36/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0532 - precision_28: 0.8529 - recall_28: 0.7081\n",
      "Epoch 36: val_loss improved from 0.10840 to 0.10581, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0531 - precision_28: 0.8503 - recall_28: 0.7087 - val_loss: 0.1058 - val_precision_28: 0.6486 - val_recall_28: 0.5624\n",
      "Epoch 37/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0554 - precision_28: 0.8321 - recall_28: 0.6805\n",
      "Epoch 37: val_loss improved from 0.10581 to 0.10492, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0545 - precision_28: 0.8350 - recall_28: 0.6886 - val_loss: 0.1049 - val_precision_28: 0.6431 - val_recall_28: 0.5798\n",
      "Epoch 38/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0516 - precision_28: 0.8582 - recall_28: 0.7208\n",
      "Epoch 38: val_loss did not improve from 0.10492\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0514 - precision_28: 0.8585 - recall_28: 0.7211 - val_loss: 0.1072 - val_precision_28: 0.6365 - val_recall_28: 0.5821\n",
      "Epoch 39/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0507 - precision_28: 0.8550 - recall_28: 0.7288\n",
      "Epoch 39: val_loss improved from 0.10492 to 0.10380, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0499 - precision_28: 0.8540 - recall_28: 0.7337 - val_loss: 0.1038 - val_precision_28: 0.6501 - val_recall_28: 0.5750\n",
      "Epoch 40/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0474 - precision_28: 0.8696 - recall_28: 0.7482\n",
      "Epoch 40: val_loss did not improve from 0.10380\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0474 - precision_28: 0.8688 - recall_28: 0.7472 - val_loss: 0.1044 - val_precision_28: 0.6485 - val_recall_28: 0.5810\n",
      "Epoch 41/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0463 - precision_28: 0.8685 - recall_28: 0.7462\n",
      "Epoch 41: val_loss did not improve from 0.10380\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0462 - precision_28: 0.8682 - recall_28: 0.7468 - val_loss: 0.1039 - val_precision_28: 0.6591 - val_recall_28: 0.5908\n",
      "Epoch 42/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0471 - precision_28: 0.8607 - recall_28: 0.7467\n",
      "Epoch 42: val_loss did not improve from 0.10380\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0463 - precision_28: 0.8622 - recall_28: 0.7504 - val_loss: 0.1048 - val_precision_28: 0.6508 - val_recall_28: 0.6022\n",
      "Epoch 43/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0450 - precision_28: 0.8667 - recall_28: 0.7595\n",
      "Epoch 43: val_loss did not improve from 0.10380\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0448 - precision_28: 0.8705 - recall_28: 0.7562 - val_loss: 0.1045 - val_precision_28: 0.6527 - val_recall_28: 0.6143\n",
      "Epoch 44/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0423 - precision_28: 0.8737 - recall_28: 0.7797\n",
      "Epoch 44: val_loss improved from 0.10380 to 0.10110, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0422 - precision_28: 0.8732 - recall_28: 0.7807 - val_loss: 0.1011 - val_precision_28: 0.6601 - val_recall_28: 0.6100\n",
      "Epoch 45/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0412 - precision_28: 0.8875 - recall_28: 0.7796\n",
      "Epoch 45: val_loss improved from 0.10110 to 0.10044, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0409 - precision_28: 0.8851 - recall_28: 0.7807 - val_loss: 0.1004 - val_precision_28: 0.6655 - val_recall_28: 0.6156\n",
      "Epoch 46/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0396 - precision_28: 0.8862 - recall_28: 0.7831\n",
      "Epoch 46: val_loss did not improve from 0.10044\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0396 - precision_28: 0.8854 - recall_28: 0.7842 - val_loss: 0.1014 - val_precision_28: 0.6567 - val_recall_28: 0.6242\n",
      "Epoch 47/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0421 - precision_28: 0.8708 - recall_28: 0.7815\n",
      "Epoch 47: val_loss improved from 0.10044 to 0.09866, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0414 - precision_28: 0.8731 - recall_28: 0.7829 - val_loss: 0.0987 - val_precision_28: 0.6703 - val_recall_28: 0.6257\n",
      "Epoch 48/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0404 - precision_28: 0.8829 - recall_28: 0.7753\n",
      "Epoch 48: val_loss did not improve from 0.09866\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0400 - precision_28: 0.8819 - recall_28: 0.7804 - val_loss: 0.1011 - val_precision_28: 0.6588 - val_recall_28: 0.6217\n",
      "Epoch 49/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0383 - precision_28: 0.8868 - recall_28: 0.7946\n",
      "Epoch 49: val_loss did not improve from 0.09866\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0382 - precision_28: 0.8864 - recall_28: 0.7959 - val_loss: 0.0996 - val_precision_28: 0.6721 - val_recall_28: 0.6299\n",
      "Epoch 50/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0373 - precision_28: 0.8904 - recall_28: 0.8096\n",
      "Epoch 50: val_loss did not improve from 0.09866\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0373 - precision_28: 0.8890 - recall_28: 0.8089 - val_loss: 0.0989 - val_precision_28: 0.6700 - val_recall_28: 0.6277\n",
      "Epoch 51/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0379 - precision_28: 0.8976 - recall_28: 0.7924\n",
      "Epoch 51: val_loss did not improve from 0.09866\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0374 - precision_28: 0.8955 - recall_28: 0.7958 - val_loss: 0.0999 - val_precision_28: 0.6611 - val_recall_28: 0.6295\n",
      "Epoch 52/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0359 - precision_28: 0.8984 - recall_28: 0.8063\n",
      "Epoch 52: val_loss improved from 0.09866 to 0.09805, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0355 - precision_28: 0.8972 - recall_28: 0.8101 - val_loss: 0.0981 - val_precision_28: 0.6792 - val_recall_28: 0.6289\n",
      "Epoch 53/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0355 - precision_28: 0.8974 - recall_28: 0.8095\n",
      "Epoch 53: val_loss did not improve from 0.09805\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0353 - precision_28: 0.8975 - recall_28: 0.8108 - val_loss: 0.0997 - val_precision_28: 0.6571 - val_recall_28: 0.6357\n",
      "Epoch 54/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0334 - precision_28: 0.9031 - recall_28: 0.8269\n",
      "Epoch 54: val_loss did not improve from 0.09805\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0334 - precision_28: 0.9018 - recall_28: 0.8271 - val_loss: 0.0991 - val_precision_28: 0.6583 - val_recall_28: 0.6345\n",
      "Epoch 55/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0339 - precision_28: 0.8982 - recall_28: 0.8192\n",
      "Epoch 55: val_loss did not improve from 0.09805\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0337 - precision_28: 0.8976 - recall_28: 0.8222 - val_loss: 0.0995 - val_precision_28: 0.6637 - val_recall_28: 0.6453\n",
      "Epoch 56/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0350 - precision_28: 0.8935 - recall_28: 0.8221\n",
      "Epoch 56: val_loss improved from 0.09805 to 0.09768, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0346 - precision_28: 0.8939 - recall_28: 0.8239 - val_loss: 0.0977 - val_precision_28: 0.6666 - val_recall_28: 0.6352\n",
      "Epoch 57/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0338 - precision_28: 0.8974 - recall_28: 0.8192\n",
      "Epoch 57: val_loss did not improve from 0.09768\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0336 - precision_28: 0.8963 - recall_28: 0.8213 - val_loss: 0.0987 - val_precision_28: 0.6750 - val_recall_28: 0.6498\n",
      "Epoch 58/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0311 - precision_28: 0.9114 - recall_28: 0.8440\n",
      "Epoch 58: val_loss improved from 0.09768 to 0.09762, saving model to 62sec_3layers_512units_0.4drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0311 - precision_28: 0.9103 - recall_28: 0.8428 - val_loss: 0.0976 - val_precision_28: 0.6755 - val_recall_28: 0.6566\n",
      "Epoch 59/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0305 - precision_28: 0.9047 - recall_28: 0.8486\n",
      "Epoch 59: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0303 - precision_28: 0.9051 - recall_28: 0.8490 - val_loss: 0.0980 - val_precision_28: 0.6718 - val_recall_28: 0.6501\n",
      "Epoch 60/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0307 - precision_28: 0.9084 - recall_28: 0.8405\n",
      "Epoch 60: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0305 - precision_28: 0.9070 - recall_28: 0.8422 - val_loss: 0.0989 - val_precision_28: 0.6774 - val_recall_28: 0.6471\n",
      "Epoch 61/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0292 - precision_28: 0.9145 - recall_28: 0.8451\n",
      "Epoch 61: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0292 - precision_28: 0.9141 - recall_28: 0.8455 - val_loss: 0.0984 - val_precision_28: 0.6644 - val_recall_28: 0.6517\n",
      "Epoch 62/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0287 - precision_28: 0.9067 - recall_28: 0.8579\n",
      "Epoch 62: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0286 - precision_28: 0.9070 - recall_28: 0.8585 - val_loss: 0.0992 - val_precision_28: 0.6714 - val_recall_28: 0.6483\n",
      "Epoch 63/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0276 - precision_28: 0.9170 - recall_28: 0.8575\n",
      "Epoch 63: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0276 - precision_28: 0.9163 - recall_28: 0.8571 - val_loss: 0.1005 - val_precision_28: 0.6605 - val_recall_28: 0.6551\n",
      "Epoch 64/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0283 - precision_28: 0.9127 - recall_28: 0.8526\n",
      "Epoch 64: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0281 - precision_28: 0.9122 - recall_28: 0.8561 - val_loss: 0.0988 - val_precision_28: 0.6794 - val_recall_28: 0.6576\n",
      "Epoch 65/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0296 - precision_28: 0.9069 - recall_28: 0.8507\n",
      "Epoch 65: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0290 - precision_28: 0.9094 - recall_28: 0.8533 - val_loss: 0.1000 - val_precision_28: 0.6716 - val_recall_28: 0.6668\n",
      "Epoch 66/200\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0272 - precision_28: 0.9167 - recall_28: 0.8661\n",
      "Epoch 66: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0271 - precision_28: 0.9168 - recall_28: 0.8667 - val_loss: 0.0986 - val_precision_28: 0.6742 - val_recall_28: 0.6690\n",
      "Epoch 67/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0255 - precision_28: 0.9241 - recall_28: 0.8715\n",
      "Epoch 67: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0254 - precision_28: 0.9239 - recall_28: 0.8714 - val_loss: 0.0977 - val_precision_28: 0.6763 - val_recall_28: 0.6624\n",
      "Epoch 68/200\n",
      "\u001b[1m11/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0266 - precision_28: 0.9219 - recall_28: 0.8645\n",
      "Epoch 68: val_loss did not improve from 0.09762\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0266 - precision_28: 0.9199 - recall_28: 0.8656 - val_loss: 0.0983 - val_precision_28: 0.6831 - val_recall_28: 0.6690\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0123 - precision_28: 0.9620 - recall_28: 0.9620 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 - precision_28: 0.6652 - recall_28: 0.6512 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1080 - precision_28: 0.6591 - recall_28: 0.6251 \n",
      "Epoch 1/200\n",
      "\u001b[1m12/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.5834 - precision_29: 0.0534 - recall_29: 0.2988\n",
      "Epoch 1: val_loss improved from inf to 0.21657, saving model to 62sec_3layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.5456 - precision_29: 0.0535 - recall_29: 0.2570 - val_loss: 0.2166 - val_precision_29: 0.0000e+00 - val_recall_29: 0.0000e+00\n",
      "Epoch 2/200\n",
      "\u001b[1m13/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2311 - precision_29: 0.1521 - recall_29: 0.0328\n",
      "Epoch 2: val_loss improved from 0.21657 to 0.19320, saving model to 62sec_3layers_512units_0.5drop.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2290 - precision_29: 0.1517 - recall_29: 0.0317 - val_loss: 0.1932 - val_precision_29: 0.0000e+00 - val_recall_29: 0.0000e+00\n",
      "Epoch 3/200\n"
     ]
    }
   ],
   "source": [
    "sequence_lengths = [62, 42, 22]\n",
    "num_layers_list = [1, 2, 3]\n",
    "dropout_rates = [0.3, 0.4, 0.5]\n",
    "num_units_list = [256, 512, 1024, 2048]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "all_results = []\n",
    "\n",
    "for seq_len in sequence_lengths:\n",
    "    for num_layers in num_layers_list:\n",
    "        for num_units in num_units_list:\n",
    "            for dropout_rate in dropout_rates:\n",
    "                # Prepare data for FFNN\n",
    "                train_data = (\n",
    "                    all_data[seq_len]['encoder_input_data_train'].reshape((all_data[seq_len]['encoder_input_data_train'].shape[0], -1)),\n",
    "                    all_data[seq_len]['decoder_target_data_train'].reshape((all_data[seq_len]['decoder_target_data_train'].shape[0], -1))\n",
    "                )\n",
    "                val_data = (\n",
    "                    all_data[seq_len]['encoder_input_data_val'].reshape((all_data[seq_len]['encoder_input_data_val'].shape[0], -1)),\n",
    "                    all_data[seq_len]['decoder_target_data_val'].reshape((all_data[seq_len]['decoder_target_data_val'].shape[0], -1))\n",
    "                )\n",
    "                test_data = (\n",
    "                    all_data[seq_len]['encoder_input_data_test'].reshape((all_data[seq_len]['encoder_input_data_test'].shape[0], -1)),\n",
    "                    all_data[seq_len]['decoder_target_data_test'].reshape((all_data[seq_len]['decoder_target_data_test'].shape[0], -1))\n",
    "                )\n",
    "                \n",
    "                input_dim = train_data[0].shape[1]\n",
    "                output_dim = train_data[1].shape[1]\n",
    "                \n",
    "                # Build FFNN model\n",
    "                ffnn_model = build_ffnn_model(input_dim, output_dim, layers=num_layers, units=num_units, dropout_rate=dropout_rate)\n",
    "                \n",
    "                model_name = f'{seq_len}sec_{num_layers}layers_{num_units}units_{dropout_rate}drop'\n",
    "                \n",
    "                # Train FFNN model\n",
    "                ffnn_history, epochs_taken = train_ffnn_model(ffnn_model, train_data, val_data, model_name=model_name)\n",
    "                \n",
    "                # Evaluate FFNN model\n",
    "                train_results = evaluate_ffnn_model(ffnn_model, train_data)\n",
    "                val_results = evaluate_ffnn_model(ffnn_model, val_data)\n",
    "                test_results = evaluate_ffnn_model(ffnn_model, test_data)\n",
    "                \n",
    "                # Store results\n",
    "                all_results.append({\n",
    "                    'Model': model_name,\n",
    "                    'Train_Loss': train_results[0],\n",
    "                    'Train_Precision': train_results[1],\n",
    "                    'Train_Recall': train_results[2],\n",
    "                    'Val_Loss': val_results[0],\n",
    "                    'Val_Precision': val_results[1],\n",
    "                    'Val_Recall': val_results[2],\n",
    "                    'Test_Precision': test_results[1],\n",
    "                    'Test_Recall': test_results[2],\n",
    "                    'Epochs_Taken': epochs_taken\n",
    "                })\n",
    "\n",
    "# Convert results to a DataFrame and save to a CSV file\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv('ffnn_results.csv', index=False)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb7813-c021-4ecb-ae04-1ce19672c4d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Build Encoder Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c2526-ebc6-476c-bde0-f0956341cd8d",
   "metadata": {},
   "source": [
    "I would now like to build an encoder-decoder LSTM model that can be compared to the baseline model. Because one layer performed best for the feed-forward NN, I will focus on single layers for my LSTM, but with the same parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4539dd8-6d2a-47bf-9b6a-43907f6263a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_lstm_model(input_features, output_features, latent_dim, dropout_rate=0.5, optimizer_name='Adam', learning_rate=0.001):\n",
    "    # Define encoder\n",
    "    encoder_inputs = Input(shape=(None, input_features))\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "    encoder_outputs = BatchNormalization()(encoder_outputs)\n",
    "    encoder_outputs = Dropout(dropout_rate)(encoder_outputs)\n",
    "    \n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Define decoder\n",
    "    decoder_inputs = Input(shape=(None, output_features))\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_outputs = BatchNormalization()(decoder_outputs)\n",
    "    decoder_outputs = Dropout(dropout_rate)(decoder_outputs)\n",
    "    \n",
    "    decoder_dense = TimeDistributed(Dense(output_features, activation='sigmoid'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = optimizers.get(optimizer_name)(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lstm_model(model, train_data, val_data, model_name, epochs=200, batch_size=32):\n",
    "    encoder_input_data_train, decoder_input_data_train, decoder_target_data_train = train_data\n",
    "    encoder_input_data_val, decoder_input_data_val, decoder_target_data_val = val_data\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    csv_logger = CSVLogger(f'{model_name}_log.csv', append=True, separator=',')\n",
    "    \n",
    "    history = model.fit(\n",
    "        [encoder_input_data_train, decoder_input_data_train], decoder_target_data_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=([encoder_input_data_val, decoder_input_data_val], decoder_target_data_val),\n",
    "        callbacks=[checkpoint, early_stopping, csv_logger]\n",
    "    )\n",
    "    \n",
    "    epochs_taken = len(history.history['loss'])\n",
    "    \n",
    "    return history, epochs_taken\n",
    "    \n",
    "def evaluate_lstm_model(model, data):\n",
    "    encoder_input_data, decoder_input_data, decoder_target_data = data\n",
    "    results = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938d6c1-19a5-452f-9f22-0f945fa42c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.9583 - precision_1: 0.0604 - recall_1: 0.6128\n",
      "Epoch 1: val_loss improved from inf to 0.64952, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.9563 - precision_1: 0.0608 - recall_1: 0.6159 - val_loss: 0.6495 - val_precision_1: 0.2981 - val_recall_1: 0.8183\n",
      "Epoch 2/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.7586 - precision_1: 0.0961 - recall_1: 0.8742\n",
      "Epoch 2: val_loss improved from 0.64952 to 0.57660, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.7578 - precision_1: 0.0961 - recall_1: 0.8741 - val_loss: 0.5766 - val_precision_1: 0.7640 - val_recall_1: 0.6917\n",
      "Epoch 3/500\n",
      "\u001b[1m28/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6327 - precision_1: 0.1187 - recall_1: 0.8726\n",
      "Epoch 3: val_loss improved from 0.57660 to 0.43319, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.6301 - precision_1: 0.1192 - recall_1: 0.8719 - val_loss: 0.4332 - val_precision_1: 0.9122 - val_recall_1: 0.4613\n",
      "Epoch 4/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4597 - precision_1: 0.1824 - recall_1: 0.8316\n",
      "Epoch 4: val_loss improved from 0.43319 to 0.26522, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.4583 - precision_1: 0.1830 - recall_1: 0.8309 - val_loss: 0.2652 - val_precision_1: 0.9501 - val_recall_1: 0.1924\n",
      "Epoch 5/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2899 - precision_1: 0.3273 - recall_1: 0.7383\n",
      "Epoch 5: val_loss improved from 0.26522 to 0.17054, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.2889 - precision_1: 0.3283 - recall_1: 0.7373 - val_loss: 0.1705 - val_precision_1: 0.9535 - val_recall_1: 0.0646\n",
      "Epoch 6/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1824 - precision_1: 0.5242 - recall_1: 0.6299\n",
      "Epoch 6: val_loss improved from 0.17054 to 0.13354, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.1820 - precision_1: 0.5250 - recall_1: 0.6294 - val_loss: 0.1335 - val_precision_1: 0.9598 - val_recall_1: 0.0277\n",
      "Epoch 7/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1372 - precision_1: 0.6483 - recall_1: 0.5750\n",
      "Epoch 7: val_loss improved from 0.13354 to 0.11815, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.1370 - precision_1: 0.6488 - recall_1: 0.5749 - val_loss: 0.1182 - val_precision_1: 0.9654 - val_recall_1: 0.0370\n",
      "Epoch 8/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1158 - precision_1: 0.7101 - recall_1: 0.5737\n",
      "Epoch 8: val_loss improved from 0.11815 to 0.10779, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.1156 - precision_1: 0.7108 - recall_1: 0.5736 - val_loss: 0.1078 - val_precision_1: 0.9676 - val_recall_1: 0.0842\n",
      "Epoch 9/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1004 - precision_1: 0.7821 - recall_1: 0.5800\n",
      "Epoch 9: val_loss improved from 0.10779 to 0.09776, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.1003 - precision_1: 0.7822 - recall_1: 0.5801 - val_loss: 0.0978 - val_precision_1: 0.9759 - val_recall_1: 0.1545\n",
      "Epoch 10/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0923 - precision_1: 0.8048 - recall_1: 0.6015\n",
      "Epoch 10: val_loss improved from 0.09776 to 0.08901, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0922 - precision_1: 0.8049 - recall_1: 0.6016 - val_loss: 0.0890 - val_precision_1: 0.9707 - val_recall_1: 0.2523\n",
      "Epoch 11/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0859 - precision_1: 0.8227 - recall_1: 0.6164\n",
      "Epoch 11: val_loss improved from 0.08901 to 0.08033, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0858 - precision_1: 0.8225 - recall_1: 0.6166 - val_loss: 0.0803 - val_precision_1: 0.9638 - val_recall_1: 0.3746\n",
      "Epoch 12/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0825 - precision_1: 0.8190 - recall_1: 0.6313\n",
      "Epoch 12: val_loss improved from 0.08033 to 0.07402, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0825 - precision_1: 0.8190 - recall_1: 0.6313 - val_loss: 0.0740 - val_precision_1: 0.9609 - val_recall_1: 0.4441\n",
      "Epoch 13/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0788 - precision_1: 0.8290 - recall_1: 0.6451\n",
      "Epoch 13: val_loss improved from 0.07402 to 0.06864, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0787 - precision_1: 0.8288 - recall_1: 0.6452 - val_loss: 0.0686 - val_precision_1: 0.9542 - val_recall_1: 0.5079\n",
      "Epoch 14/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0759 - precision_1: 0.8383 - recall_1: 0.6521\n",
      "Epoch 14: val_loss improved from 0.06864 to 0.06361, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0759 - precision_1: 0.8384 - recall_1: 0.6524 - val_loss: 0.0636 - val_precision_1: 0.9487 - val_recall_1: 0.5730\n",
      "Epoch 15/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0727 - precision_1: 0.8412 - recall_1: 0.6668\n",
      "Epoch 15: val_loss improved from 0.06361 to 0.05972, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0726 - precision_1: 0.8412 - recall_1: 0.6669 - val_loss: 0.0597 - val_precision_1: 0.9451 - val_recall_1: 0.6216\n",
      "Epoch 16/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0702 - precision_1: 0.8481 - recall_1: 0.6802\n",
      "Epoch 16: val_loss improved from 0.05972 to 0.05669, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0701 - precision_1: 0.8480 - recall_1: 0.6804 - val_loss: 0.0567 - val_precision_1: 0.9414 - val_recall_1: 0.6519\n",
      "Epoch 17/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0681 - precision_1: 0.8548 - recall_1: 0.6838\n",
      "Epoch 17: val_loss improved from 0.05669 to 0.05416, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0681 - precision_1: 0.8547 - recall_1: 0.6840 - val_loss: 0.0542 - val_precision_1: 0.9313 - val_recall_1: 0.6826\n",
      "Epoch 18/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0662 - precision_1: 0.8519 - recall_1: 0.7028\n",
      "Epoch 18: val_loss improved from 0.05416 to 0.05295, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0662 - precision_1: 0.8520 - recall_1: 0.7029 - val_loss: 0.0529 - val_precision_1: 0.9255 - val_recall_1: 0.6924\n",
      "Epoch 19/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0636 - precision_1: 0.8636 - recall_1: 0.7073\n",
      "Epoch 19: val_loss improved from 0.05295 to 0.05108, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0635 - precision_1: 0.8635 - recall_1: 0.7075 - val_loss: 0.0511 - val_precision_1: 0.9259 - val_recall_1: 0.7084\n",
      "Epoch 20/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0630 - precision_1: 0.8578 - recall_1: 0.7165\n",
      "Epoch 20: val_loss improved from 0.05108 to 0.05047, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0629 - precision_1: 0.8577 - recall_1: 0.7167 - val_loss: 0.0505 - val_precision_1: 0.9216 - val_recall_1: 0.7187\n",
      "Epoch 21/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0608 - precision_1: 0.8688 - recall_1: 0.7180\n",
      "Epoch 21: val_loss improved from 0.05047 to 0.04984, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0608 - precision_1: 0.8686 - recall_1: 0.7183 - val_loss: 0.0498 - val_precision_1: 0.9175 - val_recall_1: 0.7280\n",
      "Epoch 22/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0602 - precision_1: 0.8686 - recall_1: 0.7180\n",
      "Epoch 22: val_loss improved from 0.04984 to 0.04879, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0602 - precision_1: 0.8684 - recall_1: 0.7182 - val_loss: 0.0488 - val_precision_1: 0.9139 - val_recall_1: 0.7429\n",
      "Epoch 23/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0585 - precision_1: 0.8693 - recall_1: 0.7350\n",
      "Epoch 23: val_loss improved from 0.04879 to 0.04849, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0585 - precision_1: 0.8692 - recall_1: 0.7351 - val_loss: 0.0485 - val_precision_1: 0.9112 - val_recall_1: 0.7471\n",
      "Epoch 24/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0573 - precision_1: 0.8690 - recall_1: 0.7447\n",
      "Epoch 24: val_loss improved from 0.04849 to 0.04845, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0573 - precision_1: 0.8690 - recall_1: 0.7448 - val_loss: 0.0485 - val_precision_1: 0.9077 - val_recall_1: 0.7497\n",
      "Epoch 25/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0572 - precision_1: 0.8708 - recall_1: 0.7402\n",
      "Epoch 25: val_loss improved from 0.04845 to 0.04789, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0572 - precision_1: 0.8708 - recall_1: 0.7404 - val_loss: 0.0479 - val_precision_1: 0.9106 - val_recall_1: 0.7550\n",
      "Epoch 26/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0550 - precision_1: 0.8751 - recall_1: 0.7472\n",
      "Epoch 26: val_loss improved from 0.04789 to 0.04779, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0549 - precision_1: 0.8750 - recall_1: 0.7474 - val_loss: 0.0478 - val_precision_1: 0.9045 - val_recall_1: 0.7641\n",
      "Epoch 27/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0549 - precision_1: 0.8742 - recall_1: 0.7545\n",
      "Epoch 27: val_loss improved from 0.04779 to 0.04754, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0548 - precision_1: 0.8741 - recall_1: 0.7546 - val_loss: 0.0475 - val_precision_1: 0.9039 - val_recall_1: 0.7606\n",
      "Epoch 28/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0533 - precision_1: 0.8807 - recall_1: 0.7589\n",
      "Epoch 28: val_loss improved from 0.04754 to 0.04740, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0533 - precision_1: 0.8805 - recall_1: 0.7589 - val_loss: 0.0474 - val_precision_1: 0.8987 - val_recall_1: 0.7648\n",
      "Epoch 29/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0529 - precision_1: 0.8794 - recall_1: 0.7604\n",
      "Epoch 29: val_loss improved from 0.04740 to 0.04723, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0529 - precision_1: 0.8793 - recall_1: 0.7605 - val_loss: 0.0472 - val_precision_1: 0.8971 - val_recall_1: 0.7669\n",
      "Epoch 30/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0517 - precision_1: 0.8809 - recall_1: 0.7686\n",
      "Epoch 30: val_loss improved from 0.04723 to 0.04705, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0517 - precision_1: 0.8808 - recall_1: 0.7687 - val_loss: 0.0471 - val_precision_1: 0.8979 - val_recall_1: 0.7693\n",
      "Epoch 31/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0506 - precision_1: 0.8868 - recall_1: 0.7672\n",
      "Epoch 31: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0506 - precision_1: 0.8866 - recall_1: 0.7674 - val_loss: 0.0475 - val_precision_1: 0.8970 - val_recall_1: 0.7623\n",
      "Epoch 32/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0497 - precision_1: 0.8887 - recall_1: 0.7738\n",
      "Epoch 32: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0497 - precision_1: 0.8885 - recall_1: 0.7739 - val_loss: 0.0477 - val_precision_1: 0.8966 - val_recall_1: 0.7646\n",
      "Epoch 33/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0492 - precision_1: 0.8866 - recall_1: 0.7729\n",
      "Epoch 33: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0492 - precision_1: 0.8864 - recall_1: 0.7730 - val_loss: 0.0475 - val_precision_1: 0.8918 - val_recall_1: 0.7666\n",
      "Epoch 34/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0485 - precision_1: 0.8891 - recall_1: 0.7803\n",
      "Epoch 34: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0485 - precision_1: 0.8889 - recall_1: 0.7804 - val_loss: 0.0478 - val_precision_1: 0.8894 - val_recall_1: 0.7676\n",
      "Epoch 35/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0483 - precision_1: 0.8839 - recall_1: 0.7852\n",
      "Epoch 35: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0483 - precision_1: 0.8839 - recall_1: 0.7853 - val_loss: 0.0477 - val_precision_1: 0.8900 - val_recall_1: 0.7655\n",
      "Epoch 36/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0475 - precision_1: 0.8904 - recall_1: 0.7825\n",
      "Epoch 36: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0475 - precision_1: 0.8903 - recall_1: 0.7827 - val_loss: 0.0477 - val_precision_1: 0.8908 - val_recall_1: 0.7641\n",
      "Epoch 37/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0466 - precision_1: 0.8877 - recall_1: 0.7874\n",
      "Epoch 37: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0466 - precision_1: 0.8877 - recall_1: 0.7874 - val_loss: 0.0488 - val_precision_1: 0.8844 - val_recall_1: 0.7610\n",
      "Epoch 38/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0463 - precision_1: 0.8926 - recall_1: 0.7891\n",
      "Epoch 38: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0463 - precision_1: 0.8925 - recall_1: 0.7892 - val_loss: 0.0487 - val_precision_1: 0.8820 - val_recall_1: 0.7645\n",
      "Epoch 39/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0449 - precision_1: 0.8926 - recall_1: 0.7936\n",
      "Epoch 39: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0449 - precision_1: 0.8925 - recall_1: 0.7938 - val_loss: 0.0485 - val_precision_1: 0.8807 - val_recall_1: 0.7636\n",
      "Epoch 40/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0449 - precision_1: 0.8914 - recall_1: 0.7973\n",
      "Epoch 40: val_loss did not improve from 0.04705\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0449 - precision_1: 0.8913 - recall_1: 0.7973 - val_loss: 0.0490 - val_precision_1: 0.8851 - val_recall_1: 0.7573\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0350 - precision_1: 0.9113 - recall_1: 0.8357\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0457 - precision_1: 0.9033 - recall_1: 0.7723\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0566 - precision_1: 0.8830 - recall_1: 0.7296\n",
      "Epoch 1/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.9777 - precision: 0.0581 - recall: 0.5937\n",
      "Epoch 1: val_loss improved from inf to 0.67128, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.9752 - precision: 0.0586 - recall: 0.5986 - val_loss: 0.6713 - val_precision: 0.1548 - val_recall: 0.8526\n",
      "Epoch 2/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8197 - precision: 0.0884 - recall: 0.8539\n",
      "Epoch 2: val_loss improved from 0.67128 to 0.64529, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.8178 - precision: 0.0885 - recall: 0.8548 - val_loss: 0.6453 - val_precision: 0.3690 - val_recall: 0.8185\n",
      "Epoch 3/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7442 - precision: 0.0984 - recall: 0.8880\n",
      "Epoch 3: val_loss improved from 0.64529 to 0.60877, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.7434 - precision: 0.0984 - recall: 0.8880 - val_loss: 0.6088 - val_precision: 0.6748 - val_recall: 0.7582\n",
      "Epoch 4/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6761 - precision: 0.1110 - recall: 0.8973\n",
      "Epoch 4: val_loss improved from 0.60877 to 0.55035, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.6752 - precision: 0.1110 - recall: 0.8971 - val_loss: 0.5504 - val_precision: 0.8515 - val_recall: 0.6604\n",
      "Epoch 5/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5981 - precision: 0.1309 - recall: 0.8898\n",
      "Epoch 5: val_loss improved from 0.55035 to 0.46782, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.5970 - precision: 0.1311 - recall: 0.8894 - val_loss: 0.4678 - val_precision: 0.9072 - val_recall: 0.5236\n",
      "Epoch 6/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5034 - precision: 0.1673 - recall: 0.8655\n",
      "Epoch 6: val_loss improved from 0.46782 to 0.36919, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.5021 - precision: 0.1677 - recall: 0.8651 - val_loss: 0.3692 - val_precision: 0.9377 - val_recall: 0.3570\n",
      "Epoch 7/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4010 - precision: 0.2300 - recall: 0.8337\n",
      "Epoch 7: val_loss improved from 0.36919 to 0.27835, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.3998 - precision: 0.2307 - recall: 0.8332 - val_loss: 0.2783 - val_precision: 0.9629 - val_recall: 0.1938\n",
      "Epoch 8/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3067 - precision: 0.3169 - recall: 0.7825\n",
      "Epoch 8: val_loss improved from 0.27835 to 0.21033, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.3055 - precision: 0.3182 - recall: 0.7817 - val_loss: 0.2103 - val_precision: 0.9634 - val_recall: 0.0786\n",
      "Epoch 9/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2354 - precision: 0.4185 - recall: 0.7254\n",
      "Epoch 9: val_loss improved from 0.21033 to 0.16803, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.2346 - precision: 0.4195 - recall: 0.7249 - val_loss: 0.1680 - val_precision: 0.9559 - val_recall: 0.0215\n",
      "Epoch 10/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1823 - precision: 0.5233 - recall: 0.6700\n",
      "Epoch 10: val_loss improved from 0.16803 to 0.14624, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1817 - precision: 0.5245 - recall: 0.6693 - val_loss: 0.1462 - val_precision: 0.9529 - val_recall: 0.0134\n",
      "Epoch 11/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1497 - precision: 0.6235 - recall: 0.6251\n",
      "Epoch 11: val_loss improved from 0.14624 to 0.13495, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1494 - precision: 0.6236 - recall: 0.6250 - val_loss: 0.1350 - val_precision: 0.9385 - val_recall: 0.0101\n",
      "Epoch 12/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1290 - precision: 0.6809 - recall: 0.6093\n",
      "Epoch 12: val_loss improved from 0.13495 to 0.12729, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1288 - precision: 0.6817 - recall: 0.6095 - val_loss: 0.1273 - val_precision: 0.9167 - val_recall: 0.0091\n",
      "Epoch 13/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1174 - precision: 0.7068 - recall: 0.6075\n",
      "Epoch 13: val_loss improved from 0.12729 to 0.12096, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1172 - precision: 0.7077 - recall: 0.6076 - val_loss: 0.1210 - val_precision: 0.9683 - val_recall: 0.0101\n",
      "Epoch 14/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1048 - precision: 0.7813 - recall: 0.6070\n",
      "Epoch 14: val_loss improved from 0.12096 to 0.11516, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1047 - precision: 0.7811 - recall: 0.6074 - val_loss: 0.1152 - val_precision: 0.9706 - val_recall: 0.0164\n",
      "Epoch 15/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0954 - precision: 0.8065 - recall: 0.6163\n",
      "Epoch 15: val_loss improved from 0.11516 to 0.11026, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0954 - precision: 0.8061 - recall: 0.6166 - val_loss: 0.1103 - val_precision: 0.9543 - val_recall: 0.0346\n",
      "Epoch 16/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0928 - precision: 0.7919 - recall: 0.6216\n",
      "Epoch 16: val_loss improved from 0.11026 to 0.10520, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0927 - precision: 0.7923 - recall: 0.6219 - val_loss: 0.1052 - val_precision: 0.9675 - val_recall: 0.0592\n",
      "Epoch 17/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0873 - precision: 0.8201 - recall: 0.6375\n",
      "Epoch 17: val_loss improved from 0.10520 to 0.10090, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0873 - precision: 0.8197 - recall: 0.6380 - val_loss: 0.1009 - val_precision: 0.9731 - val_recall: 0.1019\n",
      "Epoch 18/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0827 - precision: 0.8409 - recall: 0.6371\n",
      "Epoch 18: val_loss improved from 0.10090 to 0.09549, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0826 - precision: 0.8402 - recall: 0.6378 - val_loss: 0.0955 - val_precision: 0.9733 - val_recall: 0.1573\n",
      "Epoch 19/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0805 - precision: 0.8349 - recall: 0.6518\n",
      "Epoch 19: val_loss improved from 0.09549 to 0.09161, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0804 - precision: 0.8343 - recall: 0.6523 - val_loss: 0.0916 - val_precision: 0.9724 - val_recall: 0.1984\n",
      "Epoch 20/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0783 - precision: 0.8301 - recall: 0.6653\n",
      "Epoch 20: val_loss improved from 0.09161 to 0.08792, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0783 - precision: 0.8299 - recall: 0.6658 - val_loss: 0.0879 - val_precision: 0.9714 - val_recall: 0.2473\n",
      "Epoch 21/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0761 - precision: 0.8363 - recall: 0.6666\n",
      "Epoch 21: val_loss improved from 0.08792 to 0.08343, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0760 - precision: 0.8362 - recall: 0.6671 - val_loss: 0.0834 - val_precision: 0.9688 - val_recall: 0.3033\n",
      "Epoch 22/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0731 - precision: 0.8482 - recall: 0.6779\n",
      "Epoch 22: val_loss improved from 0.08343 to 0.07897, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0731 - precision: 0.8477 - recall: 0.6782 - val_loss: 0.0790 - val_precision: 0.9641 - val_recall: 0.3693\n",
      "Epoch 23/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0723 - precision: 0.8420 - recall: 0.6905\n",
      "Epoch 23: val_loss improved from 0.07897 to 0.07494, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0722 - precision: 0.8421 - recall: 0.6906 - val_loss: 0.0749 - val_precision: 0.9633 - val_recall: 0.4177\n",
      "Epoch 24/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0695 - precision: 0.8531 - recall: 0.6943\n",
      "Epoch 24: val_loss improved from 0.07494 to 0.07149, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0695 - precision: 0.8528 - recall: 0.6946 - val_loss: 0.0715 - val_precision: 0.9646 - val_recall: 0.4608\n",
      "Epoch 25/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0673 - precision: 0.8587 - recall: 0.7023\n",
      "Epoch 25: val_loss improved from 0.07149 to 0.06840, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0672 - precision: 0.8586 - recall: 0.7027 - val_loss: 0.0684 - val_precision: 0.9623 - val_recall: 0.4954\n",
      "Epoch 26/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0668 - precision: 0.8550 - recall: 0.7115\n",
      "Epoch 26: val_loss improved from 0.06840 to 0.06618, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0668 - precision: 0.8546 - recall: 0.7115 - val_loss: 0.0662 - val_precision: 0.9588 - val_recall: 0.5281\n",
      "Epoch 27/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0664 - precision: 0.8468 - recall: 0.7087\n",
      "Epoch 27: val_loss improved from 0.06618 to 0.06289, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0663 - precision: 0.8470 - recall: 0.7091 - val_loss: 0.0629 - val_precision: 0.9544 - val_recall: 0.5727\n",
      "Epoch 28/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0646 - precision: 0.8592 - recall: 0.7205\n",
      "Epoch 28: val_loss improved from 0.06289 to 0.06094, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0646 - precision: 0.8590 - recall: 0.7206 - val_loss: 0.0609 - val_precision: 0.9516 - val_recall: 0.5995\n",
      "Epoch 29/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0631 - precision: 0.8624 - recall: 0.7222\n",
      "Epoch 29: val_loss improved from 0.06094 to 0.05880, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0630 - precision: 0.8623 - recall: 0.7225 - val_loss: 0.0588 - val_precision: 0.9496 - val_recall: 0.6247\n",
      "Epoch 30/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0612 - precision: 0.8701 - recall: 0.7267\n",
      "Epoch 30: val_loss improved from 0.05880 to 0.05682, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0611 - precision: 0.8699 - recall: 0.7271 - val_loss: 0.0568 - val_precision: 0.9476 - val_recall: 0.6471\n",
      "Epoch 31/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0609 - precision: 0.8650 - recall: 0.7307\n",
      "Epoch 31: val_loss improved from 0.05682 to 0.05467, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0609 - precision: 0.8648 - recall: 0.7312 - val_loss: 0.0547 - val_precision: 0.9458 - val_recall: 0.6687\n",
      "Epoch 32/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0596 - precision: 0.8667 - recall: 0.7424\n",
      "Epoch 32: val_loss improved from 0.05467 to 0.05333, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0596 - precision: 0.8663 - recall: 0.7425 - val_loss: 0.0533 - val_precision: 0.9428 - val_recall: 0.6826\n",
      "Epoch 33/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0584 - precision: 0.8751 - recall: 0.7347\n",
      "Epoch 33: val_loss improved from 0.05333 to 0.05277, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0584 - precision: 0.8749 - recall: 0.7351 - val_loss: 0.0528 - val_precision: 0.9407 - val_recall: 0.6834\n",
      "Epoch 34/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0582 - precision: 0.8685 - recall: 0.7423\n",
      "Epoch 34: val_loss improved from 0.05277 to 0.05159, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0582 - precision: 0.8684 - recall: 0.7426 - val_loss: 0.0516 - val_precision: 0.9393 - val_recall: 0.6948\n",
      "Epoch 35/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0570 - precision: 0.8755 - recall: 0.7501\n",
      "Epoch 35: val_loss improved from 0.05159 to 0.05079, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0569 - precision: 0.8754 - recall: 0.7504 - val_loss: 0.0508 - val_precision: 0.9355 - val_recall: 0.7020\n",
      "Epoch 36/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0555 - precision: 0.8797 - recall: 0.7544\n",
      "Epoch 36: val_loss improved from 0.05079 to 0.04962, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0555 - precision: 0.8794 - recall: 0.7545 - val_loss: 0.0496 - val_precision: 0.9337 - val_recall: 0.7171\n",
      "Epoch 37/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0560 - precision: 0.8700 - recall: 0.7584\n",
      "Epoch 37: val_loss improved from 0.04962 to 0.04867, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0559 - precision: 0.8701 - recall: 0.7586 - val_loss: 0.0487 - val_precision: 0.9305 - val_recall: 0.7280\n",
      "Epoch 38/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0551 - precision: 0.8745 - recall: 0.7567\n",
      "Epoch 38: val_loss improved from 0.04867 to 0.04814, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0550 - precision: 0.8744 - recall: 0.7570 - val_loss: 0.0481 - val_precision: 0.9277 - val_recall: 0.7336\n",
      "Epoch 39/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0539 - precision: 0.8790 - recall: 0.7594\n",
      "Epoch 39: val_loss improved from 0.04814 to 0.04754, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0539 - precision: 0.8788 - recall: 0.7597 - val_loss: 0.0475 - val_precision: 0.9230 - val_recall: 0.7416\n",
      "Epoch 40/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0531 - precision: 0.8797 - recall: 0.7673\n",
      "Epoch 40: val_loss improved from 0.04754 to 0.04712, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0531 - precision: 0.8793 - recall: 0.7675 - val_loss: 0.0471 - val_precision: 0.9191 - val_recall: 0.7481\n",
      "Epoch 41/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0534 - precision: 0.8748 - recall: 0.7689\n",
      "Epoch 41: val_loss improved from 0.04712 to 0.04688, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0533 - precision: 0.8747 - recall: 0.7692 - val_loss: 0.0469 - val_precision: 0.9175 - val_recall: 0.7539\n",
      "Epoch 42/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0528 - precision: 0.8825 - recall: 0.7606\n",
      "Epoch 42: val_loss improved from 0.04688 to 0.04644, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0528 - precision: 0.8823 - recall: 0.7611 - val_loss: 0.0464 - val_precision: 0.9151 - val_recall: 0.7558\n",
      "Epoch 43/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0517 - precision: 0.8804 - recall: 0.7742\n",
      "Epoch 43: val_loss improved from 0.04644 to 0.04641, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0517 - precision: 0.8803 - recall: 0.7743 - val_loss: 0.0464 - val_precision: 0.9169 - val_recall: 0.7497\n",
      "Epoch 44/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0514 - precision: 0.8784 - recall: 0.7753\n",
      "Epoch 44: val_loss improved from 0.04641 to 0.04591, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0513 - precision: 0.8783 - recall: 0.7757 - val_loss: 0.0459 - val_precision: 0.9122 - val_recall: 0.7628\n",
      "Epoch 45/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0502 - precision: 0.8880 - recall: 0.7769\n",
      "Epoch 45: val_loss did not improve from 0.04591\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0502 - precision: 0.8877 - recall: 0.7772 - val_loss: 0.0460 - val_precision: 0.9125 - val_recall: 0.7610\n",
      "Epoch 46/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0502 - precision: 0.8834 - recall: 0.7813\n",
      "Epoch 46: val_loss improved from 0.04591 to 0.04568, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0502 - precision: 0.8832 - recall: 0.7816 - val_loss: 0.0457 - val_precision: 0.9091 - val_recall: 0.7661\n",
      "Epoch 47/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0496 - precision: 0.8867 - recall: 0.7809\n",
      "Epoch 47: val_loss improved from 0.04568 to 0.04551, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0496 - precision: 0.8864 - recall: 0.7811 - val_loss: 0.0455 - val_precision: 0.9117 - val_recall: 0.7648\n",
      "Epoch 48/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0494 - precision: 0.8857 - recall: 0.7838\n",
      "Epoch 48: val_loss did not improve from 0.04551\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0493 - precision: 0.8858 - recall: 0.7841 - val_loss: 0.0456 - val_precision: 0.9075 - val_recall: 0.7658\n",
      "Epoch 49/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0486 - precision: 0.8859 - recall: 0.7861\n",
      "Epoch 49: val_loss did not improve from 0.04551\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0486 - precision: 0.8854 - recall: 0.7864 - val_loss: 0.0459 - val_precision: 0.9063 - val_recall: 0.7681\n",
      "Epoch 50/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0481 - precision: 0.8923 - recall: 0.7804\n",
      "Epoch 50: val_loss did not improve from 0.04551\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0481 - precision: 0.8921 - recall: 0.7809 - val_loss: 0.0457 - val_precision: 0.9105 - val_recall: 0.7643\n",
      "Epoch 51/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0477 - precision: 0.8879 - recall: 0.7925\n",
      "Epoch 51: val_loss improved from 0.04551 to 0.04518, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0477 - precision: 0.8877 - recall: 0.7925 - val_loss: 0.0452 - val_precision: 0.9043 - val_recall: 0.7739\n",
      "Epoch 52/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0471 - precision: 0.8907 - recall: 0.7908\n",
      "Epoch 52: val_loss did not improve from 0.04518\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0471 - precision: 0.8906 - recall: 0.7912 - val_loss: 0.0454 - val_precision: 0.9020 - val_recall: 0.7706\n",
      "Epoch 53/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0468 - precision: 0.8893 - recall: 0.7952\n",
      "Epoch 53: val_loss improved from 0.04518 to 0.04483, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0467 - precision: 0.8893 - recall: 0.7953 - val_loss: 0.0448 - val_precision: 0.9044 - val_recall: 0.7734\n",
      "Epoch 54/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0462 - precision: 0.8934 - recall: 0.7942\n",
      "Epoch 54: val_loss did not improve from 0.04483\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0462 - precision: 0.8932 - recall: 0.7945 - val_loss: 0.0453 - val_precision: 0.9041 - val_recall: 0.7643\n",
      "Epoch 55/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0457 - precision: 0.8920 - recall: 0.7969\n",
      "Epoch 55: val_loss did not improve from 0.04483\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0457 - precision: 0.8918 - recall: 0.7971 - val_loss: 0.0451 - val_precision: 0.9011 - val_recall: 0.7762\n",
      "Epoch 56/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0455 - precision: 0.8877 - recall: 0.7992\n",
      "Epoch 56: val_loss did not improve from 0.04483\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0454 - precision: 0.8878 - recall: 0.7996 - val_loss: 0.0449 - val_precision: 0.8986 - val_recall: 0.7804\n",
      "Epoch 57/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0450 - precision: 0.8926 - recall: 0.8000\n",
      "Epoch 57: val_loss did not improve from 0.04483\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0449 - precision: 0.8924 - recall: 0.8002 - val_loss: 0.0451 - val_precision: 0.9026 - val_recall: 0.7724\n",
      "Epoch 58/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0443 - precision: 0.8962 - recall: 0.8043\n",
      "Epoch 58: val_loss improved from 0.04483 to 0.04460, saving model to 62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0443 - precision: 0.8959 - recall: 0.8045 - val_loss: 0.0446 - val_precision: 0.8987 - val_recall: 0.7850\n",
      "Epoch 59/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0450 - precision: 0.8900 - recall: 0.7982\n",
      "Epoch 59: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0449 - precision: 0.8900 - recall: 0.7986 - val_loss: 0.0451 - val_precision: 0.8984 - val_recall: 0.7772\n",
      "Epoch 60/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0449 - precision: 0.8907 - recall: 0.8026\n",
      "Epoch 60: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0448 - precision: 0.8907 - recall: 0.8027 - val_loss: 0.0450 - val_precision: 0.9000 - val_recall: 0.7772\n",
      "Epoch 61/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0443 - precision: 0.8925 - recall: 0.8033\n",
      "Epoch 61: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0443 - precision: 0.8925 - recall: 0.8035 - val_loss: 0.0453 - val_precision: 0.8988 - val_recall: 0.7761\n",
      "Epoch 62/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0433 - precision: 0.8968 - recall: 0.8043\n",
      "Epoch 62: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0433 - precision: 0.8966 - recall: 0.8046 - val_loss: 0.0449 - val_precision: 0.9055 - val_recall: 0.7762\n",
      "Epoch 63/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0432 - precision: 0.8966 - recall: 0.8094\n",
      "Epoch 63: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0432 - precision: 0.8966 - recall: 0.8095 - val_loss: 0.0451 - val_precision: 0.8972 - val_recall: 0.7782\n",
      "Epoch 64/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0423 - precision: 0.8958 - recall: 0.8118\n",
      "Epoch 64: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0423 - precision: 0.8957 - recall: 0.8120 - val_loss: 0.0452 - val_precision: 0.8971 - val_recall: 0.7759\n",
      "Epoch 65/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0421 - precision: 0.8968 - recall: 0.8088\n",
      "Epoch 65: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0421 - precision: 0.8967 - recall: 0.8091 - val_loss: 0.0451 - val_precision: 0.8964 - val_recall: 0.7800\n",
      "Epoch 66/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0418 - precision: 0.8988 - recall: 0.8093\n",
      "Epoch 66: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0418 - precision: 0.8986 - recall: 0.8094 - val_loss: 0.0453 - val_precision: 0.8965 - val_recall: 0.7736\n",
      "Epoch 67/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0414 - precision: 0.8984 - recall: 0.8147\n",
      "Epoch 67: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0414 - precision: 0.8982 - recall: 0.8150 - val_loss: 0.0451 - val_precision: 0.8949 - val_recall: 0.7815\n",
      "Epoch 68/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0408 - precision: 0.8999 - recall: 0.8149\n",
      "Epoch 68: val_loss did not improve from 0.04460\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0408 - precision: 0.8998 - recall: 0.8151 - val_loss: 0.0451 - val_precision: 0.8961 - val_recall: 0.7776\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0314 - precision: 0.9128 - recall: 0.8571\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0434 - precision: 0.9042 - recall: 0.7882\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0547 - precision: 0.8850 - recall: 0.7421\n",
      "Epoch 1/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9030 - precision: 0.0621 - recall: 0.6268\n",
      "Epoch 1: val_loss improved from inf to 0.64925, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.9010 - precision: 0.0624 - recall: 0.6304 - val_loss: 0.6493 - val_precision: 0.3115 - val_recall: 0.8165\n",
      "Epoch 2/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.7132 - precision: 0.1003 - recall: 0.8858\n",
      "Epoch 2: val_loss improved from 0.64925 to 0.56834, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.7124 - precision: 0.1004 - recall: 0.8858 - val_loss: 0.5683 - val_precision: 0.8002 - val_recall: 0.6975\n",
      "Epoch 3/500\n",
      "\u001b[1m28/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5885 - precision: 0.1313 - recall: 0.8843\n",
      "Epoch 3: val_loss improved from 0.56834 to 0.41038, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.5857 - precision: 0.1320 - recall: 0.8836 - val_loss: 0.4104 - val_precision: 0.9227 - val_recall: 0.4532\n",
      "Epoch 4/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.4057 - precision: 0.2280 - recall: 0.8389\n",
      "Epoch 4: val_loss improved from 0.41038 to 0.23929, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.4042 - precision: 0.2290 - recall: 0.8381 - val_loss: 0.2393 - val_precision: 0.9469 - val_recall: 0.1774\n",
      "Epoch 5/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2377 - precision: 0.4363 - recall: 0.7386\n",
      "Epoch 5: val_loss improved from 0.23929 to 0.15370, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.2368 - precision: 0.4377 - recall: 0.7377 - val_loss: 0.1537 - val_precision: 0.9702 - val_recall: 0.0486\n",
      "Epoch 6/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1547 - precision: 0.6208 - recall: 0.6569\n",
      "Epoch 6: val_loss improved from 0.15370 to 0.12638, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.1543 - precision: 0.6219 - recall: 0.6565 - val_loss: 0.1264 - val_precision: 0.9630 - val_recall: 0.0388\n",
      "Epoch 7/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1153 - precision: 0.7499 - recall: 0.6226\n",
      "Epoch 7: val_loss improved from 0.12638 to 0.11331, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.1151 - precision: 0.7502 - recall: 0.6223 - val_loss: 0.1133 - val_precision: 0.9565 - val_recall: 0.0438\n",
      "Epoch 8/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0970 - precision: 0.8081 - recall: 0.6184\n",
      "Epoch 8: val_loss improved from 0.11331 to 0.10333, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0969 - precision: 0.8081 - recall: 0.6186 - val_loss: 0.1033 - val_precision: 0.9664 - val_recall: 0.0953\n",
      "Epoch 9/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0869 - precision: 0.8364 - recall: 0.6261\n",
      "Epoch 9: val_loss improved from 0.10333 to 0.09352, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0869 - precision: 0.8362 - recall: 0.6262 - val_loss: 0.0935 - val_precision: 0.9734 - val_recall: 0.1759\n",
      "Epoch 10/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0795 - precision: 0.8500 - recall: 0.6537\n",
      "Epoch 10: val_loss improved from 0.09352 to 0.08477, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0795 - precision: 0.8499 - recall: 0.6538 - val_loss: 0.0848 - val_precision: 0.9666 - val_recall: 0.2879\n",
      "Epoch 11/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0748 - precision: 0.8554 - recall: 0.6663\n",
      "Epoch 11: val_loss improved from 0.08477 to 0.07560, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0748 - precision: 0.8551 - recall: 0.6664 - val_loss: 0.0756 - val_precision: 0.9656 - val_recall: 0.4283\n",
      "Epoch 12/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0706 - precision: 0.8583 - recall: 0.6871\n",
      "Epoch 12: val_loss improved from 0.07560 to 0.07010, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0706 - precision: 0.8583 - recall: 0.6872 - val_loss: 0.0701 - val_precision: 0.9622 - val_recall: 0.4931\n",
      "Epoch 13/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0673 - precision: 0.8624 - recall: 0.6977\n",
      "Epoch 13: val_loss improved from 0.07010 to 0.06354, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0673 - precision: 0.8623 - recall: 0.6979 - val_loss: 0.0635 - val_precision: 0.9555 - val_recall: 0.5737\n",
      "Epoch 14/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0644 - precision: 0.8728 - recall: 0.7073\n",
      "Epoch 14: val_loss improved from 0.06354 to 0.05869, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0644 - precision: 0.8726 - recall: 0.7075 - val_loss: 0.0587 - val_precision: 0.9463 - val_recall: 0.6282\n",
      "Epoch 15/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0627 - precision: 0.8740 - recall: 0.7140\n",
      "Epoch 15: val_loss improved from 0.05869 to 0.05566, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0627 - precision: 0.8738 - recall: 0.7143 - val_loss: 0.0557 - val_precision: 0.9352 - val_recall: 0.6647\n",
      "Epoch 16/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0599 - precision: 0.8747 - recall: 0.7352\n",
      "Epoch 16: val_loss improved from 0.05566 to 0.05290, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0599 - precision: 0.8746 - recall: 0.7351 - val_loss: 0.0529 - val_precision: 0.9329 - val_recall: 0.6894\n",
      "Epoch 17/500\n",
      "\u001b[1m28/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0581 - precision: 0.8773 - recall: 0.7404\n",
      "Epoch 17: val_loss improved from 0.05290 to 0.05104, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0580 - precision: 0.8771 - recall: 0.7407 - val_loss: 0.0510 - val_precision: 0.9239 - val_recall: 0.7126\n",
      "Epoch 18/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0563 - precision: 0.8790 - recall: 0.7497\n",
      "Epoch 18: val_loss improved from 0.05104 to 0.04989, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0563 - precision: 0.8788 - recall: 0.7499 - val_loss: 0.0499 - val_precision: 0.9171 - val_recall: 0.7247\n",
      "Epoch 19/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0553 - precision: 0.8822 - recall: 0.7507\n",
      "Epoch 19: val_loss improved from 0.04989 to 0.04888, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0553 - precision: 0.8821 - recall: 0.7508 - val_loss: 0.0489 - val_precision: 0.9128 - val_recall: 0.7423\n",
      "Epoch 20/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0540 - precision: 0.8821 - recall: 0.7614\n",
      "Epoch 20: val_loss improved from 0.04888 to 0.04865, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0540 - precision: 0.8821 - recall: 0.7615 - val_loss: 0.0486 - val_precision: 0.9074 - val_recall: 0.7441\n",
      "Epoch 21/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0527 - precision: 0.8812 - recall: 0.7651\n",
      "Epoch 21: val_loss improved from 0.04865 to 0.04776, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0527 - precision: 0.8811 - recall: 0.7652 - val_loss: 0.0478 - val_precision: 0.9058 - val_recall: 0.7539\n",
      "Epoch 22/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0517 - precision: 0.8865 - recall: 0.7697\n",
      "Epoch 22: val_loss improved from 0.04776 to 0.04753, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0516 - precision: 0.8864 - recall: 0.7698 - val_loss: 0.0475 - val_precision: 0.9006 - val_recall: 0.7600\n",
      "Epoch 23/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0506 - precision: 0.8853 - recall: 0.7735\n",
      "Epoch 23: val_loss did not improve from 0.04753\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0506 - precision: 0.8853 - recall: 0.7736 - val_loss: 0.0476 - val_precision: 0.8993 - val_recall: 0.7671\n",
      "Epoch 24/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0483 - precision: 0.8906 - recall: 0.7840\n",
      "Epoch 24: val_loss did not improve from 0.04753\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0483 - precision: 0.8905 - recall: 0.7841 - val_loss: 0.0476 - val_precision: 0.8944 - val_recall: 0.7665\n",
      "Epoch 25/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0476 - precision: 0.8972 - recall: 0.7847\n",
      "Epoch 25: val_loss did not improve from 0.04753\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0476 - precision: 0.8970 - recall: 0.7848 - val_loss: 0.0483 - val_precision: 0.8918 - val_recall: 0.7625\n",
      "Epoch 26/500\n",
      "\u001b[1m28/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0467 - precision: 0.8920 - recall: 0.7903\n",
      "Epoch 26: val_loss did not improve from 0.04753\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0466 - precision: 0.8918 - recall: 0.7907 - val_loss: 0.0477 - val_precision: 0.8859 - val_recall: 0.7771\n",
      "Epoch 27/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0451 - precision: 0.8971 - recall: 0.7976\n",
      "Epoch 27: val_loss improved from 0.04753 to 0.04748, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0450 - precision: 0.8970 - recall: 0.7977 - val_loss: 0.0475 - val_precision: 0.8842 - val_recall: 0.7759\n",
      "Epoch 28/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0449 - precision: 0.8960 - recall: 0.7957\n",
      "Epoch 28: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0448 - precision: 0.8959 - recall: 0.7958 - val_loss: 0.0481 - val_precision: 0.8883 - val_recall: 0.7714\n",
      "Epoch 29/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0439 - precision: 0.8987 - recall: 0.8040\n",
      "Epoch 29: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0438 - precision: 0.8986 - recall: 0.8041 - val_loss: 0.0483 - val_precision: 0.8822 - val_recall: 0.7784\n",
      "Epoch 30/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0434 - precision: 0.8943 - recall: 0.8082\n",
      "Epoch 30: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0434 - precision: 0.8943 - recall: 0.8082 - val_loss: 0.0488 - val_precision: 0.8854 - val_recall: 0.7684\n",
      "Epoch 31/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0428 - precision: 0.8958 - recall: 0.8055\n",
      "Epoch 31: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0428 - precision: 0.8958 - recall: 0.8057 - val_loss: 0.0493 - val_precision: 0.8767 - val_recall: 0.7658\n",
      "Epoch 32/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0417 - precision: 0.8982 - recall: 0.8135\n",
      "Epoch 32: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0416 - precision: 0.8982 - recall: 0.8135 - val_loss: 0.0496 - val_precision: 0.8704 - val_recall: 0.7716\n",
      "Epoch 33/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0404 - precision: 0.9006 - recall: 0.8171\n",
      "Epoch 33: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0404 - precision: 0.9006 - recall: 0.8172 - val_loss: 0.0496 - val_precision: 0.8683 - val_recall: 0.7759\n",
      "Epoch 34/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0401 - precision: 0.9012 - recall: 0.8151\n",
      "Epoch 34: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0401 - precision: 0.9011 - recall: 0.8152 - val_loss: 0.0510 - val_precision: 0.8711 - val_recall: 0.7572\n",
      "Epoch 35/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0397 - precision: 0.9025 - recall: 0.8194\n",
      "Epoch 35: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0397 - precision: 0.9025 - recall: 0.8194 - val_loss: 0.0499 - val_precision: 0.8655 - val_recall: 0.7645\n",
      "Epoch 36/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0390 - precision: 0.9023 - recall: 0.8230\n",
      "Epoch 36: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0390 - precision: 0.9022 - recall: 0.8230 - val_loss: 0.0512 - val_precision: 0.8639 - val_recall: 0.7534\n",
      "Epoch 37/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0382 - precision: 0.9031 - recall: 0.8267\n",
      "Epoch 37: val_loss did not improve from 0.04748\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0382 - precision: 0.9030 - recall: 0.8266 - val_loss: 0.0504 - val_precision: 0.8642 - val_recall: 0.7625\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0332 - precision: 0.9070 - recall: 0.8490\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0462 - precision: 0.8895 - recall: 0.7779\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0559 - precision: 0.8818 - recall: 0.7264\n",
      "Epoch 1/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.9266 - precision: 0.0589 - recall: 0.6021\n",
      "Epoch 1: val_loss improved from inf to 0.67055, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.9239 - precision: 0.0594 - recall: 0.6073 - val_loss: 0.6706 - val_precision: 0.1624 - val_recall: 0.8619\n",
      "Epoch 2/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7644 - precision: 0.0935 - recall: 0.8865\n",
      "Epoch 2: val_loss improved from 0.67055 to 0.64405, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.7637 - precision: 0.0935 - recall: 0.8867 - val_loss: 0.6440 - val_precision: 0.3653 - val_recall: 0.8352\n",
      "Epoch 3/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6990 - precision: 0.1043 - recall: 0.9060\n",
      "Epoch 3: val_loss improved from 0.64405 to 0.60378, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.6985 - precision: 0.1043 - recall: 0.9061 - val_loss: 0.6038 - val_precision: 0.6595 - val_recall: 0.7729\n",
      "Epoch 4/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6363 - precision: 0.1186 - recall: 0.9122\n",
      "Epoch 4: val_loss improved from 0.60378 to 0.53909, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.6354 - precision: 0.1188 - recall: 0.9121 - val_loss: 0.5391 - val_precision: 0.8378 - val_recall: 0.6842\n",
      "Epoch 5/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5564 - precision: 0.1455 - recall: 0.8993\n",
      "Epoch 5: val_loss improved from 0.53909 to 0.44657, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.5554 - precision: 0.1458 - recall: 0.8991 - val_loss: 0.4466 - val_precision: 0.8986 - val_recall: 0.5523\n",
      "Epoch 6/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4545 - precision: 0.1999 - recall: 0.8779\n",
      "Epoch 6: val_loss improved from 0.44657 to 0.34014, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.4531 - precision: 0.2007 - recall: 0.8775 - val_loss: 0.3401 - val_precision: 0.9322 - val_recall: 0.3713\n",
      "Epoch 7/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3484 - precision: 0.2913 - recall: 0.8413\n",
      "Epoch 7: val_loss improved from 0.34014 to 0.24765, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.3471 - precision: 0.2925 - recall: 0.8408 - val_loss: 0.2476 - val_precision: 0.9530 - val_recall: 0.2085\n",
      "Epoch 8/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2611 - precision: 0.3972 - recall: 0.7925\n",
      "Epoch 8: val_loss improved from 0.24765 to 0.18707, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2600 - precision: 0.3990 - recall: 0.7918 - val_loss: 0.1871 - val_precision: 0.9611 - val_recall: 0.0941\n",
      "Epoch 9/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1889 - precision: 0.5516 - recall: 0.7428\n",
      "Epoch 9: val_loss improved from 0.18707 to 0.15258, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1882 - precision: 0.5525 - recall: 0.7421 - val_loss: 0.1526 - val_precision: 0.9559 - val_recall: 0.0323\n",
      "Epoch 10/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1519 - precision: 0.6270 - recall: 0.6998\n",
      "Epoch 10: val_loss improved from 0.15258 to 0.13613, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.1514 - precision: 0.6292 - recall: 0.6996 - val_loss: 0.1361 - val_precision: 0.9565 - val_recall: 0.0109\n",
      "Epoch 11/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.1228 - precision: 0.7255 - recall: 0.6712\n",
      "Epoch 11: val_loss improved from 0.13613 to 0.12709, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1225 - precision: 0.7255 - recall: 0.6712 - val_loss: 0.1271 - val_precision: 1.0000 - val_recall: 0.0066\n",
      "Epoch 12/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1075 - precision: 0.7800 - recall: 0.6612\n",
      "Epoch 12: val_loss improved from 0.12709 to 0.12093, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1073 - precision: 0.7803 - recall: 0.6609 - val_loss: 0.1209 - val_precision: 1.0000 - val_recall: 0.0096\n",
      "Epoch 13/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0968 - precision: 0.7977 - recall: 0.6533\n",
      "Epoch 13: val_loss improved from 0.12093 to 0.11615, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0966 - precision: 0.7980 - recall: 0.6535 - val_loss: 0.1161 - val_precision: 0.9600 - val_recall: 0.0159\n",
      "Epoch 14/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0884 - precision: 0.8176 - recall: 0.6668\n",
      "Epoch 14: val_loss improved from 0.11615 to 0.11073, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0883 - precision: 0.8178 - recall: 0.6670 - val_loss: 0.1107 - val_precision: 0.9774 - val_recall: 0.0287\n",
      "Epoch 15/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0810 - precision: 0.8505 - recall: 0.6722\n",
      "Epoch 15: val_loss improved from 0.11073 to 0.10638, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0809 - precision: 0.8503 - recall: 0.6724 - val_loss: 0.1064 - val_precision: 0.9658 - val_recall: 0.0375\n",
      "Epoch 16/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0764 - precision: 0.8607 - recall: 0.6797\n",
      "Epoch 16: val_loss improved from 0.10638 to 0.10168, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0763 - precision: 0.8601 - recall: 0.6800 - val_loss: 0.1017 - val_precision: 0.9742 - val_recall: 0.0753\n",
      "Epoch 17/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0727 - precision: 0.8647 - recall: 0.6988\n",
      "Epoch 17: val_loss improved from 0.10168 to 0.09663, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0726 - precision: 0.8643 - recall: 0.6989 - val_loss: 0.0966 - val_precision: 0.9732 - val_recall: 0.1263\n",
      "Epoch 18/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0698 - precision: 0.8701 - recall: 0.6997\n",
      "Epoch 18: val_loss improved from 0.09663 to 0.09147, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0698 - precision: 0.8699 - recall: 0.7000 - val_loss: 0.0915 - val_precision: 0.9793 - val_recall: 0.1880\n",
      "Epoch 19/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0680 - precision: 0.8666 - recall: 0.7099\n",
      "Epoch 19: val_loss improved from 0.09147 to 0.08717, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0679 - precision: 0.8664 - recall: 0.7102 - val_loss: 0.0872 - val_precision: 0.9792 - val_recall: 0.2345\n",
      "Epoch 20/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0657 - precision: 0.8671 - recall: 0.7151\n",
      "Epoch 20: val_loss improved from 0.08717 to 0.08139, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0657 - precision: 0.8671 - recall: 0.7154 - val_loss: 0.0814 - val_precision: 0.9724 - val_recall: 0.3207\n",
      "Epoch 21/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0641 - precision: 0.8667 - recall: 0.7293\n",
      "Epoch 21: val_loss improved from 0.08139 to 0.07726, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0641 - precision: 0.8666 - recall: 0.7294 - val_loss: 0.0773 - val_precision: 0.9679 - val_recall: 0.3696\n",
      "Epoch 22/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0619 - precision: 0.8765 - recall: 0.7306\n",
      "Epoch 22: val_loss improved from 0.07726 to 0.07296, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0619 - precision: 0.8761 - recall: 0.7309 - val_loss: 0.0730 - val_precision: 0.9664 - val_recall: 0.4288\n",
      "Epoch 23/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0605 - precision: 0.8804 - recall: 0.7302\n",
      "Epoch 23: val_loss improved from 0.07296 to 0.06935, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0604 - precision: 0.8801 - recall: 0.7306 - val_loss: 0.0694 - val_precision: 0.9650 - val_recall: 0.4704\n",
      "Epoch 24/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0596 - precision: 0.8742 - recall: 0.7447\n",
      "Epoch 24: val_loss improved from 0.06935 to 0.06581, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0596 - precision: 0.8743 - recall: 0.7450 - val_loss: 0.0658 - val_precision: 0.9606 - val_recall: 0.5138\n",
      "Epoch 25/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0574 - precision: 0.8847 - recall: 0.7488\n",
      "Epoch 25: val_loss improved from 0.06581 to 0.06271, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0574 - precision: 0.8844 - recall: 0.7489 - val_loss: 0.0627 - val_precision: 0.9560 - val_recall: 0.5508\n",
      "Epoch 26/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0563 - precision: 0.8787 - recall: 0.7564\n",
      "Epoch 26: val_loss improved from 0.06271 to 0.05981, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0563 - precision: 0.8785 - recall: 0.7566 - val_loss: 0.0598 - val_precision: 0.9507 - val_recall: 0.5942\n",
      "Epoch 27/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0550 - precision: 0.8862 - recall: 0.7592\n",
      "Epoch 27: val_loss improved from 0.05981 to 0.05721, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0549 - precision: 0.8859 - recall: 0.7594 - val_loss: 0.0572 - val_precision: 0.9470 - val_recall: 0.6244\n",
      "Epoch 28/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0543 - precision: 0.8846 - recall: 0.7625\n",
      "Epoch 28: val_loss improved from 0.05721 to 0.05588, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0543 - precision: 0.8845 - recall: 0.7628 - val_loss: 0.0559 - val_precision: 0.9449 - val_recall: 0.6423\n",
      "Epoch 29/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0528 - precision: 0.8855 - recall: 0.7683\n",
      "Epoch 29: val_loss improved from 0.05588 to 0.05330, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0528 - precision: 0.8852 - recall: 0.7686 - val_loss: 0.0533 - val_precision: 0.9408 - val_recall: 0.6743\n",
      "Epoch 30/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0520 - precision: 0.8914 - recall: 0.7723\n",
      "Epoch 30: val_loss improved from 0.05330 to 0.05210, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0519 - precision: 0.8912 - recall: 0.7726 - val_loss: 0.0521 - val_precision: 0.9411 - val_recall: 0.6809\n",
      "Epoch 31/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0511 - precision: 0.8916 - recall: 0.7739\n",
      "Epoch 31: val_loss improved from 0.05210 to 0.05032, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0511 - precision: 0.8912 - recall: 0.7742 - val_loss: 0.0503 - val_precision: 0.9338 - val_recall: 0.7066\n",
      "Epoch 32/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0503 - precision: 0.8906 - recall: 0.7777\n",
      "Epoch 32: val_loss improved from 0.05032 to 0.04921, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0502 - precision: 0.8901 - recall: 0.7779 - val_loss: 0.0492 - val_precision: 0.9316 - val_recall: 0.7182\n",
      "Epoch 33/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0495 - precision: 0.8869 - recall: 0.7836\n",
      "Epoch 33: val_loss improved from 0.04921 to 0.04840, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0495 - precision: 0.8868 - recall: 0.7840 - val_loss: 0.0484 - val_precision: 0.9251 - val_recall: 0.7308\n",
      "Epoch 34/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0492 - precision: 0.8901 - recall: 0.7867\n",
      "Epoch 34: val_loss improved from 0.04840 to 0.04761, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0492 - precision: 0.8900 - recall: 0.7870 - val_loss: 0.0476 - val_precision: 0.9225 - val_recall: 0.7316\n",
      "Epoch 35/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0481 - precision: 0.8949 - recall: 0.7837\n",
      "Epoch 35: val_loss improved from 0.04761 to 0.04755, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0481 - precision: 0.8948 - recall: 0.7841 - val_loss: 0.0476 - val_precision: 0.9209 - val_recall: 0.7331\n",
      "Epoch 36/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0476 - precision: 0.8894 - recall: 0.7933\n",
      "Epoch 36: val_loss improved from 0.04755 to 0.04683, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0476 - precision: 0.8894 - recall: 0.7937 - val_loss: 0.0468 - val_precision: 0.9165 - val_recall: 0.7514\n",
      "Epoch 37/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0471 - precision: 0.8898 - recall: 0.7915\n",
      "Epoch 37: val_loss did not improve from 0.04683\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0471 - precision: 0.8897 - recall: 0.7917 - val_loss: 0.0469 - val_precision: 0.9176 - val_recall: 0.7459\n",
      "Epoch 38/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0461 - precision: 0.8978 - recall: 0.7975\n",
      "Epoch 38: val_loss improved from 0.04683 to 0.04643, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0461 - precision: 0.8975 - recall: 0.7976 - val_loss: 0.0464 - val_precision: 0.9106 - val_recall: 0.7547\n",
      "Epoch 39/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0462 - precision: 0.8939 - recall: 0.7983\n",
      "Epoch 39: val_loss improved from 0.04643 to 0.04609, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0462 - precision: 0.8937 - recall: 0.7985 - val_loss: 0.0461 - val_precision: 0.9074 - val_recall: 0.7616\n",
      "Epoch 40/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0448 - precision: 0.8933 - recall: 0.8039\n",
      "Epoch 40: val_loss improved from 0.04609 to 0.04600, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0448 - precision: 0.8931 - recall: 0.8041 - val_loss: 0.0460 - val_precision: 0.9079 - val_recall: 0.7611\n",
      "Epoch 41/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0448 - precision: 0.8956 - recall: 0.7977\n",
      "Epoch 41: val_loss improved from 0.04600 to 0.04591, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0448 - precision: 0.8954 - recall: 0.7981 - val_loss: 0.0459 - val_precision: 0.9035 - val_recall: 0.7665\n",
      "Epoch 42/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0445 - precision: 0.8948 - recall: 0.7999\n",
      "Epoch 42: val_loss did not improve from 0.04591\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0444 - precision: 0.8947 - recall: 0.8002 - val_loss: 0.0460 - val_precision: 0.8997 - val_recall: 0.7686\n",
      "Epoch 43/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0438 - precision: 0.8975 - recall: 0.8059\n",
      "Epoch 43: val_loss improved from 0.04591 to 0.04582, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0437 - precision: 0.8974 - recall: 0.8060 - val_loss: 0.0458 - val_precision: 0.8995 - val_recall: 0.7684\n",
      "Epoch 44/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0428 - precision: 0.8963 - recall: 0.8123\n",
      "Epoch 44: val_loss improved from 0.04582 to 0.04581, saving model to 62sec_1layer_256units_0.5dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0428 - precision: 0.8962 - recall: 0.8123 - val_loss: 0.0458 - val_precision: 0.8946 - val_recall: 0.7736\n",
      "Epoch 45/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0426 - precision: 0.8966 - recall: 0.8122\n",
      "Epoch 45: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0426 - precision: 0.8966 - recall: 0.8123 - val_loss: 0.0463 - val_precision: 0.8866 - val_recall: 0.7727\n",
      "Epoch 46/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0416 - precision: 0.9008 - recall: 0.8157\n",
      "Epoch 46: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0415 - precision: 0.9007 - recall: 0.8159 - val_loss: 0.0463 - val_precision: 0.8874 - val_recall: 0.7736\n",
      "Epoch 47/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0418 - precision: 0.8961 - recall: 0.8110\n",
      "Epoch 47: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0418 - precision: 0.8961 - recall: 0.8113 - val_loss: 0.0464 - val_precision: 0.8845 - val_recall: 0.7732\n",
      "Epoch 48/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0408 - precision: 0.9041 - recall: 0.8185\n",
      "Epoch 48: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0408 - precision: 0.9039 - recall: 0.8187 - val_loss: 0.0464 - val_precision: 0.8775 - val_recall: 0.7766\n",
      "Epoch 49/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0404 - precision: 0.9025 - recall: 0.8158\n",
      "Epoch 49: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0404 - precision: 0.9024 - recall: 0.8160 - val_loss: 0.0470 - val_precision: 0.8811 - val_recall: 0.7729\n",
      "Epoch 50/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0400 - precision: 0.9014 - recall: 0.8159\n",
      "Epoch 50: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0399 - precision: 0.9012 - recall: 0.8161 - val_loss: 0.0471 - val_precision: 0.8780 - val_recall: 0.7781\n",
      "Epoch 51/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0394 - precision: 0.9052 - recall: 0.8221\n",
      "Epoch 51: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0394 - precision: 0.9050 - recall: 0.8222 - val_loss: 0.0476 - val_precision: 0.8721 - val_recall: 0.7834\n",
      "Epoch 52/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0393 - precision: 0.9030 - recall: 0.8240\n",
      "Epoch 52: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0392 - precision: 0.9028 - recall: 0.8242 - val_loss: 0.0474 - val_precision: 0.8777 - val_recall: 0.7757\n",
      "Epoch 53/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0387 - precision: 0.9068 - recall: 0.8227\n",
      "Epoch 53: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0387 - precision: 0.9066 - recall: 0.8228 - val_loss: 0.0480 - val_precision: 0.8728 - val_recall: 0.7721\n",
      "Epoch 54/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0387 - precision: 0.9024 - recall: 0.8262\n",
      "Epoch 54: val_loss did not improve from 0.04581\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0386 - precision: 0.9023 - recall: 0.8265 - val_loss: 0.0480 - val_precision: 0.8725 - val_recall: 0.7746\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0314 - precision: 0.9175 - recall: 0.8471\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0442 - precision: 0.9043 - recall: 0.7785\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0534 - precision: 0.8856 - recall: 0.7363\n",
      "Epoch 1/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.8561 - precision: 0.0666 - recall: 0.6694\n",
      "Epoch 1: val_loss improved from inf to 0.64772, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.8542 - precision: 0.0670 - recall: 0.6726 - val_loss: 0.6477 - val_precision: 0.3275 - val_recall: 0.8233\n",
      "Epoch 2/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.6754 - precision: 0.1057 - recall: 0.9000\n",
      "Epoch 2: val_loss improved from 0.64772 to 0.55786, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.6746 - precision: 0.1058 - recall: 0.9000 - val_loss: 0.5579 - val_precision: 0.8133 - val_recall: 0.6919\n",
      "Epoch 3/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5415 - precision: 0.1506 - recall: 0.8959\n",
      "Epoch 3: val_loss improved from 0.55786 to 0.38340, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.5402 - precision: 0.1511 - recall: 0.8953 - val_loss: 0.3834 - val_precision: 0.9194 - val_recall: 0.4290\n",
      "Epoch 4/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3584 - precision: 0.2920 - recall: 0.8401\n",
      "Epoch 4: val_loss improved from 0.38340 to 0.21714, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.3570 - precision: 0.2934 - recall: 0.8394 - val_loss: 0.2171 - val_precision: 0.9597 - val_recall: 0.1658\n",
      "Epoch 5/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2042 - precision: 0.5481 - recall: 0.7495\n",
      "Epoch 5: val_loss improved from 0.21714 to 0.14559, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.2035 - precision: 0.5496 - recall: 0.7486 - val_loss: 0.1456 - val_precision: 0.9592 - val_recall: 0.0234\n",
      "Epoch 6/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1306 - precision: 0.7427 - recall: 0.6793\n",
      "Epoch 6: val_loss improved from 0.14559 to 0.12314, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.1303 - precision: 0.7429 - recall: 0.6789 - val_loss: 0.1231 - val_precision: 0.9636 - val_recall: 0.0176\n",
      "Epoch 7/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1014 - precision: 0.8140 - recall: 0.6464\n",
      "Epoch 7: val_loss improved from 0.12314 to 0.11118, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.1012 - precision: 0.8144 - recall: 0.6465 - val_loss: 0.1112 - val_precision: 0.9714 - val_recall: 0.0338\n",
      "Epoch 8/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0857 - precision: 0.8515 - recall: 0.6558\n",
      "Epoch 8: val_loss improved from 0.11118 to 0.10169, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0856 - precision: 0.8515 - recall: 0.6560 - val_loss: 0.1017 - val_precision: 0.9757 - val_recall: 0.0799\n",
      "Epoch 9/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0757 - precision: 0.8704 - recall: 0.6733\n",
      "Epoch 9: val_loss improved from 0.10169 to 0.09067, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0757 - precision: 0.8702 - recall: 0.6735 - val_loss: 0.0907 - val_precision: 0.9747 - val_recall: 0.2171\n",
      "Epoch 10/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0698 - precision: 0.8749 - recall: 0.6989\n",
      "Epoch 10: val_loss improved from 0.09067 to 0.08078, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0698 - precision: 0.8748 - recall: 0.6990 - val_loss: 0.0808 - val_precision: 0.9693 - val_recall: 0.3345\n",
      "Epoch 11/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0657 - precision: 0.8760 - recall: 0.7097\n",
      "Epoch 11: val_loss improved from 0.08078 to 0.07260, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0656 - precision: 0.8759 - recall: 0.7098 - val_loss: 0.0726 - val_precision: 0.9658 - val_recall: 0.4540\n",
      "Epoch 12/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0619 - precision: 0.8891 - recall: 0.7199\n",
      "Epoch 12: val_loss improved from 0.07260 to 0.06474, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0618 - precision: 0.8889 - recall: 0.7201 - val_loss: 0.0647 - val_precision: 0.9580 - val_recall: 0.5594\n",
      "Epoch 13/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0587 - precision: 0.8846 - recall: 0.7428\n",
      "Epoch 13: val_loss improved from 0.06474 to 0.05924, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0587 - precision: 0.8844 - recall: 0.7429 - val_loss: 0.0592 - val_precision: 0.9533 - val_recall: 0.6191\n",
      "Epoch 14/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0562 - precision: 0.8886 - recall: 0.7514\n",
      "Epoch 14: val_loss improved from 0.05924 to 0.05480, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0562 - precision: 0.8883 - recall: 0.7515 - val_loss: 0.0548 - val_precision: 0.9441 - val_recall: 0.6718\n",
      "Epoch 15/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0547 - precision: 0.8872 - recall: 0.7566\n",
      "Epoch 15: val_loss improved from 0.05480 to 0.05246, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0546 - precision: 0.8872 - recall: 0.7568 - val_loss: 0.0525 - val_precision: 0.9331 - val_recall: 0.6977\n",
      "Epoch 16/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0525 - precision: 0.8948 - recall: 0.7623\n",
      "Epoch 16: val_loss improved from 0.05246 to 0.04978, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0524 - precision: 0.8947 - recall: 0.7626 - val_loss: 0.0498 - val_precision: 0.9256 - val_recall: 0.7235\n",
      "Epoch 17/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0508 - precision: 0.8928 - recall: 0.7712\n",
      "Epoch 17: val_loss improved from 0.04978 to 0.04855, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0507 - precision: 0.8928 - recall: 0.7714 - val_loss: 0.0486 - val_precision: 0.9208 - val_recall: 0.7360\n",
      "Epoch 18/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0489 - precision: 0.8979 - recall: 0.7864\n",
      "Epoch 18: val_loss improved from 0.04855 to 0.04800, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0489 - precision: 0.8977 - recall: 0.7864 - val_loss: 0.0480 - val_precision: 0.9123 - val_recall: 0.7471\n",
      "Epoch 19/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0479 - precision: 0.8939 - recall: 0.7863\n",
      "Epoch 19: val_loss improved from 0.04800 to 0.04721, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0479 - precision: 0.8938 - recall: 0.7865 - val_loss: 0.0472 - val_precision: 0.9098 - val_recall: 0.7593\n",
      "Epoch 20/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0461 - precision: 0.9014 - recall: 0.7940\n",
      "Epoch 20: val_loss improved from 0.04721 to 0.04670, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0461 - precision: 0.9013 - recall: 0.7941 - val_loss: 0.0467 - val_precision: 0.9080 - val_recall: 0.7693\n",
      "Epoch 21/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0453 - precision: 0.8985 - recall: 0.7967\n",
      "Epoch 21: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0453 - precision: 0.8984 - recall: 0.7969 - val_loss: 0.0469 - val_precision: 0.9026 - val_recall: 0.7679\n",
      "Epoch 22/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0442 - precision: 0.9009 - recall: 0.8002\n",
      "Epoch 22: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0442 - precision: 0.9008 - recall: 0.8004 - val_loss: 0.0472 - val_precision: 0.8970 - val_recall: 0.7709\n",
      "Epoch 23/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0430 - precision: 0.9019 - recall: 0.8063\n",
      "Epoch 23: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0430 - precision: 0.9018 - recall: 0.8063 - val_loss: 0.0473 - val_precision: 0.8947 - val_recall: 0.7814\n",
      "Epoch 24/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0416 - precision: 0.9037 - recall: 0.8128\n",
      "Epoch 24: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0416 - precision: 0.9035 - recall: 0.8129 - val_loss: 0.0471 - val_precision: 0.8930 - val_recall: 0.7759\n",
      "Epoch 25/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0409 - precision: 0.9050 - recall: 0.8161\n",
      "Epoch 25: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0409 - precision: 0.9049 - recall: 0.8162 - val_loss: 0.0471 - val_precision: 0.8912 - val_recall: 0.7739\n",
      "Epoch 26/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0400 - precision: 0.9034 - recall: 0.8193\n",
      "Epoch 26: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0400 - precision: 0.9034 - recall: 0.8194 - val_loss: 0.0474 - val_precision: 0.8885 - val_recall: 0.7767\n",
      "Epoch 27/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0391 - precision: 0.9091 - recall: 0.8215\n",
      "Epoch 27: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0390 - precision: 0.9090 - recall: 0.8217 - val_loss: 0.0481 - val_precision: 0.8849 - val_recall: 0.7762\n",
      "Epoch 28/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0382 - precision: 0.9083 - recall: 0.8278\n",
      "Epoch 28: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0382 - precision: 0.9082 - recall: 0.8279 - val_loss: 0.0477 - val_precision: 0.8887 - val_recall: 0.7693\n",
      "Epoch 29/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0375 - precision: 0.9096 - recall: 0.8256\n",
      "Epoch 29: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0375 - precision: 0.9095 - recall: 0.8257 - val_loss: 0.0491 - val_precision: 0.8950 - val_recall: 0.7611\n",
      "Epoch 30/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0372 - precision: 0.9068 - recall: 0.8289\n",
      "Epoch 30: val_loss did not improve from 0.04670\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0372 - precision: 0.9068 - recall: 0.8290 - val_loss: 0.0485 - val_precision: 0.8877 - val_recall: 0.7681\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0346 - precision: 0.9171 - recall: 0.8319\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0456 - precision: 0.9130 - recall: 0.7724\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0559 - precision: 0.8926 - recall: 0.7230\n",
      "Epoch 1/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8781 - precision: 0.0608 - recall: 0.6177\n",
      "Epoch 1: val_loss improved from inf to 0.67048, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.8725 - precision: 0.0620 - recall: 0.6299 - val_loss: 0.6705 - val_precision: 0.1627 - val_recall: 0.8798\n",
      "Epoch 2/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7256 - precision: 0.0971 - recall: 0.9020\n",
      "Epoch 2: val_loss improved from 0.67048 to 0.64260, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.7249 - precision: 0.0972 - recall: 0.9020 - val_loss: 0.6426 - val_precision: 0.3710 - val_recall: 0.8369\n",
      "Epoch 3/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6627 - precision: 0.1104 - recall: 0.9172\n",
      "Epoch 3: val_loss improved from 0.64260 to 0.59806, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.6615 - precision: 0.1105 - recall: 0.9170 - val_loss: 0.5981 - val_precision: 0.6519 - val_recall: 0.7699\n",
      "Epoch 4/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6012 - precision: 0.1294 - recall: 0.9171\n",
      "Epoch 4: val_loss improved from 0.59806 to 0.52573, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.5992 - precision: 0.1299 - recall: 0.9166 - val_loss: 0.5257 - val_precision: 0.8335 - val_recall: 0.6720\n",
      "Epoch 5/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5146 - precision: 0.1689 - recall: 0.9076\n",
      "Epoch 5: val_loss improved from 0.52573 to 0.42307, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.5134 - precision: 0.1694 - recall: 0.9073 - val_loss: 0.4231 - val_precision: 0.8973 - val_recall: 0.5342\n",
      "Epoch 6/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4122 - precision: 0.2436 - recall: 0.8784\n",
      "Epoch 6: val_loss improved from 0.42307 to 0.31410, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.4093 - precision: 0.2459 - recall: 0.8776 - val_loss: 0.3141 - val_precision: 0.9371 - val_recall: 0.3729\n",
      "Epoch 7/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3036 - precision: 0.3688 - recall: 0.8407\n",
      "Epoch 7: val_loss improved from 0.31410 to 0.22502, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.3009 - precision: 0.3723 - recall: 0.8394 - val_loss: 0.2250 - val_precision: 0.9565 - val_recall: 0.2006\n",
      "Epoch 8/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2186 - precision: 0.5194 - recall: 0.8011\n",
      "Epoch 8: val_loss improved from 0.22502 to 0.17135, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.2176 - precision: 0.5211 - recall: 0.8004 - val_loss: 0.1713 - val_precision: 0.9555 - val_recall: 0.0748\n",
      "Epoch 9/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1634 - precision: 0.6353 - recall: 0.7463\n",
      "Epoch 9: val_loss improved from 0.17135 to 0.14465, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1628 - precision: 0.6369 - recall: 0.7460 - val_loss: 0.1446 - val_precision: 0.9617 - val_recall: 0.0375\n",
      "Epoch 10/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1289 - precision: 0.7234 - recall: 0.7287\n",
      "Epoch 10: val_loss improved from 0.14465 to 0.13023, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.1285 - precision: 0.7239 - recall: 0.7281 - val_loss: 0.1302 - val_precision: 0.9314 - val_recall: 0.0157\n",
      "Epoch 11/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1040 - precision: 0.8183 - recall: 0.6979\n",
      "Epoch 11: val_loss improved from 0.13023 to 0.12271, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1038 - precision: 0.8185 - recall: 0.6979 - val_loss: 0.1227 - val_precision: 0.9474 - val_recall: 0.0179\n",
      "Epoch 12/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0897 - precision: 0.8373 - recall: 0.6942\n",
      "Epoch 12: val_loss improved from 0.12271 to 0.11715, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0896 - precision: 0.8376 - recall: 0.6945 - val_loss: 0.1172 - val_precision: 0.9825 - val_recall: 0.0186\n",
      "Epoch 13/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0817 - precision: 0.8648 - recall: 0.7022\n",
      "Epoch 13: val_loss improved from 0.11715 to 0.11275, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0816 - precision: 0.8646 - recall: 0.7022 - val_loss: 0.1127 - val_precision: 0.9653 - val_recall: 0.0230\n",
      "Epoch 14/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0750 - precision: 0.8726 - recall: 0.7059\n",
      "Epoch 14: val_loss improved from 0.11275 to 0.10771, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0749 - precision: 0.8722 - recall: 0.7062 - val_loss: 0.1077 - val_precision: 0.9716 - val_recall: 0.0454\n",
      "Epoch 15/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0711 - precision: 0.8792 - recall: 0.7145\n",
      "Epoch 15: val_loss improved from 0.10771 to 0.10265, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0710 - precision: 0.8787 - recall: 0.7148 - val_loss: 0.1026 - val_precision: 0.9783 - val_recall: 0.0746\n",
      "Epoch 16/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0669 - precision: 0.8790 - recall: 0.7249\n",
      "Epoch 16: val_loss improved from 0.10265 to 0.09817, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0669 - precision: 0.8788 - recall: 0.7252 - val_loss: 0.0982 - val_precision: 0.9722 - val_recall: 0.1101\n",
      "Epoch 17/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0637 - precision: 0.8868 - recall: 0.7296\n",
      "Epoch 17: val_loss improved from 0.09817 to 0.09176, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0637 - precision: 0.8864 - recall: 0.7300 - val_loss: 0.0918 - val_precision: 0.9763 - val_recall: 0.1842\n",
      "Epoch 18/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0609 - precision: 0.8910 - recall: 0.7360\n",
      "Epoch 18: val_loss improved from 0.09176 to 0.08673, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0608 - precision: 0.8907 - recall: 0.7363 - val_loss: 0.0867 - val_precision: 0.9714 - val_recall: 0.2473\n",
      "Epoch 19/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0586 - precision: 0.8929 - recall: 0.7495\n",
      "Epoch 19: val_loss improved from 0.08673 to 0.08179, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0586 - precision: 0.8924 - recall: 0.7498 - val_loss: 0.0818 - val_precision: 0.9722 - val_recall: 0.3068\n",
      "Epoch 20/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0579 - precision: 0.8853 - recall: 0.7541\n",
      "Epoch 20: val_loss improved from 0.08179 to 0.07663, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0578 - precision: 0.8851 - recall: 0.7544 - val_loss: 0.0766 - val_precision: 0.9670 - val_recall: 0.3889\n",
      "Epoch 21/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0559 - precision: 0.8896 - recall: 0.7602\n",
      "Epoch 21: val_loss improved from 0.07663 to 0.07210, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0558 - precision: 0.8893 - recall: 0.7605 - val_loss: 0.0721 - val_precision: 0.9650 - val_recall: 0.4429\n",
      "Epoch 22/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0541 - precision: 0.8899 - recall: 0.7655\n",
      "Epoch 22: val_loss improved from 0.07210 to 0.06822, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0540 - precision: 0.8899 - recall: 0.7658 - val_loss: 0.0682 - val_precision: 0.9642 - val_recall: 0.4905\n",
      "Epoch 23/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0531 - precision: 0.8885 - recall: 0.7733\n",
      "Epoch 23: val_loss improved from 0.06822 to 0.06401, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0531 - precision: 0.8883 - recall: 0.7736 - val_loss: 0.0640 - val_precision: 0.9604 - val_recall: 0.5422\n",
      "Epoch 24/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0515 - precision: 0.8961 - recall: 0.7730\n",
      "Epoch 24: val_loss improved from 0.06401 to 0.06113, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0514 - precision: 0.8958 - recall: 0.7740 - val_loss: 0.0611 - val_precision: 0.9557 - val_recall: 0.5763\n",
      "Epoch 25/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0507 - precision: 0.8938 - recall: 0.7833\n",
      "Epoch 25: val_loss improved from 0.06113 to 0.05883, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0506 - precision: 0.8935 - recall: 0.7836 - val_loss: 0.0588 - val_precision: 0.9474 - val_recall: 0.6058\n",
      "Epoch 26/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0487 - precision: 0.8951 - recall: 0.7887\n",
      "Epoch 26: val_loss improved from 0.05883 to 0.05563, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0486 - precision: 0.8949 - recall: 0.7890 - val_loss: 0.0556 - val_precision: 0.9411 - val_recall: 0.6468\n",
      "Epoch 27/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0485 - precision: 0.8973 - recall: 0.7876\n",
      "Epoch 27: val_loss improved from 0.05563 to 0.05368, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0484 - precision: 0.8971 - recall: 0.7879 - val_loss: 0.0537 - val_precision: 0.9395 - val_recall: 0.6697\n",
      "Epoch 28/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0470 - precision: 0.8979 - recall: 0.7913\n",
      "Epoch 28: val_loss improved from 0.05368 to 0.05267, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0470 - precision: 0.8977 - recall: 0.7915 - val_loss: 0.0527 - val_precision: 0.9344 - val_recall: 0.6847\n",
      "Epoch 29/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0464 - precision: 0.8968 - recall: 0.7959\n",
      "Epoch 29: val_loss improved from 0.05267 to 0.05098, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0464 - precision: 0.8965 - recall: 0.7962 - val_loss: 0.0510 - val_precision: 0.9331 - val_recall: 0.7023\n",
      "Epoch 30/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0457 - precision: 0.8995 - recall: 0.8006\n",
      "Epoch 30: val_loss improved from 0.05098 to 0.04987, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0457 - precision: 0.8994 - recall: 0.8009 - val_loss: 0.0499 - val_precision: 0.9288 - val_recall: 0.7094\n",
      "Epoch 31/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0450 - precision: 0.8946 - recall: 0.8094\n",
      "Epoch 31: val_loss improved from 0.04987 to 0.04862, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0449 - precision: 0.8946 - recall: 0.8093 - val_loss: 0.0486 - val_precision: 0.9268 - val_recall: 0.7285\n",
      "Epoch 32/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0441 - precision: 0.8983 - recall: 0.8089\n",
      "Epoch 32: val_loss improved from 0.04862 to 0.04813, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0441 - precision: 0.8982 - recall: 0.8091 - val_loss: 0.0481 - val_precision: 0.9221 - val_recall: 0.7318\n",
      "Epoch 33/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0427 - precision: 0.9026 - recall: 0.8066\n",
      "Epoch 33: val_loss improved from 0.04813 to 0.04739, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0427 - precision: 0.9025 - recall: 0.8070 - val_loss: 0.0474 - val_precision: 0.9183 - val_recall: 0.7469\n",
      "Epoch 34/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0418 - precision: 0.9054 - recall: 0.8139\n",
      "Epoch 34: val_loss improved from 0.04739 to 0.04682, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0417 - precision: 0.9052 - recall: 0.8141 - val_loss: 0.0468 - val_precision: 0.9147 - val_recall: 0.7552\n",
      "Epoch 35/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0421 - precision: 0.9042 - recall: 0.8128\n",
      "Epoch 35: val_loss improved from 0.04682 to 0.04648, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0420 - precision: 0.9040 - recall: 0.8131 - val_loss: 0.0465 - val_precision: 0.9133 - val_recall: 0.7542\n",
      "Epoch 36/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0411 - precision: 0.9029 - recall: 0.8162\n",
      "Epoch 36: val_loss did not improve from 0.04648\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0411 - precision: 0.9027 - recall: 0.8164 - val_loss: 0.0465 - val_precision: 0.9084 - val_recall: 0.7606\n",
      "Epoch 37/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0401 - precision: 0.9070 - recall: 0.8213\n",
      "Epoch 37: val_loss did not improve from 0.04648\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0401 - precision: 0.9068 - recall: 0.8215 - val_loss: 0.0465 - val_precision: 0.9056 - val_recall: 0.7585\n",
      "Epoch 38/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0401 - precision: 0.9048 - recall: 0.8214\n",
      "Epoch 38: val_loss did not improve from 0.04648\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0400 - precision: 0.9046 - recall: 0.8215 - val_loss: 0.0470 - val_precision: 0.8995 - val_recall: 0.7643\n",
      "Epoch 39/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0394 - precision: 0.9064 - recall: 0.8243\n",
      "Epoch 39: val_loss did not improve from 0.04648\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0394 - precision: 0.9061 - recall: 0.8245 - val_loss: 0.0467 - val_precision: 0.8972 - val_recall: 0.7678\n",
      "Epoch 40/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0390 - precision: 0.9078 - recall: 0.8239\n",
      "Epoch 40: val_loss improved from 0.04648 to 0.04627, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0390 - precision: 0.9075 - recall: 0.8241 - val_loss: 0.0463 - val_precision: 0.8995 - val_recall: 0.7698\n",
      "Epoch 41/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0383 - precision: 0.9070 - recall: 0.8250\n",
      "Epoch 41: val_loss improved from 0.04627 to 0.04625, saving model to 62sec_1layer_256units_0.4dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0383 - precision: 0.9069 - recall: 0.8252 - val_loss: 0.0463 - val_precision: 0.8967 - val_recall: 0.7668\n",
      "Epoch 42/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0376 - precision: 0.9064 - recall: 0.8310\n",
      "Epoch 42: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0376 - precision: 0.9062 - recall: 0.8311 - val_loss: 0.0467 - val_precision: 0.8939 - val_recall: 0.7713\n",
      "Epoch 43/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0375 - precision: 0.9064 - recall: 0.8325\n",
      "Epoch 43: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0374 - precision: 0.9063 - recall: 0.8327 - val_loss: 0.0464 - val_precision: 0.8877 - val_recall: 0.7794\n",
      "Epoch 44/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0367 - precision: 0.9078 - recall: 0.8375\n",
      "Epoch 44: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0367 - precision: 0.9077 - recall: 0.8376 - val_loss: 0.0465 - val_precision: 0.8870 - val_recall: 0.7764\n",
      "Epoch 45/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0363 - precision: 0.9100 - recall: 0.8364\n",
      "Epoch 45: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0363 - precision: 0.9098 - recall: 0.8365 - val_loss: 0.0473 - val_precision: 0.8824 - val_recall: 0.7751\n",
      "Epoch 46/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0358 - precision: 0.9075 - recall: 0.8387\n",
      "Epoch 46: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0357 - precision: 0.9073 - recall: 0.8389 - val_loss: 0.0472 - val_precision: 0.8877 - val_recall: 0.7689\n",
      "Epoch 47/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0355 - precision: 0.9082 - recall: 0.8368\n",
      "Epoch 47: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0355 - precision: 0.9080 - recall: 0.8370 - val_loss: 0.0467 - val_precision: 0.8859 - val_recall: 0.7719\n",
      "Epoch 48/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0346 - precision: 0.9137 - recall: 0.8387\n",
      "Epoch 48: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0346 - precision: 0.9134 - recall: 0.8390 - val_loss: 0.0473 - val_precision: 0.8847 - val_recall: 0.7669\n",
      "Epoch 49/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0345 - precision: 0.9129 - recall: 0.8409\n",
      "Epoch 49: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0344 - precision: 0.9127 - recall: 0.8410 - val_loss: 0.0475 - val_precision: 0.8758 - val_recall: 0.7724\n",
      "Epoch 50/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0339 - precision: 0.9110 - recall: 0.8485\n",
      "Epoch 50: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0339 - precision: 0.9109 - recall: 0.8486 - val_loss: 0.0472 - val_precision: 0.8850 - val_recall: 0.7625\n",
      "Epoch 51/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0335 - precision: 0.9138 - recall: 0.8467\n",
      "Epoch 51: val_loss did not improve from 0.04625\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0335 - precision: 0.9137 - recall: 0.8468 - val_loss: 0.0472 - val_precision: 0.8821 - val_recall: 0.7711\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0296 - precision: 0.9159 - recall: 0.8595\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0448 - precision: 0.9027 - recall: 0.7713\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0556 - precision: 0.8808 - recall: 0.7224\n",
      "Epoch 1/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.8258 - precision: 0.0672 - recall: 0.6724\n",
      "Epoch 1: val_loss improved from inf to 0.64789, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.8239 - precision: 0.0676 - recall: 0.6759 - val_loss: 0.6479 - val_precision: 0.3410 - val_recall: 0.8304\n",
      "Epoch 2/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.6480 - precision: 0.1108 - recall: 0.9084\n",
      "Epoch 2: val_loss improved from 0.64789 to 0.55237, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.6472 - precision: 0.1110 - recall: 0.9083 - val_loss: 0.5524 - val_precision: 0.8254 - val_recall: 0.6819\n",
      "Epoch 3/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.5153 - precision: 0.1699 - recall: 0.9018\n",
      "Epoch 3: val_loss improved from 0.55237 to 0.36482, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.5138 - precision: 0.1707 - recall: 0.9014 - val_loss: 0.3648 - val_precision: 0.9225 - val_recall: 0.4280\n",
      "Epoch 4/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3250 - precision: 0.3703 - recall: 0.8481\n",
      "Epoch 4: val_loss improved from 0.36482 to 0.20414, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.3237 - precision: 0.3720 - recall: 0.8473 - val_loss: 0.2041 - val_precision: 0.9612 - val_recall: 0.1726\n",
      "Epoch 5/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1781 - precision: 0.6575 - recall: 0.7599\n",
      "Epoch 5: val_loss improved from 0.20414 to 0.14083, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.1775 - precision: 0.6586 - recall: 0.7591 - val_loss: 0.1408 - val_precision: 0.9614 - val_recall: 0.0454\n",
      "Epoch 6/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1160 - precision: 0.8062 - recall: 0.6945\n",
      "Epoch 6: val_loss improved from 0.14083 to 0.11975, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.1157 - precision: 0.8067 - recall: 0.6944 - val_loss: 0.1197 - val_precision: 0.9835 - val_recall: 0.0197\n",
      "Epoch 7/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0883 - precision: 0.8580 - recall: 0.6883\n",
      "Epoch 7: val_loss improved from 0.11975 to 0.10914, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0882 - precision: 0.8580 - recall: 0.6883 - val_loss: 0.1091 - val_precision: 0.9659 - val_recall: 0.0423\n",
      "Epoch 8/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0755 - precision: 0.8802 - recall: 0.6936\n",
      "Epoch 8: val_loss improved from 0.10914 to 0.09837, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0754 - precision: 0.8800 - recall: 0.6938 - val_loss: 0.0984 - val_precision: 0.9717 - val_recall: 0.1195\n",
      "Epoch 9/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0674 - precision: 0.8858 - recall: 0.7120\n",
      "Epoch 9: val_loss improved from 0.09837 to 0.08863, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0673 - precision: 0.8858 - recall: 0.7122 - val_loss: 0.0886 - val_precision: 0.9721 - val_recall: 0.2140\n",
      "Epoch 10/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0624 - precision: 0.8866 - recall: 0.7317\n",
      "Epoch 10: val_loss improved from 0.08863 to 0.07877, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0624 - precision: 0.8866 - recall: 0.7319 - val_loss: 0.0788 - val_precision: 0.9712 - val_recall: 0.3516\n",
      "Epoch 11/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0584 - precision: 0.8955 - recall: 0.7466\n",
      "Epoch 11: val_loss improved from 0.07877 to 0.06976, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0584 - precision: 0.8953 - recall: 0.7467 - val_loss: 0.0698 - val_precision: 0.9631 - val_recall: 0.4802\n",
      "Epoch 12/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0552 - precision: 0.8931 - recall: 0.7598\n",
      "Epoch 12: val_loss improved from 0.06976 to 0.06271, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0552 - precision: 0.8930 - recall: 0.7600 - val_loss: 0.0627 - val_precision: 0.9568 - val_recall: 0.5690\n",
      "Epoch 13/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0526 - precision: 0.8967 - recall: 0.7681\n",
      "Epoch 13: val_loss improved from 0.06271 to 0.05685, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0526 - precision: 0.8966 - recall: 0.7682 - val_loss: 0.0569 - val_precision: 0.9474 - val_recall: 0.6383\n",
      "Epoch 14/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0500 - precision: 0.8992 - recall: 0.7825\n",
      "Epoch 14: val_loss improved from 0.05685 to 0.05284, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0500 - precision: 0.8991 - recall: 0.7825 - val_loss: 0.0528 - val_precision: 0.9387 - val_recall: 0.6776\n",
      "Epoch 15/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0482 - precision: 0.9021 - recall: 0.7851\n",
      "Epoch 15: val_loss improved from 0.05284 to 0.05016, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0481 - precision: 0.9020 - recall: 0.7853 - val_loss: 0.0502 - val_precision: 0.9282 - val_recall: 0.7137\n",
      "Epoch 16/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0462 - precision: 0.9026 - recall: 0.7956\n",
      "Epoch 16: val_loss improved from 0.05016 to 0.04850, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0462 - precision: 0.9025 - recall: 0.7958 - val_loss: 0.0485 - val_precision: 0.9221 - val_recall: 0.7320\n",
      "Epoch 17/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0443 - precision: 0.9027 - recall: 0.8028\n",
      "Epoch 17: val_loss improved from 0.04850 to 0.04741, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0443 - precision: 0.9026 - recall: 0.8028 - val_loss: 0.0474 - val_precision: 0.9088 - val_recall: 0.7534\n",
      "Epoch 18/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0433 - precision: 0.9038 - recall: 0.8051\n",
      "Epoch 18: val_loss improved from 0.04741 to 0.04700, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0433 - precision: 0.9038 - recall: 0.8053 - val_loss: 0.0470 - val_precision: 0.9064 - val_recall: 0.7562\n",
      "Epoch 19/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0418 - precision: 0.9032 - recall: 0.8119\n",
      "Epoch 19: val_loss improved from 0.04700 to 0.04633, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch16.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0418 - precision: 0.9032 - recall: 0.8121 - val_loss: 0.0463 - val_precision: 0.9010 - val_recall: 0.7691\n",
      "Epoch 20/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0404 - precision: 0.9103 - recall: 0.8182\n",
      "Epoch 20: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0404 - precision: 0.9102 - recall: 0.8183 - val_loss: 0.0468 - val_precision: 0.8901 - val_recall: 0.7723\n",
      "Epoch 21/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0390 - precision: 0.9098 - recall: 0.8258\n",
      "Epoch 21: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0390 - precision: 0.9098 - recall: 0.8259 - val_loss: 0.0468 - val_precision: 0.8921 - val_recall: 0.7781\n",
      "Epoch 22/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0379 - precision: 0.9098 - recall: 0.8315\n",
      "Epoch 22: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0379 - precision: 0.9098 - recall: 0.8316 - val_loss: 0.0467 - val_precision: 0.8912 - val_recall: 0.7779\n",
      "Epoch 23/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0369 - precision: 0.9157 - recall: 0.8284\n",
      "Epoch 23: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0368 - precision: 0.9156 - recall: 0.8285 - val_loss: 0.0474 - val_precision: 0.8854 - val_recall: 0.7706\n",
      "Epoch 24/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0361 - precision: 0.9130 - recall: 0.8375\n",
      "Epoch 24: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0361 - precision: 0.9130 - recall: 0.8376 - val_loss: 0.0477 - val_precision: 0.8805 - val_recall: 0.7706\n",
      "Epoch 25/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0351 - precision: 0.9161 - recall: 0.8376\n",
      "Epoch 25: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0351 - precision: 0.9160 - recall: 0.8377 - val_loss: 0.0486 - val_precision: 0.8843 - val_recall: 0.7623\n",
      "Epoch 26/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0342 - precision: 0.9176 - recall: 0.8417\n",
      "Epoch 26: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0342 - precision: 0.9175 - recall: 0.8418 - val_loss: 0.0490 - val_precision: 0.8858 - val_recall: 0.7660\n",
      "Epoch 27/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0331 - precision: 0.9208 - recall: 0.8441\n",
      "Epoch 27: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0331 - precision: 0.9208 - recall: 0.8442 - val_loss: 0.0505 - val_precision: 0.8769 - val_recall: 0.7499\n",
      "Epoch 28/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0322 - precision: 0.9184 - recall: 0.8534\n",
      "Epoch 28: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0322 - precision: 0.9183 - recall: 0.8535 - val_loss: 0.0503 - val_precision: 0.8769 - val_recall: 0.7439\n",
      "Epoch 29/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0320 - precision: 0.9207 - recall: 0.8497\n",
      "Epoch 29: val_loss did not improve from 0.04633\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0320 - precision: 0.9207 - recall: 0.8498 - val_loss: 0.0506 - val_precision: 0.8772 - val_recall: 0.7529\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0332 - precision: 0.9104 - recall: 0.8487\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0450 - precision: 0.9049 - recall: 0.7762\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0562 - precision: 0.8813 - recall: 0.7175\n",
      "Epoch 1/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8439 - precision: 0.0632 - recall: 0.6419\n",
      "Epoch 1: val_loss improved from inf to 0.66943, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.8412 - precision: 0.0638 - recall: 0.6480 - val_loss: 0.6694 - val_precision: 0.1702 - val_recall: 0.8510\n",
      "Epoch 2/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6957 - precision: 0.1004 - recall: 0.9140\n",
      "Epoch 2: val_loss improved from 0.66943 to 0.64200, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.6943 - precision: 0.1005 - recall: 0.9140 - val_loss: 0.6420 - val_precision: 0.4268 - val_recall: 0.8205\n",
      "Epoch 3/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6359 - precision: 0.1161 - recall: 0.9274\n",
      "Epoch 3: val_loss improved from 0.64200 to 0.59313, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.6352 - precision: 0.1163 - recall: 0.9272 - val_loss: 0.5931 - val_precision: 0.7194 - val_recall: 0.7484\n",
      "Epoch 4/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5695 - precision: 0.1432 - recall: 0.9227\n",
      "Epoch 4: val_loss improved from 0.59313 to 0.51084, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.5686 - precision: 0.1435 - recall: 0.9224 - val_loss: 0.5108 - val_precision: 0.8589 - val_recall: 0.6357\n",
      "Epoch 5/500\n",
      "\u001b[1m14/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4792 - precision: 0.2003 - recall: 0.9062\n",
      "Epoch 5: val_loss improved from 0.51084 to 0.40094, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.4766 - precision: 0.2021 - recall: 0.9056 - val_loss: 0.4009 - val_precision: 0.9181 - val_recall: 0.4739\n",
      "Epoch 6/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3675 - precision: 0.3198 - recall: 0.8756\n",
      "Epoch 6: val_loss improved from 0.40094 to 0.29098, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.3662 - precision: 0.3213 - recall: 0.8752 - val_loss: 0.2910 - val_precision: 0.9413 - val_recall: 0.2977\n",
      "Epoch 7/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2640 - precision: 0.4857 - recall: 0.8409\n",
      "Epoch 7: val_loss improved from 0.29098 to 0.20777, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.2628 - precision: 0.4878 - recall: 0.8404 - val_loss: 0.2078 - val_precision: 0.9502 - val_recall: 0.1614\n",
      "Epoch 8/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.1872 - precision: 0.6340 - recall: 0.7946\n",
      "Epoch 8: val_loss improved from 0.20777 to 0.16288, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1865 - precision: 0.6355 - recall: 0.7942 - val_loss: 0.1629 - val_precision: 0.9363 - val_recall: 0.0706\n",
      "Epoch 9/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1391 - precision: 0.7458 - recall: 0.7551\n",
      "Epoch 9: val_loss improved from 0.16288 to 0.13943, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1386 - precision: 0.7466 - recall: 0.7550 - val_loss: 0.1394 - val_precision: 0.9474 - val_recall: 0.0298\n",
      "Epoch 10/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1101 - precision: 0.8069 - recall: 0.7341\n",
      "Epoch 10: val_loss improved from 0.13943 to 0.12820, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.1098 - precision: 0.8071 - recall: 0.7340 - val_loss: 0.1282 - val_precision: 0.9600 - val_recall: 0.0239\n",
      "Epoch 11/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0931 - precision: 0.8501 - recall: 0.7234\n",
      "Epoch 11: val_loss improved from 0.12820 to 0.12162, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0929 - precision: 0.8501 - recall: 0.7234 - val_loss: 0.1216 - val_precision: 0.9593 - val_recall: 0.0196\n",
      "Epoch 12/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0820 - precision: 0.8715 - recall: 0.7211\n",
      "Epoch 12: val_loss improved from 0.12162 to 0.11649, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0818 - precision: 0.8716 - recall: 0.7214 - val_loss: 0.1165 - val_precision: 0.9821 - val_recall: 0.0182\n",
      "Epoch 13/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0734 - precision: 0.8866 - recall: 0.7276\n",
      "Epoch 13: val_loss improved from 0.11649 to 0.11186, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0733 - precision: 0.8862 - recall: 0.7278 - val_loss: 0.1119 - val_precision: 0.9586 - val_recall: 0.0230\n",
      "Epoch 14/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0665 - precision: 0.8933 - recall: 0.7352\n",
      "Epoch 14: val_loss improved from 0.11186 to 0.10666, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0664 - precision: 0.8931 - recall: 0.7356 - val_loss: 0.1067 - val_precision: 0.9620 - val_recall: 0.0419\n",
      "Epoch 15/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0628 - precision: 0.8995 - recall: 0.7463\n",
      "Epoch 15: val_loss improved from 0.10666 to 0.10151, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0627 - precision: 0.8992 - recall: 0.7466 - val_loss: 0.1015 - val_precision: 0.9717 - val_recall: 0.0627\n",
      "Epoch 16/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0597 - precision: 0.8982 - recall: 0.7559\n",
      "Epoch 16: val_loss improved from 0.10151 to 0.09582, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0596 - precision: 0.8979 - recall: 0.7562 - val_loss: 0.0958 - val_precision: 0.9729 - val_recall: 0.1248\n",
      "Epoch 17/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0573 - precision: 0.9003 - recall: 0.7635\n",
      "Epoch 17: val_loss improved from 0.09582 to 0.09096, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0572 - precision: 0.9001 - recall: 0.7638 - val_loss: 0.0910 - val_precision: 0.9783 - val_recall: 0.1719\n",
      "Epoch 18/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0546 - precision: 0.8985 - recall: 0.7717\n",
      "Epoch 18: val_loss improved from 0.09096 to 0.08556, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0546 - precision: 0.8982 - recall: 0.7718 - val_loss: 0.0856 - val_precision: 0.9755 - val_recall: 0.2445\n",
      "Epoch 19/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0524 - precision: 0.9026 - recall: 0.7763\n",
      "Epoch 19: val_loss improved from 0.08556 to 0.07983, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0524 - precision: 0.9024 - recall: 0.7767 - val_loss: 0.0798 - val_precision: 0.9759 - val_recall: 0.3221\n",
      "Epoch 20/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0508 - precision: 0.9012 - recall: 0.7817\n",
      "Epoch 20: val_loss improved from 0.07983 to 0.07484, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0507 - precision: 0.9010 - recall: 0.7821 - val_loss: 0.0748 - val_precision: 0.9697 - val_recall: 0.3922\n",
      "Epoch 21/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0494 - precision: 0.9021 - recall: 0.7888\n",
      "Epoch 21: val_loss improved from 0.07484 to 0.07025, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0493 - precision: 0.9019 - recall: 0.7891 - val_loss: 0.0702 - val_precision: 0.9667 - val_recall: 0.4565\n",
      "Epoch 22/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0479 - precision: 0.9041 - recall: 0.7927\n",
      "Epoch 22: val_loss improved from 0.07025 to 0.06588, saving model to 62sec_1layer_256units_0.3dropout_Adam_lr0.001_batch32.keras\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0479 - precision: 0.9040 - recall: 0.7930 - val_loss: 0.0659 - val_precision: 0.9612 - val_recall: 0.5137\n",
      "Epoch 23/500\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0467 - precision: 0.9050 - recall: 0.7933"
     ]
    }
   ],
   "source": [
    "units_list = [256]\n",
    "dropout_rates = [0.6]\n",
    "optimizers = {'Adam': Adam}\n",
    "learning_rates = [0.001]\n",
    "sequence_lengths = [62]\n",
    "batch_sizes = [16]  # Added batch sizes to test\n",
    "\n",
    "# Initialize a list to store the results incrementally\n",
    "results_path = 'lstm_hyperparameter_tuning_results.csv'\n",
    "with open(results_path, 'w') as f:\n",
    "    f.write('Model,Input Sequence,Units,Dropout,Learning Rate,Batch Size,Epochs,Train_Loss,Train_Precision,Train_Recall,Val_Loss,Val_Precision,Val_Recall,Test_Precision,Test_Recall\\n')\n",
    "\n",
    "for seq_len in sequence_lengths:\n",
    "    # Prepare data for LSTM\n",
    "    train_data = (\n",
    "        all_data[seq_len]['encoder_input_data_train'],\n",
    "        all_data[seq_len]['decoder_input_data_train'],\n",
    "        all_data[seq_len]['decoder_target_data_train']\n",
    "    )\n",
    "    val_data = (\n",
    "        all_data[seq_len]['encoder_input_data_val'],\n",
    "        all_data[seq_len]['decoder_input_data_val'],\n",
    "        all_data[seq_len]['decoder_target_data_val']\n",
    "    )\n",
    "    test_data = (\n",
    "        all_data[seq_len]['encoder_input_data_test'],\n",
    "        all_data[seq_len]['decoder_input_data_test'],\n",
    "        all_data[seq_len]['decoder_target_data_test']\n",
    "    )\n",
    "    \n",
    "    input_features = train_data[0].shape[2]\n",
    "    output_features = train_data[2].shape[2]\n",
    "    \n",
    "    for units in units_list:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for optimizer_name in optimizers.keys():\n",
    "                for learning_rate in learning_rates:\n",
    "                    for batch_size in batch_sizes:  # Added batch size loop\n",
    "                        model_name = f'{seq_len}sec_1layer_{units}units_{dropout_rate}dropout_{optimizer_name}_lr{learning_rate}_batch{batch_size}'\n",
    "                        \n",
    "                        lstm_model = build_simple_lstm_model(input_features, output_features, latent_dim=units, dropout_rate=dropout_rate, optimizer_name=optimizer_name, learning_rate=learning_rate)\n",
    "                        \n",
    "                        lstm_history, epochs_taken = train_lstm_model(lstm_model, train_data, val_data, model_name, epochs=500, batch_size=batch_size)\n",
    "                        \n",
    "                        train_results = evaluate_lstm_model(lstm_model, train_data)\n",
    "                        val_results = evaluate_lstm_model(lstm_model, val_data)\n",
    "                        test_results = evaluate_lstm_model(lstm_model, test_data)\n",
    "                        \n",
    "                        # Append the results incrementally to the CSV file\n",
    "                        with open(results_path, 'a') as f:\n",
    "                            f.write(f'{model_name},{seq_len // 10},{units},{dropout_rate},{learning_rate},{batch_size},{epochs_taken},{train_results[0]},{train_results[1]},{train_results[2]},{val_results[0]},{val_results[1]},{val_results[2]},{test_results[1]},{test_results[2]}\\n')\n",
    "                        \n",
    "                        # Clear session to free up memory\n",
    "                        K.clear_session()\n",
    "\n",
    "# Print the results\n",
    "results_df = pd.read_csv(results_path)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03c17a-262e-4bc1-985a-3f23592451ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed522131-bdb5-4187-9b7c-7958fd9a8c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lstm_hyperparameter_tuning_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Analyze Results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_hyperparameter_tuning_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lstm_hyperparameter_tuning_results.csv'"
     ]
    }
   ],
   "source": [
    "# Analyze Results\n",
    "file_path = 'lstm_hyperparameter_tuning_results.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e082c2fd-bb28-4730-be58-c1d9abc16748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values for each hyperparameter\n",
    "units_list = df['Units'].unique()\n",
    "learning_rates = df['Learning Rate'].unique()\n",
    "dropout_rates = df['Dropout'].unique()\n",
    "batch_sizes = df['Batch Size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a536fb11-7d57-4651-95fa-41d499f09ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Create a DataFrame with all possible combinations of hyperparameters\n",
    "all_combinations = list(itertools.product(units_list, learning_rates, dropout_rates, batch_sizes))\n",
    "columns = ['Units', 'Learning Rate', 'Dropout', 'Batch Size']\n",
    "combinations_df = pd.DataFrame(all_combinations, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f60b7f5b-450f-4ccf-accf-71cc7c879219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the original DataFrame to ensure all combinations are represented\n",
    "merged_df = pd.merge(combinations_df, df, on=columns, how='left')\n",
    "merged_df.fillna(0, inplace=True)  # Fill missing values with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7d0ec5a-a5e3-40a5-8216-ad6bb4b514cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "<class 'float'>    144\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['F1 Score'].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88f9cdef-4f87-434d-a6c1-669274adb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Test_F1' column to numeric, coercing errors to NaN\n",
    "merged_df['F1 Score'] = pd.to_numeric(merged_df['F1 Score'], errors='coerce')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_df['F1 Score'] = merged_df['F1 Score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "865b68e9-36e4-4f56-837e-ce5b47ca6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Units'] = pd.to_numeric(merged_df['Units'])\n",
    "merged_df['Dropout'] = pd.to_numeric(merged_df['Dropout'])\n",
    "merged_df['F1 Score'] = pd.to_numeric(merged_df['F1 Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca0cab07-640e-468a-adef-a4b4d771e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/seaborn/axisgrid.py:123: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the color scale limits\n",
    "vmin, vmax = 0, 1\n",
    "\n",
    "# Create a FacetGrid to visualize the impact of multiple hyperparameters\n",
    "g = sns.FacetGrid(merged_df, col='Batch Size', row='Learning Rate', margin_titles=True, despine=False)\n",
    "\n",
    "# Define the heatmap function\n",
    "def heatmap(data, **kws):\n",
    "    data = data.pivot_table(values='F1 Score', index='Units', columns='Dropout')\n",
    "    sns.heatmap(data, **kws)\n",
    "\n",
    "# Map the heatmap function to the grid\n",
    "g.map_dataframe(heatmap, cmap='viridis', cbar_ax=g.fig.add_axes([.92, .3, .03, .4]), annot=True, fmt=\".4f\", linewidths=.5, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Adjust the axis labels\n",
    "g.set_axis_labels(\"Dropout Rate\", \"Units\")\n",
    "g.set_titles(col_template=\"Batch Size: {col_name}\", row_template=\"Learning Rate: {row_name}\")\n",
    "g.fig.subplots_adjust(top=0.9, right=0.85)\n",
    "g.fig.suptitle('Heatmap of F1 Score for Different Hyperparameters', fontsize=16)\n",
    "plt.savefig('LSTM Hyperparameters Heatmap.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f01bd3-618a-4588-beeb-3961f55e4234",
   "metadata": {},
   "source": [
    "## Validation Threshold Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70d875-05b5-42bb-866f-66fae9f4c896",
   "metadata": {},
   "source": [
    "Given the models and hyperparameter tuning done, I would like to now focus on examining the precision and recall at the different threshold values. This will be evaluated on the validation data specifically, since it is technically a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e482bc11-b228-4c36-9f93-e8da2ccad33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05a96918-fbfb-4724-abd3-aef8028ef211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
     ]
    }
   ],
   "source": [
    "val_data = (\n",
    "    all_data[62]['encoder_input_data_val'],\n",
    "    all_data[62]['decoder_input_data_val'],\n",
    "    all_data[62]['decoder_target_data_val']\n",
    ")\n",
    "encoder_input_data_val, decoder_input_data_val, decoder_target_data_val = val_data\n",
    "\n",
    "predictions = model.predict([encoder_input_data_val, decoder_input_data_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f7c5eeb-f901-48df-bdbf-f0067af8957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIoCAYAAABnOF0AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACrxklEQVR4nOzdd3hTZfsH8O9J0k0HdEJbKC3QAkKhtCAyRETBgYD6ylA2qAiKIiIogvhTcSJuFFnqC6KIE15UUJbM0gKyS0sppbvQFkpXkvP745i0aZKOdGSc7+e6cpE+OTl9ntx3w52T5zxHEEVRBBERERGRTCis3QEiIiIioubEApiIiIiIZIUFMBERERHJCgtgIiIiIpIVFsBEREREJCssgImIiIhIVlgAExEREZGssAAmIiIiIllhAUxEREREssICmMiGrF27FoIgYO3atRY9f9CgQRAEoXE7RVZlLifCwsIQFhZmlT7Zo6ysLEycOBGhoaFQKpUQBAEFBQXW7hY1UGP8Hbz88ssQBAE7d+5slD6RfWABTLKQmpoKQRAMbs7OzggNDcW4ceNw/Phxa3eRmtCkSZOM4u/p6YlevXrhrbfeQllZmbW72GyOHDmCqVOnomPHjvDw8ICbmxsiIiIwfvx4/PHHH9buXpOZNGkSvvrqKwwcOBALFy7E4sWL4erq2qx9qJ6DgiDAzc0NkZGRePbZZ5Gbm9tsfdH9TaSmplr0PEEQ8NFHH5ndbvTo0frtLP1AT9SUVNbuAFFzioiIwCOPPAIAuH79Og4cOIANGzZg8+bN2LFjB/r162fV/o0aNQo333wzWrdubdHzv/zyS9y4caORe+U4pk6dipCQEIiiiIyMDPzwww94/vnn8eeff2Lbtm3W7l6T0mq1mDt3Lt577z2oVCoMHjwY9913H5ycnJCSkoItW7bg66+/xiuvvIKXXnrJ2t1tVOXl5fjjjz8wZMgQ/Pe//7VqX3x9fTFr1iz9z/n5+di5cyeWLVuGn376CQkJCfDy8rJiD+tGpVJh9erVBmPRuXLlCn766SeoVCqo1Wor9I6odiyASVY6dOiAl19+2aBt4cKFeO211/Diiy9a/Sswb29veHt7W/z8tm3bNmJvHM+0adNw8803639+44030L17d/z222/466+/cNttt1mxd01r4cKFeO+999CjRw9s2rQJERERBo+XlJTgo48+Qn5+vpV62HSysrKg1WrRpk0ba3cFfn5+Ru9Boihi+PDh2LJlCzZt2oQpU6ZYp3P1cNddd+GXX37BsWPHEB0dbfDY119/jbKyMtx33334+eefrdRDoppxCgTJ3pNPPgkAOHz4sL5NEAQMGjQIly9fxoQJExAUFASFQmFQIO/evRvDhw+Hn58fXFxc0LFjRyxcuNDsEdjdu3dj5MiRCAwMhIuLC0JDQ3H//fdj7969+m3MzfdMSEjAgw8+iLZt28LFxQX+/v6Ii4vDa6+9ZrCduTnAarUay5YtQ3R0NNzc3ODt7Y3bbrsNv/zyi9G2Vfvw+++/45ZbboG7uzt8fX0xceLEOhdIHTp0gKenp9nX47777oMgCDh37hwA6QjlF198gd69e6NVq1Zwc3NDSEgIhg8f3mQfTHx9fTFy5EgA0tSA6o4fP44xY8agdevWcHZ2Rrt27fDkk0+afQ2OHTuGhx9+GCEhIXBxcUHr1q0xbNgwg9e5sLAQb775Jm699Va0adMGzs7OaNOmDSZMmIDk5OQmGef58+fx1ltvwdfXF9u2bTMqfgHAzc0Nzz33HJYsWaJvq2lOuamv0Kvmzi+//IJ+/frB09MTYWFh2LNnDwRBMFvc5eTkwMnJyehbmGvXrmHx4sXo2rUr3Nzc4OPjg6FDhxr83dRk0KBBaNeuHQBg3bp1+q/lJ02apN+muLgYixcvRlRUFFxdXdGqVSvcc889+Pvvv432V3W+6Nq1axETEwN3d3cMGjSoTv0xRRAEDB06FACQl5dn9Hh9XoPMzEzMnj0bHTt21G/buXNnPP744ygsLAQgzZtdt24dAKB9+/b616Q+Y5g4cSKUSiVWrVpl9NiaNWvQuXNn9O3b1+zz//77b9xzzz1o1aoVXF1dERUVhcWLF5t9v/jpp58QFxcHNzc3BAYGYvr06bh69arZ/ZeXl2PZsmWIiYmBh4cHPD09MWDAABbkpMcjwET/qv4ffX5+Pvr27YtWrVphzJgxKC0t1X81+emnn2LmzJnw8fHB8OHDERAQgPj4eLz22mv466+/8Ndff8HZ2Vm/r/fffx/PPPMM3NzcMGrUKLRt2xaXL1/G3r17sWnTJvTv399sv44ePYpbbrkFSqUSI0aMQLt27VBQUIBTp07h888/x4svvljjuERRxIMPPoiffvoJnTp1wsyZM1FcXIyNGzfivvvuw7Jly/DMM88YPe/nn3/Gli1bMHz4cNxyyy3YvXs3vvzySyQnJ9ep+HjkkUewZMkS/Pjjjxg3bpzBY3l5edi2bRv69OmDTp06AQAWLFiAt956CxERERg3bhw8PT31r9H27dsbVGDUhUpl+Hb4888/46GHHoJCocCIESMQGhqKU6dO4aOPPsJvv/2GgwcPomXLlvrtv//+e4wbN05/NC8yMhI5OTk4ePAgVq1aheHDhwMATp8+jUWLFuG2227DqFGj4OHhgTNnzmD9+vXYsmULEhIS9AVbY1m7di00Gg0ee+wxBAYG1riti4tLg3/fd999h99//x333nsvnnjiCRQVFaF///4ICwvD999/j08++cRo/u2GDRugVqsxfvx4fduVK1cwcOBAnDx5Ev369cPjjz+OoqIi/PTTT7jtttvw3Xff6T/AmDNp0iT06NED77//PqKjo/Xb9+jRAwBQWlqKwYMH49ChQ4iJicHTTz+N7OxsbNy4Eb/99hs2bNiA//znP0b7ffvtt/HXX39hxIgRuPPOO6FUKhv0munmX8fExBi01+c1uHHjBvr164fU1FTceeedGDVqFMrLy3HhwgV89dVXmDt3Lry9vfH0009j7dq1OHbsGGbPng0fHx8AqNfJZMHBwbjzzjuxfv16vPPOO/r3u4SEBBw9ehRvvfUWNBqNyed+9913GDt2LFxcXDB69GgEBATg999/xyuvvILffvsNO3fuNMiPL7/8EhMnToSXlxfGjx8PHx8f/PrrrxgyZAjKy8sN3msBoKysDMOGDcPOnTvRo0cPTJ06FRUVFdiyZQtGjBiBDz/80OTUDZIZkUgGLly4IAIQhw4davTYokWLRADibbfdpm8DIAIQJ0+eLKrVaoPtT548KapUKjE6OlrMy8szeGzp0qUiAPGdd97Rtx09elRUKBRimzZtxAsXLhhsr9VqxcuXL+t/XrNmjQhAXLNmjb5tzpw5IgDxxx9/NOp79d9/6623itX/rNetWycCEG+99VaxrKxM337x4kXRz89PVKlUYnJyslEfVCqVuHfvXn27Wq0WBw0aJAIQ9+/fb9SX6pKSkkQA4l133WX02IcffigCED/66CN9W6tWrcQ2bdqIxcXFRtvn5+fX+vtqMnHiRJP9zsvLE9u0aSMCEA8dOmTQ7uXlJQYHB4upqakGz9mwYYMIQJw1a5a+LSsrS/Tw8BA9PDzEhIQEo99/6dIl/f2CggKT4/nzzz9FhUIhTps2zaDdVE6Ioii2a9dObNeuXa1jF0VRH7ft27fXaXsdU/mko3tNq+a0rq8KhUL8448/jJ6zcOFCEYC4ceNGo8d69eolOjs7G7w248aNEwGIK1euNNg2OztbDA0NFf39/cWSkpJax6H7+584caLRY0uWLBEBiA8//LCo1Wr17QkJCaKzs7Po4+MjFhUV6dsXL14sAhA9PDzE48eP1/q7qwIg+vr6iosXL9bfnnrqKbF79+6iSqUSZ8+ebfSc+rwGP//8swhAfPrpp432c+3aNbG0tFT/s6n41UXVv6VNmzaJAMRvv/1W//gTTzwhqlQqMSsrS/9+WDV3CwsLRW9vb9HFxUU8duyYvl2j0YijR48WAYivvPKKwfZeXl6ih4eHePbsWX17eXm5OHDgQBGA0d/BCy+8IAIQX3rpJYOYFhUVibGxsaKzs7PB+64upn/99Ve9XguybyyASRZ0/wFGRETo/+OZO3euOGDAABGA6OrqKu7bt0+/PQDR2dlZzM3NNdrXU089JQIQd+/ebfSYRqMR/f39xV69eunbZsyYIQIQV69eXWs/ayqAf/vtt1qfb6pgGTx4sAhAPHjwoNH2r732mtF/OLo+TJgwwWz/Pvjgg1r7Ioqi2LdvX1GlUonZ2dkG7b179xadnJwMXt9WrVqJYWFhBv9JNxbdf9pTp04VFy9eLC5atEicNm2a6OfnJwIQn3rqKYPtly1bJgIQv/zyS5P7i4mJEf38/PQ/v/nmmyIAcdGiRQ3qZ7du3cSwsDCDtsYogKOiokQA4pkzZ+rVH0sL4FGjRpl8ztmzZ0UA4vDhww3aT506JQIQR44cqW/Lzc0VlUqlOHjwYJP7+uCDD0QA4i+//FLrOGoqgMPDw0UnJyeDDyk606dPN8oDXbH0zDPP1Pp7q9N9sDZ169+/v1EBVt/XQFcAL1iwoNa+NEYBXF5eLvr5+YnDhg0TRVEUS0pKxJYtW4ojRowQRVE0WQB/+eWXIgBxxowZRvu+ePGiqFKpxPDwcH2b7gP8k08+abT9nj17jApgjUYjtmzZUoyIiDAofnV0r9GHH36ob2MBLE+cAkGykpycrJ/j6OTkhMDAQIwbNw7z589Ht27dDLZt3749/Pz8jPZx4MABAMBvv/2GHTt2GD3u5OSEM2fO6H8+dOgQAODOO++0qM8PPfQQli9fjlGjRmH06NG44447MHDgQAQHB9fp+YmJiXB3d0fv3r2NHtOd9HX06FGjx3r16mXUFhISAgB1Xj91/Pjx2L9/PzZs2IDZs2cDAJKSknDo0CH9/GmdMWPG4JNPPsFNN92EMWPG4LbbbkPfvn3h5uZWp99VF6bmKz777LN45513DNp0MT548KDJebmlpaXIy8tDXl4e/Pz86h3jnTt3Yvny5Th48CDy8vIMzpSv/nWuPTKVawDQqVMn9O7dG9u2bdO/doB00hQAg+kPhw8fhkajQVlZmdFJY4CURwBw5swZ3HvvvRb1s6ioCCkpKejcubM+t6u67bbbsHLlShw9etSgbzWNsTaRkZEG7w8FBQVISEjAnDlzMGTIEHz33XcYNWoUgPq/BgMHDkTr1q3xxhtv4NixY7j33ntx6623onPnzk2yPriTkxMeeeQRfPDBB7h8+TJ2796Nq1ev1ngSX2JiIgCYnNLUtm1bhIeH49y5c7h27Ro8PT1x7NgxAMCAAQOMtu/bt6/R1KWzZ8/i6tWraNOmjcF8dh3dUnNVY0DyxAKYZGXo0KF1Xu7K3FzJK1euAIDRCWjmFBYWQhAEi5c269OnD3bu3InXX38d69evx5o1awAAcXFxePPNN2tduaCoqAihoaEmH9P1qaioyOgxU0sx6f6zMTe3r7rRo0fj6aefxtdff60vgL/66isAMCoo3n//fbRv3x5r1qzBq6++ildffRWurq546KGH8O6775r8MFJf+/fvx80334zy8nIcO3YMTzzxBN5991107twZU6dO1W+ni/HHH39c4/6Ki4vh5+enP7moLh9KvvvuO4wePRotWrTA0KFDERYWBnd3d/3JYxcvXmzACE0LCgrCmTNncPnyZURGRjb6/quraZ7x+PHjcejQIWzcuBEzZ86EKIr473//i5YtW+Kee+7Rb6eLwd9//23yZDSd4uJii/upy3tz/a3p76O2udR15ePjg8GDB2PTpk3o2LEj5s2bpy+A6/saeHt748CBA1i0aBF++eUXbN26FQAQGhqK+fPn44knnmiUPlc1ZcoULF++HGvXrsXOnTsRFBSEu+++2+z2dXnNz507h6KiInh6eur/tgICAoy2VSqV8PX1NWjTvWYnT57EyZMnzfajIXlDjoGrQBCZYe6Iia4wLCoqgihNIzJ50/Hx8YEoisjMzLS4LwMGDMD//vc/XL16FX/99RfmzJmDf/75B/fccw9SUlJqfK6XlxdycnJMPpaVlWUwpsbWqlUr3H333YiPj8fZs2cBSEf7vL299SeF6ahUKsydOxcnT57E5cuXsX79egwYMABffvklHn744Ubtl7OzM+Li4rB161a0bNkSTz31FC5fvqx/XPd6/PPPPzXGWHeymu4koqr7MOfll1+Gq6srjhw5gu+++w5vv/02lixZom9vCrqVFUx9Y1EThUL6L8LUWq66wsSUmo42jhkzBk5OTvqjvrt378bFixfx0EMPGZyAp4vBs88+W2MMFi9eXK8xVaX7HdnZ2SYfr+nvo7GPqHbo0AGtWrXC+fPn9d+wWPIatG3bFmvXrkVubi4SExPx5ptvQqvVYubMmdiwYUOj9hkAunXrhri4OHz88cf4888/MWHCBKOjslXV9zXXLQtp6j1Mo9EYrciie94DDzxQ42umO5BA8sUCmKie+vTpA6Dya/La6L4q/f333xv8u93c3DBo0CC8++67eOGFF1BSUlLr1bt69uyJGzdu6L+mr0q3vJjujPimoDvS+/XXX+Pvv//GhQsX8OCDD9ZY7LVp0wZjx47Ftm3b0KFDB2zfvh0lJSWN3jd/f3/90ktVvy7VxXj//v112k99YpycnIzOnTujY8eOBu2ZmZm1fpix1KRJk6BUKvH555/XerWxqlfF061yUb2w12q1+q+m68vPzw/Dhg3DgQMHcP78eX0hrLtAjU5cXBwEQahzDCzh5eWF8PBwnD9/3uSHl+b4+9BRq9W4du0aAOn1BRr2GigUCvTo0QPz5s3TF75VlwDTrVpR129zajJlyhRkZmZCq9XWuoZxz549AcDk0oaXLl1CcnIywsPD4enpCQD6NYb37NljtP3+/fuNPpx17twZXl5eiI+PR0VFhSXDIZlgAUxUT0888QRUKhWefPJJpKWlGT1eUFCgn+cGAI8//jiUSiUWLlxo9PW2+O8VyWqyf/9+lJaWGrXrjqDUdtRw4sSJAKRlxqr+h3Dp0iUsW7YMKpWq0Y+wVnXPPfegZcuW+O9//4svv/wSgPH0h7KyMuzbt8/oucXFxbh+/TqcnJz0RyMBqYg8c+ZMo/wH99hjj6FNmzZYs2YNLly4AACYPHkyPD098eKLL5r8GvXGjRsGH4AmTpyIFi1a4N133zU5n7pqcdWuXTucP3/e4AhYaWkpZsyY0WT/YXfo0AHz5s1DXl4e7rrrLv04qyotLcWyZcsM5prGxcUBgNG61MuWLTO5j7rSxf+LL77Ad999h/bt2xut/xsUFISHHnoI+/btw9tvv23wrYrOwYMHG3zlw4kTJ6KiogILFiww+B3Hjx/H2rVr4e3tXetSa43ho48+QkVFBbp27YpWrVoBqP9rcPLkSZNHVk29V+h+x6VLlxrc90ceeQQ//PAD/ve//9U6xWbEiBHw9vbGmjVrDP62RFHE888/D7VabbBG84gRI+Dl5YXVq1fr1wwHgIqKCixcuNBo/yqVCjNmzMDFixcxd+5ck39TJ06cMPutGMkH5wAT1dNNN92ETz75BDNmzEBkZCTuvvtuRERE4Nq1a0hJScGuXbswadIkrFixAoD0FeHy5cvx1FNPoWvXrhg5ciTatWuHrKws7N69G/fccw+WL19u9ve9+eab+OuvvzBw4EC0b98erq6uSEhIwI4dOxAeHq6fL2jO+PHjsXnzZvz000/o3r077r33Xv06wFeuXMG7776L8PDwxnyJDLi4uOChhx7CZ599hjVr1qBdu3YYOHCgwTYlJSXo168fOnXqhF69eqFt27a4fv06fv31V2RlZWHu3LkGX4/ffvvtuHjxIi5cuFCvtUtNcXV1xfz58/HUU0/hlVdewZo1a+Dv769f/zU6OhrDhg1DVFQUysrKkJqail27duGWW27RzycPCAjAl19+iTFjxqB379647777EBkZiby8PBw8eBBhYWH48ccfAUgXXnnyySfRs2dPPPjgg1Cr1fjjjz8giiKio6MtPrJam1dffRWlpaV47733EBkZicGDB+Omm26Ck5MTLly4gO3btyM/Px+vvvqq/jmTJ0/GW2+9hZdffhlHjx5FREQE4uPjceLECdx6663YtWuXRX0ZPnw4vL29sWzZMlRUVOCpp54yOaXgk08+wdmzZzFv3jx89dVX6Nu3L3x8fHDp0iXEx8cjKSkJmZmZcHd3t/h1mTdvHrZs2YKvvvoKp0+fxu23346cnBxs3LgRarUaK1eu1B+NbAx5eXkGHzIKCwuRkJCA3bt3w8XFBR9++KHB9vV5Df744w8899xz+r8lX19fpKSk4Oeff4arqytmzpyp3+/gwYPxzjvv4NFHH8UDDzwADw8PtGvXzujDaV20aNGizh8SvLy8sHLlSowdOxZ9+vTB6NGj4e/vj+3bt+PIkSPo3bs3nnvuOf323t7e+OCDDzBp0iTExcVhzJgx8Pb2xq+//go3NzeT51YsWbIECQkJ+OCDD7BlyxYMHDgQAQEBuHz5Mv755x8cO3YM+/fvNzmvmGSkiVaXILIpNa0DbAr+XTe3JocOHRLHjBkjtmnTRnRychL9/PzEmJgYcf78+eLp06eNtv/rr7/Ee++9V2zVqpXo7OwshoSEiA888ID4999/67cxteTVtm3bxAkTJoiRkZGip6en2KJFC7FLly7iCy+8YLRMm7llqyoqKsR33nlH7Natm+ji4iJ6enqKt956q/jTTz8ZbWtu2S3dGACIixcvrvG1qW7v3r365Z5MLdFUXl4uvvnmm+Kdd94phoSEiM7OzmJgYKA4cOBAcf369UbLGbVr165eSziZWwdYp7S0VAwODhaVSqXBWqNnzpwRp06dKrZr1050dnYWW7ZsKXbr1k186qmnDNYN1klMTBQfeughMTAwUHRychJbt24t3nXXXeKvv/6q30ar1YorVqwQu3btKrq6uopBQUHi1KlTxZycHJPxa4xl0Ko6fPiwOGXKFLFDhw6im5ub6OLiIoaFhYnjxo0zuXbv0aNHxdtvv110d3cXvby8xBEjRohJSUk1LoNmKneqmzZtmj4nqr7m1d24cUN86623xF69eokeHh6im5ub2L59e3HkyJHil19+KVZUVNT6u2paBk0URfH69eviSy+9JHbq1Em/9u9dd90l7tmzx2jbhiyZpRtv1ZuTk5PYtm1bcfz48eKJEydMPq+ur8GpU6fE2bNniz179hR9fX1FFxcXMTw8XJw4caJ48uRJo/2+9dZbYseOHUUnJ6c6veeJYu1/S1WZWgZNZ/fu3eJdd90l+vj4iM7OzmKnTp3El156Sbx+/brJff3www9ir169RBcXFzEgIECcNm2aeOXKFbN/B2q1Wvzss8/Efv36iV5eXqKLi4vYtm1bcdiwYeKnn35q8Hu4DJo8CaJo4jsVIiIiIiIHxTnARERERCQrLICJiIiISFZYABMRERGRrLAAJiIiIiJZYQFMRERERLLCApiIiIiIZIUXwqgDrVaLjIwMeHp6Nvr13+tCkZwM18cfh5CfD3h5oeTTT6Ht3Ll6J+Hy0ktQ7dgBqNXQ9OmD0vfeA5ydIVy8iBY9ekDbtat+8xtffgmxCS9+QERERNScRFHEtWvX0KZNG4Orh5rCdYDrID09HaGhoVb7/TsAfAlgHYAHADwPoHe1baYBGAtgGIAKAJ8DOAfgHQDtABwF0LJ5uktERERkNZcuXUJISEiN27AAroPCwkL9pSe9vLya9XcLublo0bMnrqWmAioVIIpo0akTirdtQ0W7dkhMTETPnj3RYv58aIOCUD53LgBA9fPPcHnjDRTv2ycdAR4wANfS0pq179S01Gq1Pv4qFb/MkSPmgLwx/sQcMFRUVITQ0FAUFBTA29u7xm35atWBbtqDl5dXsxfASEoCWreGV6tWlW3t2sHz6lWou3WDh4cHvLy8oOrbF/jsM7jOnQu4uQG//gqkpUn99fQEiovhdfvtgEYDjBwJvPgioFQ271ioUanV6sr4841PlpgD8sb4E3PAtLpMV+VJcHZMqVSie/fuUCqVwKRJwLBhwK23SrdOnaQjxgDQujVw+TJw+DCwfTuwZw/w7rtW7Ts1nEH8SZaYA/LG+BNzwHIsgG1daCiQmQmo1dLPogikpQFt2wIAnJ2dpXZBAF5+GUhMBPbtA7p0AXQnvbm4AAEB0v1WrYApU6QimOyePv4kW8wBeWP8iTlgGRbAti4gAIiJAb7+Wvr5+++BkBCgQwdoNBrEx8dDo9EApaXA1avSNnl5wBtvAPPmST/n5AAVFdL9sjJg82agZ8/mHws1KoP4kywxB+SN8SfmgOU4YcQefPaZNMXh9dcBLy9gzRoAgOLRR9Gyc2cgNhYoLAQGDQIUCkCrBWbPBoYPl56/dy+waJE051etBgYPluYAExEREckQC2B7EBkJ7N9v1Kz9/HNcjY+XfggMBE6fNv38+++XbkRERETEKRBEREREJC9cB7gOioqK4O3tjcLCwuZfBq0GoihCo9FAqVRa5Qp1ZF2MPzEH5I3xJ+aAofrUazwCbOfKy8ut3QWyIsafmAPyxvgTc8AyLIDtgFqtNnmGp0ajwfHjx3n2p0wx/sQckDfGn5gDlmMBbAe2bduGH374wdrdICIiInIILIDtQHJyMlq0aIFNmzYhXrfqAxERERFZhAWwjbt27RoKCgqQl5eH06dPo1WrVrh06ZL+cV7+UN4Yf2IOyBvjT8wBy3AViDqw5ioQp06dwnfffQcA6NChAy5fvozy8nI8++yzcHNza9a+EBEREdkqrgLhQE6dOgUAEAQBaWlp6N69O2bOnAk3NzeIooiCggLwM4w8Mf7EHJA3xp+YA5ZjAWxjkpKABQuAsWOBBQtEpKfnQqVS4fbbb8czzzyDYcOGoWXLlgCksz/PnDnDsz9livEn5oC8Mf7EHLAcL4VsQ9asAaZNAwQBEEXpqK8oPo6VK0X068fPKkRERESNgQWwjUhKkopfrbb6IwKmTRPQsiXQty8QEAAoWAsTERERWYwFsI1YvVo68muKKAL33y/dd3ICgoOBkBAgOFgBV9dw9OihQNu2QGio1B4YyCJZDgRBgJubGy9/KWPMAXlj/Ik5YDmuAlEHzbEKxNixwLffmjoCXH8qVWWRHBJSWRhXvR8YCHDlFCIiInIU9anXeATYRoSFmT8CLAhAdLRU1KanA5cuAVeumN+XWg1cvCjdzFGpgDZtai6Sg4JYJNsyrVaLvLw8+Pn5QcFD/rLEHJA3xp+YA5ZjAWwjpkwB3nrL9GOCAHz3HdChQ2XbjRvAxYtq7NhxDh4ekcjMVOLSJalA1hXJ+fnmf59aDaSlSTdzlErzRbLu56AgqZim5qfVapGSkoJWrVrxjU+mmAPyxvgTc8ByLF1sRMeOwKpVwNSpVVeBkP5dtcqw+AUAd3fpOYWFRYiNFU0WoSUlwOXLMCqMq97PyzPfJ41G2qbKheeMKBRA69amjyDr7rduzSKZiIiIbAfLEhsyaRLQv79U8KamStMipk41Ln7rys1Nem5Nzy8tlYpkU8Wx7n5Ojvnna7XS8y9fNr+NQiEdKa6tSHZysmycRERERPXBAtjGdOgALF1at20FQYC3t3eDzv50dQUiIqSbOaWlQEZGzUVydrb552u10vMzMoCDB82NpfYiuU0bFslVNUb8yb4xB+SN8SfmgOW4CkQdNMcqEPaurKz2Ijkrq2G/QxCk1StqK5KdnRtnTERERGQ/uAqETGi1WmRkZKBNmzZWn/zu4gK0by/dzCkvryySzRXKWVnSvGdTRFF6PCsLOHzY/O+pqUiW1k+W+mvvbCn+ZB3MAXlj/Ik5YDkWwHZMq9UiPT0dQUFBdpH4zs7SvOawMPPbVFTUXiRnZpovkgFpOkZ2NhAfb36bgADzy7/pbrZeJNtb/KnxMQfkjfEn5oDlWACTTXFyAtq1k27mVFRIRXBtRXJNFxXJyZFuCQnmt/H3r71IdnW1fKxETSYpCZg4UVrmxdsbWLsW6NrVcButFpg7F9i2TVqmxdcXWLlSOhEhNVU6MaBbt8rtv/++5pMFiIjsCAtgsjtOTkDbttLNHLW69iI5I6PmIjk3V7olJprfxs+v9iLZzc3ysRJZ5LHHgEcflZaW2bRJ+rf6vKGffwb+/hs4dkz6o3r1VeCFF6RLUgKApydw9Ggzd5yIqHmwALZjCoUC/v7+/NrDBJVKKkRDQ81vo1ZL84lNFcm6nzMypPWQzcnLk2411Qm+vrUXye7u9R8j408mcyAnR5r/8/vv0s8PPADMmgWcP2+4JqIgSGevlpZKfzBFRVIykt3gewAxByzHAtiOKRQKRPArSYupVJUFqDkajTSfuKaLiWRkSMW0Ofn50u3YMfPbtGpVe5Hs4WH4HMafTObApUuGV58RBOnrkrQ0wwJ4+HDgr7+k9Qc9PaWzQ3ftqny8uBiIi5P+CEaOBF58kddGtzF8DyDmgOVYANsxrVaLCxcuoH379vz010R0l4Nu0wbo08f0NhqNdNCtpiL58uWai+QrV6Tb8ePmt2nZ0rA4Dg7WwsUlDz17+qFtWwVCQoAWLRo2XrIvDXoPiI8HTpyQktPLC5g/H3j8ceDrr6UC+vJl6WzRK1eA0aOBd98F5s1rmoGQRfh/ADEHLMcC2I5ptVrk5uaiXbt2THwrUiqleqF1a6B3b9PbaLV1K5IrKsz/nqtXpds//+haFAACDLbx8TG/RrLuvqdnIwyabILJ94DQUGkCvFotHQUWRenob/VJ819+CQweLCUNIJ00d+ed0n0XF6n4BaSvJ6ZMAdavZwFsY/h/ADEHLMcCmKgZ6C4HHRQkfatsilYrnXRnrkjW3crLzf+eggLpduKE+W28vWsvknm9FzsWEADExEhHcidNklZvCAkxviZ6eDiwdau0EoSzM/Drr8BNN0mP5eRIXzk4OUnzhDdvBnr2bPahEBE1FRbARDZCoZAu4hEYCMTGmt5Gq5VOuktPB1JTNdi3Lw1KZTtcvqwwKJLLysz/nsJC6XbypPltvLxqL5K9vWseT1ISsHq1tKJWWJh0ELFjx9peBWoUn30mFb+vvy4Fc80aqX3aNOC++6TbzJnA6dNAdLRU6AYFAStWSNvt3QssWiR9vaFWS0eKX3zRasMhImpsvBRyHdjqpZB5BRh5Mxd/Uawskms6mlxa2rDf7+lpvkg+fBh4+WXp/CtRrPx31SqpLqPGwfcAeWP8iTlgqD71ms0VwB9//DHefvttZGVlITo6Gh9++CF6m5lYWVFRgaVLl2LdunW4fPkyIiMj8eabb2LYsGH6bV5++WUsWbLE4HmRkZE4c+ZMnftkqwUwkaVEUVqZoqYi+dKlhhfJ1QkC8Pbb0gmFYWHSvGkuLEBERI2hPvWaTU2B2LhxI+bMmYMVK1agT58+WL58OYYOHYqzZ88iICDAaPuFCxfi66+/xsqVKxEVFYXffvsNo0aNwr59+9Czyny1rl27Yvv27fqfVSqbGrbFNBoNzp07h06dOkHJKkJ2GhJ/QZAu4uHnB/ToYXobUZQWAKjpYiKXLgElJXX/vaIoTTnV0a3XrLv6n+4WFib9GxoqTU8l0/geIG+MPzEHLGdTleCyZcswffp0TJ48GQCwYsUKbNmyBatXr8b8+fONtv/qq6/w4osv4u677wYAzJgxA9u3b8e7776Lr7/+Wr+dSqVCUFBQnftRVlaGsiqTKIuKigAAarUa6n/XslIoFFAoFNBqtdBWuZyYrl2j0aDqwXVz7UqlEoIg6PdbtR2Qkttcu0ajQUFBAdRqNZRKJURRNNheEAQolUqjPpprt4UxVaVSqTimGsZUNf6iKDbJmLy9pbm+XbuaHpMoAteuqXDpkoi0NC0uXQI+/liB06cBURRQG7UauHBBupkiCCJatxbQtq2Idu1EtG0LtGsnIixMQPv2CoSEaODubttxasrc02q1BjngCGMy1XeOyXTfNRoNCgsLzfbRHsfkiHFqyjHp/h8QRdFhxqTroyVxqr59TWymAC4vL8eRI0ewYMECfZtCocCQIUOwf/9+k88pKyuDq6urQZubmxv27t1r0JaUlIQ2bdrA1dUVffv2xdKlS9G2huvoLl261GjaBAAkJibC49+rEfj7+yMiIgIXLlxAbm6ufpuQkBCEhITg3LlzKCws1LeHh4cjICAAJ06cQEmVQ2ZRUVHw8fFBYmKiQUC7d+8OZ2dnxMfHG/QhNjYW5eXlOH78OERRREFBAY4dO4bevXujsLDQYGqHm5sboqOjkZeXh5SUFH27t7c3OnfujIyMDKSnp+vbbWFMOkqlEnFxcRxTDWO6ePEiCgoKkJCQAEEQrDomhaIQJSVn4O8P9OoVirNn25i8gp5CIWLQIAFhYdeQlFSBrCwXZGW54No1029FoiggIwPIyBBw4ICpgloJb+8KBAWVISioHF27uqNTJ1eUl19AQEAJgoLK4OWlQXS0Y+aeUqk0yAHdmFJSUpCZmQkXFxe7G5MjxqmpxuT575qGmZmZyMzMdIgxOWKcmnJMVQtfRxkTYHmcEhMTUVc2Mwc4IyMDwcHB2LdvH/r27atvnzdvHnbt2oWDBw8aPWfcuHE4duwYfvzxR0RERGDHjh0YMWIENBqN/gju//73P1y/fh2RkZHIzMzEkiVLcPnyZZw4cUL/5lGdqSPAoaGhyM/P188psfanHN0R4ISEBMTExMDFxcXuP7k54qfRphyT7kNjTEwMlEqlzYwpKQm46SYltNrqBasIhQI4e1ZAeLjhmK5fV+DSJQUuXNAiNVVEWpqAixfx778CsrNhsRYtRP3UiqpHktu2FREerkRgICCK9pl7arUa8fHx+hzQeeuttzBkyBBERkbC3d0dgiDYzZgAvkfU5whwYmIiYmJiDE6AsucxOWKcmvoIcEJCAuJMrK9pr2PS9dGSOF29ehW+vr72dRKcJQVwbm4upk+fjl9++QWCICAiIgJDhgzB6tWrDT5JVFVQUIB27dph2bJlmDp1ap36ZqsnwWm1WuTl5cHPz8/gzY/kwZbjv3YtMHVq460CUVoqXcvh4kXplppaef/iRWk+cpX32npxcZHmGuvmHVe/hYRUXlXY1pjKgcuXL+OLL77A0KFD8fvvv2Py5MkIDQ21ck+pKdjyewA1D+aAIbs8Cc7Pzw9KpRLZ1Q71ZGdnm52/6+/vjx9//BGlpaXIz89HmzZtMH/+fISHh5v9PT4+PujUqRPOnz/fqP23BoVCYfLkQJIHW47/pElA//5SwatbB3jqVONrMdSVqyvQqZN0M0Wtlq6kZ6o4lo4km18buawMOH9eupmiUEhFsKniWDqqDLi5WTauhjKVA5cuXYJSqcRff/2FiIgI5OXlIS8vz+DEYHIMtvweQM2DOWA5mymAnZ2d0atXL+zYsQMjR44EIH2y2bFjB2bNmlXjc11dXREcHIyKigp8//33eOihh8xue/36dSQnJ2P8+PGN2X2r0Gg0OHHiBG666Sae/SlDth7/Dh2ApUub53epVJUF6cCBxo9r/70UtaniWHe7ds30vrVaqYBOSwP27DG9TWCg6eJYd1S5qb44MpUDqampAKSvM7OysnD+/HnExsayAHZAtv4eQE2POWA5mymAAWDOnDmYOHEiYmNj0bt3byxfvhzFxcX6VSEmTJiA4OBgLP33f9WDBw/i8uXL6NGjBy5fvoyXX34ZWq0W86pcr37u3LkYPnw42rVrh4yMDCxevBhKpRJjx461yhgbkyiKKCkpgY3MYqFmxvjXnaLKpahvvtn4cVEErl41XxynpkrrJpuTnS3dDh0y/biPT80Fsp+fNE2kvkRRxLlzItavF5CWJu3P3T0ZWq10HkR0dDRuvvlm+Pv713/nZLmkJGDiROmKNN7e0pygrl0Nt1mzBnj//cqf09OlT2+bN0sJFxEBdOtW+fj330ttVfA9gJgDlrOpAnj06NHIzc3FokWLkJWVhR49emDbtm0IDAwEAKSlpRnMcSktLcXChQuRkpKCFi1a4O6778ZXX30FHx8f/Tbp6ekYO3Ys8vPz4e/vj/79++PAgQP8D4GI9AQBaNVKupk7UFpcXHOBnJkpFdKmFBRIt2PHTD/u7o5/l3gzLo7btTN/wZC1awU89li0wVzrxx5rifbtgzFjxhD9qjXUzB57DHj0UWku0KZN0r+HDxtuM3mydNO56Sbg4Ycrf/b0BI4ebYbOEsmTzZwEZ8ts9SQ43RngsbGxDnNxD6o7xt+2lJdLFwYxVRxfvCg9Vo8lKg1Uv2BIWJg0L/qFF0ST6y1Lq21YPueaGiAnR3rhr1yRAieK0ieYvXvNB+TgQWD4cGkiu5OTlDQ9ekifmmrA9wBiDhiyy5PgqP6USiWioqI470emGH/b4uwsfUNd7VtqPY1GOkpsqjjW3cxdVc/8BUNMz5sQReDZZ4GFC6X+tGpl6aio3i5dkgpeXTEiCNLh/bQ08wXwqlXA+PFS8atTXAzExUmJM3Ik8OKLRl8D8D2AmAOWYwFsxwRBMJjuQfLC+NsXpVJaTSIkBOjXz/hxUZSmjJorji9erPWAoMG+fv5ZugHSHOTw8MoCveotONj09ApqJsXFwDffAAcOVLa1bi0dDQ4IkI4kjx4NvPsuUOX8FoDvAcQcaAgWwHZMrVYjMTERPXv25FcfMsT4OxZBAPz9pVtsrOltiooqi+MPPwS2bzc9BaK6ggIgIUG6VefsLE2pqF4Yh4dLN2st8Wa3QkOlQ/1qdeUUiLQ06SiwKd99J50g16VLZZuLi1T8AtLh+ylTgPXrjQpgvgcQc8ByfLXsXPWroZC8MP7y4uUlLQzQrRsQFSXdpNM4DItgQQDmzgUKC4HkZOmWlmb6YiHl5cC5c9LNlDZtjAtj3X1fX8tWr3BoAQFATAzw9dfSyW/ffy8d9q9p+kP1izLl5AAtW0pTIsrKpJUhzJydyfcAYg5YhgUwEZEd6tgR+PxzLR59VAFBkI4E13TFvfJy6ehxSkplUay7paQAN26Y/j0ZGdLN1BrIXl6mC+OICOlAqGynVnz2mRSA11+XXqQ1a6T2adOA++6TboB0puLRo8DWrYbP37sXWLRIegHVamDwYGkOMBE1GhbARER2auJEEV5eRxEfH420NKHGK+45O0tFc8eOxo+JorSOcfXCWFcc5+SY/v1FRUBionSrzslJmlphau5xeLi09Ft9JSUBq1dXXl1wyhTT47G6yEhg/37j9i++MN7O1BVY7r9fuhFRk+EyaHVgq8ug6RbAdnNzg8DvIWWH8afmyoFr18wfOb54UVqooL6CgkyflBcRYfrCIGvWSAdQq655bO5ot1zwPYCYA4bqU6+xAK4DWy6ANRoNlEolE1+GGH+yhRyoqJDmF1cvjHX3i4vrv09PT8Mjxy1aAC+/bPpCI3Je89gW4k/WxRwwxHWAZUKj0XABbBlj/MkWcsDJyfz6x6IoTZ8wVRgnJ0vTLky5dk26ap65K+dVJQjSUeClSxs2DntkC/En62IOWI6vFhERNQlBAAIDpdsttxg/fv26VBSbml5x8WLdrpyn0QCffirta9AgYOBAaSk5a9JoNBAEAQqFwrodISKzWAATEZFVtGgBdO8u3apTq6WpFSkpwDvvAL//bnoKBCAt9/bRR9INkJbVHTSosiDWLanbXH799VeIooiRI0c27y8mojpjAUxERDZHpaq8GEe7dro1j01vqzshTufkSen28cfSz126SMXwrbdKt8DApuu3KIpITk5Gt27dsGnTJnTs2BHR0dFN9wuJyCI8Ca4OeBIc2SLGn+SUA2vXSku8mVoF4v77gb//BnbulG5HjtS8MkXnzlIhrCuKg4Iar58FBQV4//33ERERgQsXLmD8+PFwdnZGmzZtGu+X/EtO8SfTmAOGuApEI7PlApjLn8gX409yy4Hz56WCV7cOsLk1j69dMyyI4+NrLogjIyunTNx6K9C6teV9/Oeff7B582YAQMeOHZGeno6Kigo899xzcHZ2tnzHJsgt/mSMOWCIBXAjs9UCWK1W8+xPGWP8iTlQN9euAfv2GRbENZ1g16mTYUFcn4O333zzDc6ePQtBEKBSqdCzZ0/06dMHrVq1atggTGD8iTlgiMugERER/cvTExg6VLoB0ooRuoJ41y7g0CHDgvjcOen2+efSzx07GhbEwcGV21a/Op2fXy5UKhVuvfVWxMbGwtXVtVnGSET1wwKYiIhkpUUL4M47pRsgXayjekFcUVG5fVKSdFu5Uvq5QwepGNatQVx1XjIwE59/DvTvb8NLoCUlARMnAnl5gLe3NMG6a1fj7f75B3jyycoFm197TZpwvXMncNdd0twRnf37ATe35ug9UaNgAWznlEqltbtAVsT4E3Og4Tw8gDvukG6AVBDv3y8Vwzt3AgcPGhbE589LN9MUmD5dWn6tOa5OZ1H8H3sMePRR6RrSmzZJ/x4+bLjNjRvAiBHAl18C/ftLk6ivXKl8PDISOHq0AT2nxsL3AMtwDnAd2OocYCIiano3bhgXxOXl5rdXKIDnngPeeKPZulh3OTlSZX7lirTWnChKZ/3t3WtYsX/xBfDnn8D69cb72LkTePppFsBkc+pTr9nwdzRUG1EUUVBQAH6GkSfGn5gDzcPdHbj9duCVV4Ddu4GCAuC223RTHoxptdLV6b74Aigtbbp+WRT/S5ekgld3wpQgAG3bSlcdqerUKcDFBbj3XqBHD2DCBCA3t/Lx5GQgJgaIiwM++aTBYyHL8D3AciyA7ZhGo8GZM2egqWl9H3JYjD8xB6zDzQ3o00c60mtOUREwfbp0EY9XXpGm2za2Jo2/Wg1s3w589hmQmCid+TdjhvRYTAyQng4kJAA//ACsWAF8+23j94FqxfcAy7EAJiIiqqcpU8xfma6qnBxg8WLpIOuMGdLqElYVGgpkZlYueyGK0tHftm0Nt2vbVjrMHRwsHSV+5BHgwAHpMS8v6eQ5AAgJAcaOBfbsab4xEDUCFsBERET11LGjtAKEQgEolYb/rlkjzRN+6KHKo8QlJdKB0qgo6dyy3bvrVkA3uoAA6Qju119LP3//vVTEVj9j76GHpBPjioqkn7duBXSXdM7MlOZ5ANIiy7/+CvTs2Tz9J2okXAXCjgmCwKu/yBjjT8wB65o0SVogwdzV6TZulNrff1+aD3z9ulT0/vyzdIuLA559FnjggcopufVhcfw/+0zq/OuvS0dz16yR2qdNA+67T7q1bQu88AJwyy1SFR8cXLkw8vffS5OcVSrpSPJ//gNMnlz/AVCD8T3AclwFog64CgQRETVEQYG0jvD77wOXLxs+1q4dMHu2VH96ekpt1S+wMWWKdNSZiMzjpZAbma0WwFqtFnl5efDz84OiprMxyCEx/sQcsD/l5dL5Yu++a7yKmJeXtDxvUBAwb57hBTZEUTrSPGlS5faMPzEHDHEZNJnQarVISUmBVjcXi2SF8SfmgP1xdpbOJ0tIAHbskC6oplNUBLzzDjB3rjTFVqMx/HfqVMMLcDD+xBywHAtgIiKiZiYIwODB0rllJ09Kxa2zc+3PWbWqefpH5OhYABMREVlRly7SSXJpaUDXrua3E0VpTnBDpKenY9euXQ3bCZEDYAFsxwRBgLe3N8/+lCnGn5gDjiUwEBg+XFpOzRStVrpi8fbturnB9Y9/fHw8zp49i8zMTKQ2tJomq+N7gOV4Elwd2OpJcERE5FiSkqS1gmub0nnLLcCiRcCdd5q/JLMpH374IYKDg3Hu3DncdNNNuPfeexvWYSIbwpPgZEKr1SI9PZ2T32WK8SfmgOMxd4ENQZBWh9DZtw8YNgyIiSnHL79o63RRjeLiYly5cgUXLlyAh4cHPDw8sGLFCuTk5DTdgKhJ8T3AciyA7RgTX94Yf2IOOKZJk4CzZ4HnnpMuyPbcc9IllNPTgW++MZwnfPSoM+67T4G4OOniGjUVwmlpaQCAGzduoKioCPv27UNISAhatmzZtAOiJsP3AMvxSnBEREQ2pkMHYOlS4/bRo6ULr23eDCxZIuLECWn+w5Ej0iWWe/SQpkaMGAEkJxteTKN9+wQAgLOzM/r27YvY2Fi4u7s325iIbAkLYCIiIjuiUAAPPgjcd58Gy5Yl45tvOuHYMakQPnoUuP9+ICREuuKcQlF5MY22bW/BU0+1waxZA6Cy5NrLjSEpCZg4EcjLA7y9gbVrjZe+2LlTWiA5MrKybf9+wM2t5seI6oFTIOyYQqGAv78/r/4iU4w/MQfkTaVS4D//UeHIERE//wzExlY+lp4uFb5VL6Zx4UJ7PPvsbUhNteKxr8ceky53d+4c8Pzzhpe2qyoyUqrmdbeqBW5Nj8kM3wMsx1fMjikUCkRERDDxZYrxJ+aAvOnir1QqMHw4cOgQsGUL0Lq1+edY9WIaOTlAfLx0KTwAeOAB4NIlw8vbUb3wPcByfMXsmFarRXJyMie/yxTjT8wBeasef0EA7r4buPVW80ujabXSwVeruHRJqs510y+keRnSFUCqS04GYmKAuDjgk0/q/pjM8D3AciyA7ZhWq0Vubi4TX6YYf2IOyJu5+IeFSXN/TRFF4H//A9atq3nFCKuKiZHmcCQkAD/8AKxYAXz7be2PyRDfAyzHApiIiMiBTJlSc3FbUiJNvb31VuDEiWbrFhAaCmRmAmq19LMoSkd/27Y13M7LSzpBDpDO5hs7Ftizp/bHiOrB5grgjz/+GGFhYXB1dUWfPn1w6NAhs9tWVFTglVdeQUREBFxdXREdHY1t27Y1aJ9ERET2zNzFNBQKwxPl9uyRlk2bOxe4dq0ZOhYQIB3B/fpr6efvv5eK2A4dDLfLzKy8FN61a8CvvwI9e9b+GFE92FQBvHHjRsyZMweLFy9GQkICoqOjMXToULNXqVm4cCE+++wzfPjhhzh16hQef/xxjBo1ComJiRbv054oFAqEhIRw8rtMMf7EHJC3muJv6mIaZ88Chw8D27ZV1pwaDfDuu9Lll7/9thmmRXz2mXTr1Al44w1gzRqpfdo06UoegFQYd+sGREcDN98M3HEHMHly7Y/JEN8DLCeIou3MAurTpw/i4uLw0UcfAZDmtoSGhuLJJ5/E/PnzjbZv06YNXnzxRcycOVPf9sADD8DNzQ1f//sJs777NKU+15YmIiKydaWlwNtvA6+/Lt3XueMO4KOPpPqUyN7Up16zmQthlJeX48iRI1iwYIG+TaFQYMiQIdi/f7/J55SVlcHV1dWgzc3NDXv37rV4n7r9lpWV6X8uKioCAKjVaqj/nbukUCigUCig1WoNJp/r2jUaDap+tjDXrlQqIQiCfr9V2wFAo9GYbddqtUhKSkLHjh3h7OwMURQNthcEAUql0qiP5tptYUxVqVQqjqmGMVVUVODcuXPo2LGjvs3ex+SIcWrKMWk0Gpw9e1afA44wJlN955hM9123AkCHDh0gVFn2oS5jUqlELFggXVnumWeU2LpVev4ffwDduol49lkRL74oICNDwBdfaHHxItCuHTBpkhZRUTYcp6QkKKdMAfLzIXh7Q7NqFcQuXQz6qI+TKEJx550QEhOBq1elvicnQxkZCdx0k65DwKZN0ISFWW9MNbRrtVqcP38ekZGRqH48U45/T9W3r4nNFMB5eXnQaDQIDAw0aA8MDMSZM2dMPmfo0KFYtmwZBg4ciIiICOzYsQObN2/WvzCW7BMAli5diiVLlhi1JyYmwsPDAwDg7++PiIgIXLhwAbm5ufptQkJCEBISgnPnzqGwsFDfHh4ejoCAAJw4cQIlJSX69qioKPj4+CAxMdEgoN27d4ezszPi4+MN+hAbG4vy8nIcP34coiiioKAAxcXF6N27NwoLCw3G5ebmhujoaOTl5SElJUXf7u3tjc6dOyMjIwPp6en6dlsYk45SqURcXBzHVMOYUlNTkZaWhqKiIgiC4BBjcsQ4NeWYlEqlQQ44wpgcMU5NNSZPT09cu3YNGRkZyMzMtHhMq1eH48CBAMyYUY7MTGeUlwtYulTAZ59pcfWqAIVC0F9N7p13lPjkk3JMnaq0yTh1njULeXfdBc8nn0TA7t0oGzsWx6ssfFw1Tv5ffw03Ly/4ajQoLymBs7Mz/vnnH3Rzd0f8Z58ZjqnKWG0p90RRhFqthiiK/HsqLzeYAlsbm5kCkZGRgeDgYOzbtw99+/bVt8+bNw+7du3CwYMHjZ6Tm5uL6dOn45dffoEgCIiIiMCQIUOwevVqlJSUWLRPwPQR4NDQUOTn5+sPqVv7U45Go4FGo0FCQgJiYmLg4uJi95/cHPHTaFOOSfcNR0xMDJRKpUOMyRHj1JRjUqvViI+P1+eAI4zJVN85JtN912g0SExMRExMjMEcUEvHVFSkweuvC1i2TEBFhZmFhCFCoQDOnAHat6//mERRhCAITROn7Gwoo6KgycmBwtkZCkGA2Lo1NDt36ic96+N07BiUs2ZB88UXUPbpY3gEODYWmry8RotTU+aerg6Ii4szipQc/56uXr0KX19f+5oC4efnB6VSiezsbIP27OxsBAUFmXyOv78/fvzxR5SWliI/Px9t2rTB/PnzER4ebvE+AcDFxQUuLi5G7SqVyuj66brgVacLRl3bzV2XvbZ2XRLq7pva3lwf69veXGOqimOquV0X/6r7s/cxOWKcmmpMVQuJ6o/b65jq284xSe312d5c3728lHjjDekEumHDgIsXTW0lQBCA1auBpUvrN6aioiJ8/vnnmDlzJjw9PWsdU73jlJkJtG4NVZWpkULbtlBlZEhn+elUVEA1YwawahVUuv/r//0GRaVSAcXFUPXtK50hOHIk8OKLNp17QtW+myD3vydzbOa0QWdnZ/Tq1Qs7duzQt2m1WuzYscPg6K0prq6uCA4Ohlqtxvfff48RI0Y0eJ/2QKFQIDw83GSSkeNj/Ik5IG9NFf+oKKBv38a/mtyFCxdQXl6OrKwsbNiwwWjOarNZsgS4/36gc2fjx1q3Bi5flpbL2L4d2LNHWibDRvE9wHI29YrNmTMHK1euxLp163D69GnMmDEDxcXFmPzvEicTJkwwOKHt4MGD2Lx5M1JSUrBnzx4MGzYMWq0W8+bNq/M+7ZlCoUBAQAATX6YYf2IOyFtTxr+2q8lt2SKtIHH9et33eenSJfj5+eGHH36AVqvFtWvXDKYbNlhdL7Sxaxfw4YfSIPv3B4qKpPu5uYCLi7ReMQC0aiVdVcSGL7TB9wDL2dQrNnr0aLzzzjtYtGgRevTogaNHj2Lbtm36k9jS0tIMJvqXlpZi4cKF6NKlC0aNGoXg4GDs3bsXPj4+dd6nPdNoNDh27JjRXBiSB8afmAPy1pTxr+1qcmVlwIsvAu3bA8uWSVeXq01aWhquXbsGlUoFQRDw3nvv1bgiU73V9UIbe/ZI8ztSU4G9e6Wry6WmAv7+QE4OUFFROcjNm236Qht8D7CczZwEZ8tsdR1g3QkwsbGx9Zr3Qo6B8SfmgLw1dfzXrgWmTpWmQuhWgRBF4JZbgH37Ki/IBkgzB158UbqehYlTaHDt2jUsW7ZM/7Ofnx9uvvlmREdHN27fz56VJjHn50uF7Zo10oUzpk0D7rtPulWVmipdDq+gQPp582Zg0SLp0nlqNTB4MPDOO6YHZQP4HmDILtcBJiIiItsxaZI0Q2DVKqlODAuTCuIOHaQ6c8kS4JtvpKI4MxOYNQt46y2pfpw4EbhwQTpZLjUVCA/PgLMzEBQUhMGDBxutXdxoIiMBU0eVv/jC9PZhYZXFLyDNDb7//sbvF9kcFsBERERkUocOwNKlxu2RkcD69cCCBcDixcAPP0jtaWnSwdYXXpCm1CoUuqPHkXBzexYfftgCHTs27xiITOEUiDqw1SkQoiiisLAQ3t7eTfNJmmwa40/MAXmzpfjHx0tHfv/3v5q3Uyiko8fVp+WSZWwpB2xBfeo1mzoJjupHEAT4+Pgw6WWK8SfmgLzZUvxjY4GtW6VzyqovulCVIEhTKqhx2FIO2BsWwHZMrVbj8OHD9br2NTkOxp+YA/Jmi/Hv1086Sc7cqlwaDbBzZ+VKZY1Nbqsh2GIO2AsWwHZObn/sZIjxJ+aAvNli/MPCzF9EAwAOHJAutrFmTeWKY41BFEV8+umnOHr0aOPt1A7YYg7YAxbARERE1GhqW0MYAJKTpe0iI6UFGsrLgaQk6aS6sWOlf5OS6vd7r169ivz8fAiCgHXr1iE3N9fyQZDDYwFMREREjaZjR2mer0IhLadb9d/nn5eW1tW5cAGYPl1aRzgyEnj7beDbb6V/o6KktYjr6tKlSwCAAwcO6Avhq1evNu7gyGFwFYg6sOVVIEpKSuDm5sYJ8DLE+BNzQN5sPf7nz5teQxiQTpb7v/8Dfv+95n3UZ9WIX3/9FSdOnIBarUbHjh1x/vx5tG7dGlOmTLFsAElJ0oLGeXmAt7dUjXftarjN/v3AjBnS/YoKaeHkDz6QLpyxcydw111SZV91ezc3y/pjgq3nQHOrT73GArgObLkA1mg0UCqVTHwZYvyJOSBvjhD/AweAhx8GUlJMP65QAI89BnzySe37evfdd3H9+nUAQIsWLdC7d2/06tUL7u7ulnVu8GBgwgTpiiCbNgFvvgkcPmy4zY0bgJOTdNNqgQceAAYOBJ55RiqAn34aaMI5yY6QA42Jy6DJhEajQXx8PCfAyxTjT8wBeXOE+N98M9C7t/lVI7Ra4NNPgbg44I03DOcFV58zXFx8Ax4eHhg5ciRmz56NAQMGWF785uRIixs/8oj08wMPAJcuSYe1q3J3l4pfQJrIXFJS8xmAjcwRcsBaeCU4IiIispraVo0ApFo0Pl4qdLt3B8LDgZ9/lp4nXWkOUCjm47PPVIiOboQC9NIlaWKy6t8ySRCkBY7T0oznY6SmAiNGSGf23XMP8MQTlY8lJwMxMdIk6MmTDR8jq+IRYCIiIrKamlaNEASgSxfDtuPHgR9/lI4OazSV/1ZUOGHaNMHoIG2TCwsDjh0DsrKAsjJg82apPSYGSE8HEhKka0WvWCGd4Uc2gQUwERERWU1Nq0asXg2cPCkdSH3rLaBPn5r31WhXmgsNBTIzK6/YIYrS0d+aLnPXogUwZgzw3/9KP3t5SSfPAUBIiDRXY8+eRugcNQYWwHZMqVQiNjYWSqXS2l0hK2D8iTkgb44U/0mTpNUennsOeOgh6d+zZ6V2QJry8Nxz0klz991nfsqEVistrdZgAQHSEdyvv5Z+/v57qYitPv3h/PnKq3mUl0tHert3l37OzJQ6BADXrgG//gr07NkInavkSDnQ3DgH2M6Vl5fDrRGXVCH7wvgTc0DeHCn+HToAS5fWvl2XLsCWLdK0h+pEUVpiLTkZiIhoYIc++0yqwF9/XTqau2aN1D5tmlSF33cf8Oef0rJnSqV0tPj224GXXpK2+/576Qw+lUp67D//keYBNzJHyoHmxGXQ6sBWl0FTq9WIj49HbGwsVCp+lpEbxp+YA/Im1/gnJUkXydAdXDXFwwNYtky6yMb589JUCt16xFOmSNMuHIFcc8AcLoNGREREDqmmOcP+/tI2xcXS+sE9ekjFckOuMEeOiQUwERER2RVzc4ZTUoBHH63c7vhx49UitFrpqnTNvloE2RQeL7dznPgub4w/MQfkTc7xNzdn+LPPpOm5Dz0kXajNFN1qEXWZc2zr5JwDDcE5wHVgq3OAiYiIyLT775cWZTBFoZAK5A0bzD8/JycHTk5OaNmyZdN0kBod5wDLhCiKKCgoAD/DyBPjT8wBeWP8axYZKc0NNkUQpBPiavLDDz/gwIEDKC0thbamM+6siDlgORbAdkyj0eDMmTO8BrhMMf7EHJA3xr9mNV1hTqORrllhTllZGbKzs9GiRQu8//77OHr0aJP0saGYA5ZjAUxEREQOx9RqEVXNmAEUFJh+bnp6OkRRREJCAtzd3eHm5oa///6bR1odCAtgIiIickjVV4sYPx7w9JQe278fuO02IDfX+HlpaWkQBAHXr18HAHz77bdISkpiAexAuAqEHRMEAW5ubhDMXROSHBrjT8wBeWP866b6ahHHjgF33CEVvkePAgMHAp9/DmzdWnmxDF/f4xBFEWq1Gv7+/hg+fDjatWtnc681c8ByXAWiDrgKBBERkeM4e1a6avHly5VtSqU0Z1gQgEceWYeoKGD69Hvh6+trvY5SvXAVCJnQarXIycmx2bNTqWkx/sQckDfG33KRkcCePUBoaGVb1YtlrFs3ES++OBFXr9p28cscsBwLYDum1WqRkpLCxJcpxp+YA/LG+DdM+/bAiBHmH9ddLMOWMQcsxwKYiIiIZCkvz3h1CB1RlOYEk2NiAUxERESyFBYmHek1RauVLqXMM6UcEwtgOyYIAry9vXn2p0wx/sQckDfGv+FqulgGAPz8M3DffUB6evP1qT6YA5bjKhB1wFUgiIiIHNPatcDUqdKRYN0qENUvrObpCbz1FvDoo+anTJD1cRUImdBqtUhPT+fkd5li/Ik5IG+Mf+OofrGM554DkpKAzZuBoCBpm2vXpCvH3XYbcO5cI/3ipCTglluATp2AuDjg5Enjbf78E+jdG+jSBejaFZg3T5qbAQCpqRCVSpR37QqxRw+gRw8gObmROuf4WADbMb75yRvjT8wBeWP8G4/uYhkbNkj/dugAjBoFnDolHR3W2b0b6N4dePNNQK1u4C997DHpkPK5c8Dzz0uVeHUtWwLffCN15MgRYN8+4MsvKx/39ETCqlXQxMdLV/WIiGhgp+SDBTARERGRCS1bAl98AWzfLi2bBgBlZcD8+UCfPsBPPwELFgBjx0r/JiXVccc5OUB8PPDII9LPDzwAXLoEnD9vuF3PnkB4uHTf1VU6ysulKRoFC2AiIiKiGtx+O/DPP8CcOZVzgBMSgJEjpaPB334LvP02EBUlzSmu1aVLQOvWgEol/SwIQNu2QFqa+edkZQGbNgH33lvZVlyMm6ZMgTIuDnjlFePJy2QWC2A7plAo4O/vDwVn5MsS40/MAXlj/JuXhwfw7rvSLIQOHSrbRbHyCnJarTRlovqB3AYrKgKGD5fmAMfGSm2tW0O8dAnZv/wC8Y8/pEvbvftuI/9ix8W/GjumUCgQERHBNz+ZYvyJOSBvjL919OkjzQ82t/JYna4gFxoKZGZWTiQWRenob9u2xtteuwYMGyZdtm7OnMp2FxcogoKkHPDzk9Z027PHojHJEf9q7JhWq0VycjJPgJApxp+YA/LG+FvPpUvmC+A6XUEuIACIiQG+/lr6+fvvgZAQw0PLAHD9ulT8DhsGLFxo+FhODrRlZVIOlJRIy1b07GnJcGSJBbAd02q1yM3N5ZufTDH+xByQN8bfemq6gpwgSI/X6rPPpFunTsAbbwBr1kjt06ZJV+AAgPffBw4dkopb3VJnr70mPbZ3L4RevRA0bBiE2FhpzbYXX2zQuOTE5grgjz/+GGFhYXB1dUWfPn1w6NChGrdfvnw5IiMj4ebmhtDQUDzzzDMoLS3VP/7yyy9DEASDW1RUVFMPg4iIiBxUTVeQ080DrlVkJLB/v7QMWnw80K2b1P7FF9Ll5wCpoK2okJY40910Re7990Nz9Cj++eoraI4dAz78EHBxadjAZMSmCuCNGzdizpw5WLx4MRISEhAdHY2hQ4ciJyfH5Pbr16/H/PnzsXjxYpw+fRqrVq3Cxo0b8cILLxhs17VrV2RmZupve/fubY7hEBERkQPq2FGa56tQAEql4dXhBKER1gimJmdTBfCyZcswffp0TJ48GV26dMGKFSvg7u6O1atXm9x+37596NevH8aNG4ewsDDceeedGDt2rNFRY5VKhaCgIP3Nz8+vOYbT5BQKBUJCQngChEwx/sQckDfG37qqX0Guf3+pXasF5s5tnj4wByynsnYHdMrLy3HkyBEsWLBA36ZQKDBkyBDs37/f5HNuueUWfP311zh06BB69+6NlJQUbN26FePHjzfYLikpCW3atIGrqyv69u2LpUuXoq2pMy3/VVZWhrKyMv3PRUVFAAC1Wg31vx/rFAoFFAoFtFqtwfwrXbtGo4FY5fsRc+1KpRKCIOj3W7UdADTV1vSr3h4UFAStVguFQgFRFA22FwQBSqXSqI/m2m1lTDoqlYpjqmFMQGX8dTlg72NyxDg15ZgEQTDIAUcYk6m+c0zmxxQSEgKtVmvwe+19TPYUp7AwDf7v/6S2khIBXbookZ4ObNkCbN2qwZ13ik0+puDgYMbp3/bq29fEZgrgvLw8aDQaBAYGGrQHBgbizJkzJp8zbtw45OXloX///hBFEWq1Go8//rjBFIg+ffpg7dq1iIyMRGZmJpYsWYIBAwbgxIkT8PT0NLnfpUuXYsmSJUbtiYmJ8PDwAAD4+/sjIiICFy5cQG5urn6bkJAQhISE4Ny5cygsLNS3h4eHIyAgACdOnEBJSYm+PSoqCj4+PkhMTDQIaPfu3eHs7Iz4+HiDPsTGxqK8vBzHjx+HKIooLi6Gl5cXevfujcLCQoPXys3NDdHR0cjLy0NKSoq+3dvbG507d0ZGRgbS09P17bYwJh2lUom4uDiOqYYxpaSkIDU1FR4eHvr/CO19TI4Yp6Yck0qlwu7du/U54AhjcsQ4NdWYvLy8IAgCPDw8kJGR4RBjsvc4vfFGtP7ibrNmleHLL4/D19d4TCUlJXByckL//v0bNCZRFOHq6oru3bszTuXlSExMRF0JYtWS24oyMjIQHByMffv2oW/fvvr2efPmYdeuXTh48KDRc3bu3IkxY8bg1VdfRZ8+fXD+/HnMnj0b06dPx0svvWTy9xQUFKBdu3ZYtmwZppqZpW7qCHBoaCjy8/Ph5eUFwPqfcjQaDTQaDRISEhATEwMXFxe7/+TmiJ9Gm3JMum9NYmJioFQqHWJMjhinphyTWq1GfHy8PgccYUym+s4xme67RqNBYmIiYmJiDL4Ct+cx2XucBEGJW24RcfCg9IH0gw80eOIJGI3pl19+QX5+Ph555BFUVFTAzc3NojHp6oC4uDhUJ8c4Xb16Fb6+vigsLNTXa+bYzBFgPz8/KJVKZGdnG7RnZ2cjKCjI5HNeeukljB8/HtOmTQMAdOvWDcXFxXj00Ufx4osvGrwh6Pj4+KBTp044X8NlWlxcXOBi4kxKlUoFlcrwJav6dXRVumDUtb36fuvarktC3X1T25vrY33bm2tMVXFMNbfr4l91f/Y+JkeMU1ONSbeyTfUcqGl7Wx9Tfds5Jqm9Ptvby5jsNU7LlwvQHcdbskSJRx4BWrY07Pvly5fRtm1bfP755wgLC8N9ulUfLBiT7tsfxsl8uyk2M2va2dkZvXr1wo4dO/RtWq0WO3bsMDgiXNWNGzeMXmDdi2juwPb169eRnJyM1q1bN1LPiYiIiCQ33wyMGyfdz8+Hfo6wTnFxMfLz83Hp0iWUlpaiffv22Lp1K27cuNH8nZUxmymAAWDOnDlYuXIl1q1bh9OnT2PGjBkoLi7G5MmTAQATJkwwOElu+PDh+PTTT/HNN9/gwoUL+OOPP/DSSy9h+PDh+kJ47ty52LVrF1JTU7Fv3z6MGjUKSqUSY8eOtcoYG5NCoUB4eLjJT1nk+Bh/Yg7IG+Nvu954A9DNavjwQ2mpXx3dnNn8/Hy4urpi8+bNuHTpktkDdzVhDljOZqZAAMDo0aORm5uLRYsWISsrCz169MC2bdv0J8alpaUZBHnhwoUQBAELFy7E5cuX4e/vj+HDh+M13VVSICXa2LFjkZ+fD39/f/Tv3x8HDhyAv79/s4+vsSkUCgQEBFi7G2QljD8xB+SN8bddoaHS8mivvCKtCXzPPUBsrHSFuIiIBADSN9V+fn4YPnw4wsLC9FMZ6oM5YDmbOQnOlhUVFcHb27tOk6qbk0ajwYkTJ3DTTTeZnT9DjovxJ+aAvDH+tq24GAgJAQoKpJ8FQbpgxsCBf+HOO1MxbdrwBl+XgDlgqD71mk0dAab6EUURJSUlFn1tQvaP8SfmgLwx/rYtIwOosuIXRBHQaIC//roNu3YBDz4INPS6XMwBy3HSCBEREVEjW73a8BLJVQmCdCllsh4WwERERESNLDVVOupriihKj5P1sAC2Y0qlElFRUZz3I1OMPzEH5I3xt21hYdKRXlMEQXq8oZgDluNJcHVgqyfBERERkW1KSgKiooAqF0TTUyiAs2eBDh2av1+OrD71Go8A2zG1Wo3Dhw8bXSqQ5IHxJ+aAvDH+tq1jR2mer0IBVD9AO3Nm4xS/zAHLsQC2c9Wvh03ywvgTc0DeGH/bNmmSdKT3ueeAgQMr2w8eND8/uL6YA5ZhAUxERETURDp0AJYuBXbuBLp1k9oOHQJ27bJqt2SPBTARERFRExMEYP78yp+XLrVeX4gnwdWJrZ4Ep1sA283NzaJLKJJ9Y/yJOSBvjL/9UauBTp2ACxekn48cAWJiLN8fc8AQT4KTEWdnZ2t3gayI8SfmgLwx/vZFpZLmA+u8+WbD98kcsAwLYDum0WgQHx/PCfAyxfgTc0DeGH/7NHkyEBgo3d+0SVouzVLMAcuxACYiIiJqJq6uwNNPS/e1WuDtt63aHdliAUxERETUjGbMAHRTVNetAzIyrNsfOWIBTERERNSMvL2BJ56Q7peXA++9Z93+yBFXgagDW14FQqPRQKlU8uxPGWL8iTkgb4y/fcvKAsLCgLIyoEULIC0NaNmyfvtgDhjiKhAyUl5ebu0ukBUx/sQckDfG334FBQFTpkj3r18HPv7Ysv0wByzDAtiOaTQaHD9+nGd/yhTjT8wBeWP87d/cuYDi30rs/feBGzfq93zmgOVYABMRERFZQXg4MHq0dD8vD1i1yrr9kRMWwERERERWUvXyyAsXSgXxggUNWx+YascC2M4plUprd4GsiPEn5oC8Mf72r3t3oFs36X5REfDdd9LawFFRwNq1tT+fOWAZrgJRB7a6CgQRERHZt6QkqdjVao0fUyiAs2eBDh2av1/2iKtAyIQoiigoKAA/w8gT40/MAXlj/B3D6tWAuRXMBKHmecHMAcuxALZjGo0GZ86c4dmfMsX4E3NA3hh/x5CaCpirX0VRetwc5oDlWAATERERWUlYWM1HgMPCmrM38sECmIiIiMhKpkyp+Qjw1KnN2x+5YAFsxwRBgJubGy9/KFOMPzEH5I3xdwwdO0rzfBUKwyPBuvm/NZ0AxxywHFeBqAOuAkFERERN6fx5aU3g77+Xfp4yhRfGqC+uAiETWq0WOTk50JpaO4UcHuNPzAF5Y/wdS4cOwGefVf584kTtz2EOWI4FsB3TarVISUlh4ssU40/MAXlj/B2Pry/QpYt0PyEBKC6ueXvmgOVYABMRERHZiP79pX/VauDAAev2xZGxACYiIiKyEQMGVN7fs8d6/XB0LIDtmCAI8Pb25tmfMsX4E3NA3hh/x1S1AN67t+ZtmQOW4yoQdcBVIIiIiKi5tG0LXLoEuLsDBQWAk5O1e2QfuAqETGi1WqSnp3Pyu0wx/sQckDfG33Hp5gHfuAEkJprfjjlgORbAdoyJL2+MPzEH5I3xd1x1nQfMHLAcC2AiIiIiG1KfecBkGRbARERERDakSxegZUvp/t69AM/WanwsgO2YQqGAv78/FAqGUY4Yf2IOyBvj77gUCqBfP+l+Xh5w5oy57RRoU1wM5cCBQKdOQFwccPKk8YapqcCgQYC3N9Cjh+FjO3cCbm5Su+5WUtJII7Fd/KuxYwqFAhEREXzzkynGn5gD8sb4O7a6zANWKBRo+9prEB59FDh3Dnj+eWDSJOMNvbyAV18F1q83vaPISODo0cqbm1vDOm8H+Fdjx7RaLZKTkzn5XaYYf2IOyBvj79jqMg9Ym5UF7aFD0I4bJzU88IC0ftr584YbtmolLS3h4dE0nbVDNlcAf/zxxwgLC4Orqyv69OmDQ4cO1bj98uXLERkZCTc3N4SGhuKZZ55BaWlpg/ZpL7RaLXJzc/nmJ1OMPzEH5I3xd2y9egGurtJ9c0eAtRcvoszXF1rdtwCCIC0inJZWv1+WnAzExEhTKD75xPJO2xGbKoA3btyIOXPmYPHixUhISEB0dDSGDh2KnJwck9uvX78e8+fPx+LFi3H69GmsWrUKGzduxAsvvGDxPomIiIiszdkZ6NNHup+aCqSnN9EviomRdp6QAPzwA7BiBfDtt030y2yHTRXAy5Ytw/Tp0zF58mR06dIFK1asgLu7O1avXm1y+3379qFfv34YN24cwsLCcOedd2Ls2LEGR3jru08iIiIiW1DrPODQUDjl5QFqtfSzKEpHf9u2rfsv8fKSTo4DgJAQYOzYmhcfdhAqa3dAp7y8HEeOHMGCBQv0bQqFAkOGDMH+/ftNPueWW27B119/jUOHDqF3795ISUnB1q1bMX78eIv3CQBlZWUoKyvT/1xUVAQAUKvVUP+bZAqFAgqFAlqt1uDrJ127RqNB1atMm2tXKpUQBEG/36rtAKDRaMy2a7VatGnTRv/7RVE02F4QBCiVSqM+mmu3hTFVpVKpOKYaxgRAH3+1Wu0QY3LEODXlmARBMMgBRxiTqb5zTKb7LooiQkJCAMDg99rzmBwxTg0Z0y23AIDUh927RYwdKxiMSevnB2337nBevx7qCRMgfP89FMHB0ISFQfnvNgZ91GikI59V+56ZCQQGQuXsDLGoCPjlF2gnT4aoVttdnKpvXxObKYDz8vKg0WgQGBho0B4YGIgzZtb/GDduHPLy8tC/f3+Iogi1Wo3HH39cPwXCkn0CwNKlS7FkyRKj9sTERHj8O4Hc398fERERuHDhAnJzc/XbhISEICQkBOfOnUNhYaG+PTw8HAEBAThx4gRKqiwvEhUVBR8fHyQmJhoEtHv37nB2dkZ8fLxBH2JjY1FeXo7jx4/r27KzsxEXF4fCwkKDcbm5uSE6Ohp5eXlISUnRt3t7e6Nz587IyMhAepXvVGxpTEqlkmOqZUwXL15Ebm4uMjIyHGZMjhinph5TRkaGPgccZUyOGKemHFN6errDjckR42TJmJydr0GhiINWK2DXLg0AldGYunzwAVyfegrlL78MtYcHkl98ESXx8YhdsQLCiBGIb90aitJSRD/0EBQVFVAUF0MMCUH27bfj0hNPIPC77xD0ww9QeXpCW16OzH79kH7TTUB8vN3FKbGm60ZXI4hVS+56EkURn3/+OVatWoWUlBRcvXrV+BeYqOBNycjIQHBwMPbt24e+ffvq2+fNm4ddu3bh4MGDRs/ZuXMnxowZg1dffRV9+vTB+fPnMXv2bEyfPh0vvfSSRfsETB8BDg0NRX5+Pry8vABY/1OO7ghwUlISOnbsCGdnZ37CltmYKioqcO7cOXTs2FHfZu9jcsQ4NeWYNBoNzp49q88BRxiTqb5zTKb7rlsFokOHDhAEwSHG5IhxauiYevdWIjFRgCCIyM8X4OVV5QiwVovz588jMjLSYJy2Pqba2i2N09WrV+Hr64vCwkJ9vWZOg44Az5s3D8uWLUOPHj3wyCOPoKXusiUW8PPzg1KpRHZ2tkF7dnY2goKCTD7npZdewvjx4zFt2jQAQLdu3VBcXIxHH30UL774okX7BAAXFxe4uLgYtatUKqhUhi9Z1a+jq9IFo67t1fdbl3a1Wo1r167pf78gCCa3N9fH+rY3x5iq45jMtwuCoI9/1f3Z85gcMU5NPSZTOWBue3sZkyPGqSnGpFarUVhYWO/XwJbHZGm7I49p4EAgMREQRQF//w3ce2/lmNRqNYqKiiCKol2Nqa7tjTEmcxpUAK9btw4PPPAAvm2EswWdnZ3Rq1cv7NixAyNHjgQgfbLZsWMHZs2aZfI5N27cMHqBdS+iKIoW7ZOIiIjIVgwYALz/vnR/zx7g3nut2x9H0aACuKSkBEOGDGmsvmDOnDmYOHEiYmNj0bt3byxfvhzFxcWYPHkyAGDChAkIDg7G0qVLAQDDhw/HsmXL0LNnT/0UiJdeegnDhw/XF8K17ZOIiIjIVvXvX3nf3AUxqP4aVADffvvtOHz4MB599NFG6czo0aORm5uLRYsWISsrCz169MC2bdv0J7GlpaUZHPFduHAhBEHAwoULcfnyZfj7+2P48OF47bXX6rxPe6ZQKBAeHm7yawZyfIw/MQfkjfGXh8BAoGNHICkJOHwYKCmpvFJxSUkJkpOTERMTY91O2qEGnQSXkZGBoUOHYuzYsXjsscfg6+vbmH2zGUVFRfD29q7TpGoiIiKixjR1KqC7fMHOncCtt0r3jx49ip9++gkzZszApUuX0KtXL6v10RbUp15r0MfGyMhIpKSk4KWXXkJAQAA8PDzg5eVlcPPWLa5MjU6j0eDYsWNGZ0OSPDD+xByQN8ZfPsxdECMtLQ2enp74/vvvceDAgebvmB1r0BSIBx54wGDpFWpeoiiipKTEaOkTkgfGn5gD8sb4y0fVArjqPOBLly6hoqICpaWl6Nu3L1asWIHY2FjExsY2fyftTIMK4LVr1zZSN4iIiIjIlPBwICgIyMoC9u0DNBqgvLwEeXl5AKSVtPbs2YPOnTujQ4cOVu6tfbCZK8ERERERkTFBkI4Cf/cdcO0acM89QK9eZ+HsLK3d26NHD9x8880Nuh6D3DS4AC4qKsJ7772HLVu24OLFiwCAdu3a4d5778XTTz/Nk8aakFKpRFRUlNkFpMmxMf7EHJA3xl9enJwq7//+O7BnTyRuueUW3HdfLwwb1pJTUuupwatADBgwABcuXEBUVBSioqIAAGfPnsXp06cRHh6OPXv2oHXr1o3WYWvgKhBERERkLUlJQFQUUOXqwnoKBXD2LMCZD824CsTzzz+PrKws/Prrrzh16hQ2b96MzZs34+TJk9iyZQuysrIwf/78hvwKqoFarcbhw4eNrpVN8sD4E3NA3hh/+Vi9WpoGYYogiFi50kRlTDVqUAG8bds2PP3007j77ruNHrvrrrvw1FNPYevWrQ35FVQLLn8jb4w/MQfkjfGXh9RUwNz39aII/DsDleqhQQVwcXFxjVdUCwoKQnFxcUN+BREREZGshYWZPwIMAO3aNVtXHEaDCuAuXbpgw4YNKC8vN3qsoqICGzZsQJcuXRryK4iIiIhkbcoUc0eApcbJkzkFor4atArE888/j9GjR6N379544okn0KlTJwDSSXArVqzA8ePHsXHjxkbpKBlTKpXo3r07zwCWKcafmAPyxvjLR8eOwKpV0iWRq54Ip1AAn3xSjshIZ+t1zk41aBUIQLoYxvz585GTk6NfgkMURQQEBODNN9/ExIkTG6Wj1mSrq0CIogiNRgOlUsnlT2SI8SfmgLwx/vJz/jwweDBw6ZL0865dIm65hTmg02yrQADApEmTkJ6ejn379mH9+vVYv3499u3bh/T0dIcofm2ZRqNBfHw8T4KQKcafmAPyxvjLT4cOQNXS6uJFLXPAQo1yJTiVSoWbb74ZN998c2PsjoiIiIhMGDiw8v7evQI6drReX+xZvQrg3bt3AwAG/vvq636uzcCq0SIiIiIii/TtCyiVgEYjFcCTJ1u7R/apXgXwoEGDIAgCSkpK4OzsrP/ZHFEUIQgCD80TERERNYIWLYCYGODwYeDUKQEFBY3yZb7s1OtV++uvvwAAzs7OBj+TdSiVSsTGxvIMYJli/Ik5IG+Mv3wNHCgVwABQXNwTSmWDT+mSnXoVwLfeemuNP1PzKy8vh5ubm7W7QVbC+BNzQN4Yf3kaOBB4913p/s6dWtx/Pwvg+mqSVywlJQWnT59uil1TFRqNBsePH+cUE5li/Ik5IG+Mv3z161d5f8eOMuaABRpUAH/wwQcYM2aMQdvkyZPRsWNH3HTTTYiNjUVOTk6DOkhERERElXx9gZtuku6fPeuBa9es2x971KAC+IsvvkBgYKD+599++w3r1q3Do48+ig8//BApKSlYsmRJgztJRERERJUGDJD+1WoFHDjAi2DUV4NOHbx48SI6d+6s//nbb79F+/bt8emnnwIAsrKy8NVXXzWsh1Qjnvwgb4w/MQfkjfGXr4EDgX/LLezZI+Cuu6zbH3vToAK4+lWUf//9d4wYMUL/c1hYGLKyshryK6gGKpUKcXFx1u4GWQnjT8wBeWP85U13BBgA9u7lSXD11aBXrFOnTvjhhx8ASNMfMjIycFeVjyDp6enw8fFpUAfJPFEUUVBQYPRBhOSB8SfmgLwx/vIWHAyEh0uxP3RIRGmplTtkZxpUAM+dOxd//PEHWrZsieHDh6Nz584YOnSo/vE///wTPXr0aGgfyQyNRoMzZ87w7E+ZYvyJOSBvjD/17y8VwGVlgn5dYKqbBk2BGDNmDHx9fbF161b4+PjgiSeegEol7fLKlSto1aoVxo8f3ygdJSIiIqJK/fuL+PJL6f6ePYbTIqhmDb5+3h133IE77rjDqL1Vq1bYvHlzQ3dPRERERCYMGFA5/WX3buCFF6zYGTvDWdN2TBAEuLm5QRC4/IkcMf7EHJA3xp86dBDg718BAPj7b0CttnKH7Igg1mP2fPv27aFQKHDmzBk4OTmhffv2tf7hCYKA5OTkBnfUmoqKiuDt7Y3CwkJ4eXlZuztEREREAIDRo4Fvv5Xux8cDvXpZtz/WVJ96rV5TIG699VYIggCFQmHwM1mHVqtFXl4e/Pz89DEh+WD8iTkgb4w/abVa9OxZjG+/9QQgTYOQcwFcH/UqgNeuXVvjz9S8tFotUlJS0KpVK775yRDjT8wBeWP8SavVIiQkBUA0AKkAfuYZ6/bJXvAvhoiIiMhOhYeXoGVLaTbrnj0Al4WumwYVwBs2bMCkSZPMPj558mR8q5uYQkRERESNSqEA+vWTqt78fOD0aSt3yE40qAB+77334OLiYvZxNzc3vPfeew35FVQDQRDg7e3NedgyxfgTc0DeGH/S5UD//pVte/ZYrz/2pEEF8NmzZ9GzZ0+zj0dHR+PMmTMN+RVUA6VSic6dO0OpVFq7K2QFjD8xB+SN8SddDgwaVFnO7d5txQ7ZkQYVwLrrkJtz9epVVFRUNORXUA20Wi3S09Oh1Wqt3RWyAsafmAPyxviTLgd69NDC3V1q272b84DrokEFcM+ePbFhwwaUl5cbPVZWVob169fXeISYGoZvfvLG+BNzQN4Yf9LlgFKpRd++Ult6OnDxonX7ZQ8aVADPnz8fJ06cwG233YZffvkFKSkpSElJwc8//4xBgwbh5MmTmD9/fmP1lYiIiIhMGDiw8j6nQdSuXusAV3fXXXdh1apVmD17NkaOHKlvF0URnp6eWLlyJe65556G9pGIiIiIalC1AN6zB5gwwXp9sQcNKoABYNKkSbj//vvx+++/IyUlBQAQERGBO++8E56eng3uIJmnUCjg7+/PBdBlivEn5oC8Mf5UNQf69AGcnICKCh4BrgtBFDlVujb1ubY0ERERkTX06wfs2yfdz8wEgoKs25/mVp96rcEfGzUaDb755hs89thjGDVqFP755x8AQGFhITZv3ozs7Ox67/Pjjz9GWFgYXF1d0adPHxw6dMjstoMGDYIgCEa3qlMvJk2aZPT4sGHD6j9YG6PVapGcnMwTIGSK8SfmgLwx/lQ9BwYMqHxs714rdcpONKgALigoQL9+/TBu3Dhs2LABP//8M3JzcwEALVq0wFNPPYX333+/XvvcuHEj5syZg8WLFyMhIQHR0dEYOnQocnJyTG6/efNmZGZm6m8nTpyAUqnEf/7zH4Pthg0bZrDdhg0bLBu0DdFqtcjNzeWbn0wx/sQckDfGn6rnAE+Eq7sGrwJx8uRJ/Pbbb0hJSUHV2RRKpRIPPvggtm7dWq99Llu2DNOnT8fkyZPRpUsXrFixAu7u7li9erXJ7Vu1aoWgoCD97Y8//oC7u7tRAezi4mKwXcuWLes/YCIiIiIb1a8foLswIK8IV7MGnQT3448/4sknn8Qdd9yB/Px8o8c7deqEtWvX1nl/5eXlOHLkCBYsWKBvUygUGDJkCPbv31+nfaxatQpjxoyBh4eHQfvOnTsREBCAli1bYvDgwXj11Vfh6+trch9lZWUoKyvT/1xUVAQAUKvVUKvV+n4pFApotVqDT9+6do1GY/CBwFy7UqmEIAj6/VZtB6QpJubadfvSaDRQqVT6+zqCIECpVBr10Vy7LYypKo6p9jFV3ZejjMkR49RUYxJF0aif9j4mU33nmEz3XbeNVqs1+L32PCZHjFNTjqnqfbVaDQ8PoHt3JY4dE3DsmIirVwFPT/sak66PlsSp+vY1aVABXFhYiPbt25t9vKKiol6dycvLg0ajQWBgoEF7YGBgnS6pfOjQIZw4cQKrVq0yaB82bBjuv/9+tG/fHsnJyXjhhRdw1113Yf/+/SYvIbl06VIsWbLEqD0xMVFfWPv7+yMiIgIXLlzQT/sAgJCQEISEhODcuXMoLCzUt4eHhyMgIAAnTpxASUmJvj0qKgo+Pj5ITEw0CGj37t3h7OyM+Ph4gz7ExsaivLwcx48fByAV68eOHUPv3r1RWFho8Dq5ubkhOjoaeXl5+hU6AMDb2xudO3dGRkYG0tPT9e22MiZASua4uDiOqYYxpaWloaysDImJiQ4zJkeMU1OOSaVSGeSAI4zJEePUVGPy8vJCSEgIsrKykJGR4RBjcsQ4NfWYfH19oVAocOTIEWg0GkRGtsOxY60higL27NEgIMD+xmRpnKq+F9amQatA3HTTTRgwYAA+/fRT5Ofnw9/fH9u3b8fgwYMBAPfccw9yc3NrPImtqoyMDAQHB2Pfvn3oq7ukCYB58+Zh165dOHjwYI3Pf+yxx7B//36DoJqSkpKCiIgIbN++HbfffrvR46aOAIeGhiI/P19/VqG1P+U44ic3jolj4pg4Jo6JY+KYGjam778XMGaM1O9580S89pr9j6m2vuvar169Cl9f3zqtAtGgI8DTpk3D888/j0GDBukLSUEQUFZWhldeeQXbtm3D559/Xuf9+fn5QalUGq0ckZ2djaBa1vIoLi7GN998g1deeaXW3xMeHg4/Pz+cP3/eZAHs4uICFxcXo3aVSgWVyvAl0wWvOlNHlmtqr77furRrNBqcO3cOnTp1AiC99qa2N9fH+rY3x5iq45jMt4uiiKSkJHTq1Mmgv/Y8JkeMU1OOSaPRmMwBc9vbw5jq2y7nMWk0Gpw+fRqdOnWq12tgy2OytF2uY9JoNDhz5oxBDgwaVLntnj2m+wjY7phq66Ml7Sa3rfOWJsyePRsnT57E2LFj4ePjAwAYN24c8vPzoVar8dhjj2Hq1Kl13p+zszN69eqFHTt26K8sp9VqsWPHDsyaNavG53733XcoKyvDI488UuvvSU9PR35+Plq3bl3nvtkiURRRWFho8KmJ5IPxJ+aAvDH+ZCoHAgOByEjg7FkgPh64cQNwd7diJ21UgwpgQRCwcuVKTJw4EZs2bUJSUhK0Wi0iIiLw0EMPYWDV9TjqaM6cOZg4cSJiY2PRu3dvLF++HMXFxZg8eTIAYMKECQgODsbSpUsNnrdq1SqMHDnS6MS269evY8mSJXjggQcQFBSE5ORkzJs3Dx06dMDQoUMtHzwRERGRDRowQCqAKyqAgweB226zdo9sj8UF8I0bN/DII4/ggQcewMMPP4z+/fs3SodGjx6N3NxcLFq0CFlZWejRowe2bdumPzEuLS3N6LD62bNnsXfvXvz+++9G+1MqlTh+/DjWrVuHgoICtGnTBnfeeSf+7//+z+Q0ByIiIiJ7NnAg8MUX0v3du1kAm9Kgk+C8vLzw7rvvYvr06Y3ZJ5tjq5dC1mq1yMvLg5+fn8m5NuTYGH9iDsgb40/mcuDiRSAsTLp/++3A9u3W6V9za7ZLIffv37/O6/NS41MoFAgICOAbn0wx/sQckDfGn8zlQLt2QGiodH/fPqC83Aqds3EN+qv56KOPsGfPHixcuNBgHThqHhqNBseOHTNaDoTkgfEn5oC8Mf5UUw7oTsMqKQESEpq5Y3agQQVwdHQ00tPTsXTpUrRr1w4uLi7w8vIyuHl7ezdWX6kaURRRUlLCM4BlivEn5oC8Mf5UUw4MGFB5n5dFNtagVSAefPDBxuoHERERETWSqgtx7d4NPPec9fpiiywqgEtLS/HTTz8hMjISvr6+uPfee+1+TV0iIiIiRxEVBfj5AXl5wN69gFYLcLp4pXoXwDk5Objllltw4cIFiKIIQRDg7u6OH374AUOGDGmKPpIZSqUSUVFRZq+gQo6N8SfmgLwx/lRTDgiCNA3ihx+AggLgxAmge/fm76Otqvdngf/7v/9DamoqnnnmGfz6669477334Orqiscee6wp+kc1EAQBPj4+EATB2l0hK2D8iTkgb4w/1ZYD1adBUKV6F8C///47JkyYgHfeeQd33303nnrqKXz00UdITU3F2bNnm6KPZIZarcbhw4ehVqut3RWyAsafmAPyxvhTbTlQtQDmiXCG6l0Ap6WlGV31rX///hBFEdnZ2Y3WMaobLn8jb4w/MQfkjfGnmnIgOhrw9JTu794NcMGQSvUugMvKyuDq6mrQpvuZn0KJiIiIbINSCfTrJ93PygKSk63bH1ti0SoQqampSKiyqnJhYSEAICkpCT4+Pkbbx8TEWNY7IiIiIrLYgAHAtm3S/d27gQ4drNsfWyGI9VxBW6FQmJxsrVsRwlSbvX9FU59rSzcn3QLYbm5uPAlChhh/Yg7IG+NPdcmBvXsrL4oxcSKwdm3z9a+51adeq/cR4DVr1ljcMWp8zs7O1u4CWRHjT8wBeWP8qbYciIsDXFyAsjKeCFdVvQvgiRMnNkU/yAIajQbx8fGIjY2FStWgi/qRHWL8iTkgb4w/1SUHXFyAPn2k6Q8pKcDly0BwcDN31AbxmiBEREREDozLoRljAUxERETkwHRzgAFeEEOHBTARERGRA+vbV1oSDWABrFPvVSDkyJZXgdBoNFAqlTwDWIYYf2IOyBvjT/XJgd69gcOHpft5eYCvbzN0sJnVp17jEWA7V15ebu0ukBUx/sQckDfGn+qaA1WnQYwaBSxYACQlNVGn7AALYDum0Whw/Phxu19nmSzD+BNzQN4Yf6pPDlRUVN7fuxd4+20gKsqx1wWuCQtgIiIiIgeWlAR8/HHlz6IIaDSAVgtMnQqcP2+9vlkLC2AiIiIiB7Z6NWBuirAgAKtWNW9/bAELYDun1J3WSbLE+BNzQN4Yf6pLDqSmSkd9TRFF6XG54aVj7JhKpUJcXJy1u0FWwvgTc0DeGH+qaw6EhdV8BDgsrFG7ZRd4BNiOiaKIgoICcCU7eWL8iTkgb4w/1TUHpkyp+Qjw1KlN0DkbxwLYjmk0Gpw5c4ZnAMsU40/MAXlj/KmuOdCxozTPV1Gt6lMopPYOHZqwkzaKBTARERGRg5s0CTh7FnB3l352d5d+njTJmr2yHhbARERERDLQoQPQp490/8YNwMfHqt2xKhbAdkwQBLi5ufESmDLF+BNzQN4Yf7IkB7p2rbx/8mQTdMpOsAC2Y0qlEtHR0VwGR6YYf2IOyBvjT5bkQNUC+NSpJuiUnWABbMe0Wi1ycnKg1Wqt3RWyAsafmAPyxviTJTnAI8ASFsB2TKvVIiUlhW9+MsX4E3NA3hh/siQHunSpvM8CmIiIiIgcnq8vEBgo3WcBTERERESyoJsGkZsr3eSIBbAdEwQB3t7ePANYphh/Yg7IG+NPluYA5wGzALZrSqUSnTt35hnAMsX4E3NA3hh/sjQHWACzALZrWq0W6enpPAFCphh/Yg7IG+NPluYAC2AWwHaNb37yxvgTc0DeGH9iAWw5FsBEREREMtKyJdC6tXT/5ElAFK3bH2tgAUxEREQkM7qjwPn58lwJggWwHVMoFPD394dCwTDKEeNPzAF5Y/ypITkg92kQNvlX8/HHHyMsLAyurq7o06cPDh06ZHbbQYMGQRAEo9s999yj30YURSxatAitW7eGm5sbhgwZgqSkpOYYSpNSKBSIiIjgm59MMf7EHJA3xp8akgMsgG3Mxo0bMWfOHCxevBgJCQmIjo7G0KFDkZOTY3L7zZs3IzMzU387ceIElEol/vOf/+i3eeutt/DBBx9gxYoVOHjwIDw8PDB06FCUlpY217CahFarRXJyMk+AkCnGn5gD8sb4U0NyQO6XRLa5AnjZsmWYPn06Jk+ejC5dumDFihVwd3fH6tWrTW7fqlUrBAUF6W9//PEH3N3d9QWwKIpYvnw5Fi5ciBEjRqB79+748ssvkZGRgR9//LEZR9b4tFotcnNz+eYnU4w/MQfkjfGnhuSA3I8Aq6zdgarKy8tx5MgRLFiwQN+mUCgwZMgQ7N+/v077WLVqFcaMGQMPDw8AwIULF5CVlYUhQ4bot/H29kafPn2wf/9+jBkzxmgfZWVlKCsr0/9cVFQEAFCr1VCr1fp+KRQKaLVag8TTtWs0GohVTqs0165UKiEIgn6/VdsBQKPRmG3X7Uuj0UClUunv6wiCAKVSadRHc+22MKaqOKbax1R1X44yJkeMU1ONSRRFo37a+5hM9Z1jMt133TZardbg99rzmBwxTk05pqr36zumFi00aNNGiYwMASdPihBFAYD1x6TroyVxqr59TWyqAM7Ly4NGo0FgYKBBe2BgIM6cOVPr8w8dOoQTJ05g1apV+rasrCz9PqrvU/dYdUuXLsWSJUuM2hMTE/WFtb+/PyIiInDhwgXkVjl9MiQkBCEhITh37hwKCwv17eHh4QgICMCJEydQUlKib4+KioKPjw8SExMNAtq9e3c4OzsjPj7eoA+xsbEoLy/H8ePHIYoiCgoKcOzYMfTu3RuFhYUGr5Obmxuio6ORl5eHlJQUfbu3tzc6d+6MjIwMpKen69ttYUw6SqUScXFxHFMNY7p48SIKCgqQkJAAQRAcYkyOGKemHJNSqTTIAUcYkyPGqanG5OnpCQD6KYCOMCZHjFNTjkkURX3RZ8mYQkKikJHhgytXBGRnA66u1h9TQ+KUmJiIuhLEqiW3lWVkZCA4OBj79u1D37599e3z5s3Drl27cPDgwRqf/9hjj2H//v0Gibpv3z7069cPGRkZaK1b9A7AQw89BEEQsHHjRqP9mDoCHBoaivz8fHh5eQGw/qccjUYDrVaLrKwsBAUFwdnZ2SY+jTZ0TFXZyidsWx2TWq1GRkYGgoKC9G32PiZHjFNTjkmr1eLy5cv6HHCEMZnqO8dkuu+iKCI7OxtBQUEG+7DnMTlinJpyTFqtFtnZ2QgODjaaBlGXMT37rAIffCC9d2zfDgwebP0x6fpoSZyuXr0KX19fFBYW6us1c2zqCLCfnx+USiWys7MN2k39gVdXXFyMb775Bq+88opBu+552dnZBgVwdnY2evToYXJfLi4ucHFxMWpXqVRQqQxfMl3wqjN3XW5z7dX3W9f2tm3b6tsEQTC5vbk+1re9ucZUFcdkvl2lUhnEX8eex+SIcWrKMSmVSpM5YG57exhTfdvlPqaQkBCT+zW3PWD7Y7KkXc5jCg0N1e+nrn3XtXfrVvnzyZPA7bfbxpjq0vf6tJtiUyfBOTs7o1evXtixY4e+TavVYseOHQZHhE357rvvUFZWhkceecSgvX379ggKCjLYZ1FREQ4ePFjrPm2dRqPB6dOnjT4JkTww/sQckDfGnxqaA3I+Ec6mjgADwJw5czBx4kTExsaid+/eWL58OYqLizF58mQAwIQJExAcHIylS5caPG/VqlUYOXIkfH19DdoFQcDTTz+NV199FR07dkT79u3x0ksvoU2bNhg5cmRzDatJiKKIwsJCg68NSD4Yf2IOyBvjTw3NgapLoZ061UidshM2VwCPHj0aubm5WLRoEbKystCjRw9s27ZNfxJbWlqa0WH1s2fPYu/evfj9999N7nPevHkoLi7Go48+ioKCAvTv3x/btm2Dq6trk4+HiIiIyBZ5ewMhIUB6unQEWBSBf8+ndXg2VwADwKxZszBr1iyTj+3cudOoLTIyssZPP4Ig4JVXXjGaH0xEREQkZ127SgXw1atAVhZQ5XQph2ZTc4CpfhQKBcLDw81OfCfHxvgTc0DeGH9qjByQ6xXh+FdjxxQKBQICAvjmJ1OMPzEH5I3xp8bIAbmeCMe/Gjum0Whw7NgxngEsU4w/MQfkjfGnxsgBFsBkd0RRRElJCc8AlinGn5gD8sb4U2PkAKdAEBEREZGseHkB/15LQ78ShBywACYiIiKSMd00iMJCICPDun1pLiyA7ZhSqURUVJTZSwiSY2P8iTkgb4w/NVYOVJ0HLJcLYrAAtmOCIMDHxweCXFatJgOMPzEH5I3xp8bKATmeCMcC2I6p1WocPnwYarXa2l0hK2D8iTkgb4w/NVYOsAAmu8Plb+SN8SfmgLwx/tQYOdC5c+V9FsBERERE5PA8PYG2baX7clkJggUwERERkczppkEUFQGXL1u3L82BBbAdUyqV6N69O88AlinGn5gD8sb4U2PmgNzmAbMAtnPOzs7W7gJZEeNPzAF5Y/ypsXKABTDZDY1Gg/j4eJ4EIVOMPzEH5I3xp8bMARbARERERCQrclsJggUwERERkcy1aAGEhUn3T51y/JUgWAATERERkX4axLVrQHq6dfvS1FgA2zGlUonY2FieASxTjD8xB+SN8afGzgE5zQNmAWznysvLrd0FsiLGn5gD8sb4U2PmQJculfdZAJPN0mg0OH78OM8AlinGn5gD8sb4U2PnAI8AExEREZGsyGklCBbARERERAQPD6B9e+m+o68EwQLYzvHkB3lj/Ik5IG+MPzV2DuimQVy/DqSlNequbQoLYDumUqkQFxcHlUpl7a6QFTD+xByQN8afmiIH5DIPmAWwHRNFEQUFBRAd+TsKMovxJ+aAvDH+1BQ5ULUAPnWq0XZrc1gA2zGNRoMzZ87wDGCZYvyJOSBvjD81RQ7wCDARERERyUpUFCAI0n0WwERERETk8NzdgfBw6f6pU4BWa93+NBUWwHZMEAS4ublB0H1UI1lh/Ik5IG+MPzVVDuiuCFdc7LgrQbAAtmNKpRLR0dFcBkemGH9iDsgb409NlQNymAfMAtiOabVa5OTkQOuo309QjRh/Yg7IG+NPTZUDLIDJpmm1WqSkpPDNT6YYf2IOyBvjT02VAyyAiYiIiEhWoqIAxb8VIgtgIiIiInJ4bm6VK0GcPu2YK0GwALZjgiDA29ubZwDLFONPzAF5Y/ypKXNANw3ixg3g4sVG373VsQC2Y0qlEp07d+YZwDLF+BNzQN4Yf2rKHHD0ecAsgO2YVqtFeno6T4CQKcafmAPyxvhTU+YAC2CyWXzzkzfGn5gD8sb4Ewtgy7EAJiIiIiIDkZGOvRIEC2AiIiIiMuDqCkRESPcdcSUImyuAP/74Y4SFhcHV1RV9+vTBoUOHaty+oKAAM2fOROvWreHi4oJOnTph69at+sdffvllCIJgcIuKimrqYTQLhUIBf39/KBQ2F0ZqBow/MQfkjfGnps4B3TSIkhLgwoUm+RVWo7J2B6rauHEj5syZgxUrVqBPnz5Yvnw5hg4dirNnzyIgIMBo+/Lyctxxxx0ICAjApk2bEBwcjIsXL8LHx8dgu65du2L79u36n1Uqmxq2xRQKBSJ0H89Idhh/Yg7IG+NPTZ0DXbsCP/4o3T95svKIsCOwqY+Ny5Ytw/Tp0zF58mR06dIFK1asgLu7O1avXm1y+9WrV+PKlSv48ccf0a9fP4SFheHWW29FdHS0wXYqlQpBQUH6m5+fX3MMp8lptVokJyfzBAiZYvyJOSBvjD81dQ448olwNnMotLy8HEeOHMGCBQv0bQqFAkOGDMH+/ftNPufnn39G3759MXPmTPz000/w9/fHuHHj8PzzzxusiZeUlIQ2bdrA1dUVffv2xdKlS9G2bVuzfSkrK0NZWZn+56KiIgCAWq2GWq3W902hUECr1Roknq5do9FAFMVa25VKJQRB0O+3ajsAaDQas+0ajQY5OTkICQmBi4sLRFE02F4QBCiVSqM+mmu3hTFVpVKpOKYaxqRWq/XxVyqVDjEmR4xTU46p6nuAbiz2PiZTfeeYTPddo9EgNzcXoaGhBl+B2/OYHDFOTTkm3XtAu3btjIrgxhhTVJQAQNr+n3+0UKu1TT4mXR8tiVP17WtiMwVwXl4eNBoNAgMDDdoDAwNx5swZk89JSUnBn3/+iYcffhhbt27F+fPn8cQTT6CiogKLFy8GAPTp0wdr165FZGQkMjMzsWTJEgwYMAAnTpyAp6enyf0uXboUS5YsMWpPTEyEh4cHAMDf3x8RERG4cOECcnNz9duEhIQgJCQE586dQ2Fhob49PDwcAQEBOHHiBEpKSvTtUVFR8PHxQWJiokFAu3fvDmdnZ8THxxv0ITY2FuXl5Th+/DhEUURBQQGOHTuG3r17o7Cw0OC1cnNzQ3R0NPLy8pCSkqJv9/b2RufOnZGRkYH09HR9uy2MSUepVCIuLo5jqmFMFy9eREFBARISEiAIgkOMyRHj1JRjUiqVBjngCGNyxDg11Zh0/4dlZmYiMzPTIcbkiHFqyjGJoqgv+ppiTEqlO5TK7tBogCNHShAf/0+TjwmwPE6JiYmoK0GsWnJbUUZGBoKDg7Fv3z707dtX3z5v3jzs2rULBw8eNHpOp06dUFpaigsXLuir/2XLluHtt982eDOoqqCgAO3atcOyZcswdepUk9uYOgIcGhqK/Px8eHl5AbD+pxzdEeCEhATExMTwCLAMx6T71iQmJoZHgGU6JrVajfj4eH0OOMKYTPWdYzJ/BDgxMRExMTE8AizTMenqgLi4OFTXWGPq2lWJs2cBV1cRBQUaKJW2G6erV6/C19cXhYWF+nrNHJs5Auzn5welUons7GyD9uzsbAQFBZl8TuvWreHk5KQfOAB07twZWVlZKC8vh7Ozs9FzfHx80KlTJ5w/f95sX1xcXODi4mLUrlKpjE6g0wWvuqp9qku7uRPzampXKBQIDQ2Fk5MTACkhTW1vro/1bW+OMVXHMZlvV6lU+vhXfdyex+SIcWrKMSmVSpM5YG57exhTfdvlPCaFQoGQkBD9/we1bV9b321hTJa2y3VMujrA3D7M9d1cu6kxde0KnD0LlJYKuHRJhQ4dmnZMlva9pnZTbOYkOGdnZ/Tq1Qs7duzQt2m1WuzYscPgiHBV/fr1w/nz5w0+ZZw7dw6tW7c2WfwCwPXr15GcnIzWrVs37gCsQPfmZy7pybEx/sQckDfGn5ojBxz1RDib+quZM2cOVq5ciXXr1uH06dOYMWMGiouLMXnyZADAhAkTDE6SmzFjBq5cuYLZs2fj3Llz2LJlC15//XXMnDlTv83cuXOxa9cupKamYt++fRg1ahSUSiXGjh3b7ONrbBqNBqdPnzb6KoDkgfEn5oC8Mf7UHDnQpUvlfUcqgG1mCgQAjB49Grm5uVi0aBGysrLQo0cPbNu2TX9iXFpamsGnnNDQUPz222945pln0L17dwQHB2P27Nl4/vnn9dukp6dj7NixyM/Ph7+/P/r3748DBw7A39+/2cfX2ERRRGFhocG8GZIPxp+YA/LG+FNz5ICjHgG2qQIYAGbNmoVZs2aZfGznzp1GbX379sWBAwfM7u+bb75prK4RERERyUqnToBSCWg0jlUA29QUCCIiIiKyHS4uQMeO0v0zZ6RC2BGwALZjCoUC4eHhPAFCphh/Yg7IG+NPzZUDumkQZWVAcnKT/qpmw78aO6ZQKBAQEMA3P5li/Ik5IG+MPzVXDlSdB3zqVJP+qmbDvxo7ptFocOzYMZ4BLFOMPzEH5I3xp+bKAUc8EY4FsB0TRRElJSU8A1imGH9iDsgb40/NlQMsgImIiIhIVjp2BHQXWWMBTEREREQOz9nZcCUItdq6/WkMLIDtmFKpRFRUlNlraJNjY/yJOSBvjD81Zw7opkGUlzvGShAsgO2YIAjw8fGBIAjW7gpZAeNPzAF5Y/ypOXPA0eYBswC2Y2q1GocPH4baEb6LoHpj/Ik5IG+MPzVnDrAAJpvC5W/kjfEn5oC8Mf7UXDnAApiIiIiIZKVjR8DJSbrPApiIiIiIHJ6TE9Cpk3T/7Fn7XwmCBbAdUyqV6N69O88AlinGn5gD8sb4U3PngG4aREUFcP58s/zKJsMC2M45OztbuwtkRYw/MQfkjfGn5swBR5oHzALYjmk0GsTHx/MkCJli/Ik5IG+MPzV3DrAAJiIiIiJZ6dKl8j4LYCIiIiJyeB06OM5KECyAiYiIiKhWTk5AZKR0/9w56WQ4eyWIoihauxO2rqioCN7e3igsLISXl5e1u6MniiI0Gg2USiUvhSlDjD8xB+SN8Sdr5MCYMcDGjdL9kycNp0VYW33qNR4BtnPl5eXW7gJZEeNPzAF5Y/ypuXPAUU6EYwFsxzQaDY4fP84zgGWK8SfmgLwx/mSNHGABTERERESyUrUAPnXKev1oKBbARERERFQnERGA7tobPAJMVsNLYMob40/MAXlj/Km5c0ClAqKipPvnzgH2Og2dq0DUga2uAkFERETU3MaNAzZskO6fOGE4LcKauAqETIiiiIKCAvAzjDwx/sQckDfGn6yVA45wRTgWwHZMo9HgzJkzPANYphh/Yg7IG+NP1soBR1gJggUwEREREdUZC2AiIiIikpWICMDFRbrPApianSAIcHNz4yUwZYrxJ+aAvDH+ZK0cUCorV4JISgLKypr11zcKrgJRB1wFgoiIiKjSww8D69dL9//5B7jpJuv2B+AqELKh1WqRk5MDrVZr7a6QFTD+xByQN8afrJkD9j4PmAWwHdNqtUhJSeGbn0wx/sQckDfGn6yZAyyAiYiIiEhWWAATERERkay0bw+4ukr3WQBTsxIEAd7e3jwDWKYYf2IOyBvjT9bMgaorQZw/b38rQbAAtmNKpRKdO3eGUqm0dlfIChh/Yg7IG+NP1s4B3TQIjQY4e9YqXbAYC2A7ptVqkZ6ezhMgZIrxJ+aAvDH+ZO0csOd5wCyA7Zi1E5+si/En5oC8Mf5k7RxgAUxEREREssICuBF9/PHHCAsLg6urK/r06YNDhw7VuH1BQQFmzpyJ1q1bw8XFBZ06dcLWrVsbtE8iIiIiqln79oCbm3T/1Cnr9qW+bKoA3rhxI+bMmYPFixcjISEB0dHRGDp0KHJyckxuX15ejjvuuAOpqanYtGkTzp49i5UrVyI4ONjifdoThUIBf39/KBQ2FUZqJow/MQfkjfEna+eAQgF07izdP38eKC21SjcsIoiiKFq7Ezp9+vRBXFwcPvroIwDS3JbQ0FA8+eSTmD9/vtH2K1aswNtvv40zZ87AycmpUfYJAGVlZSirsp5HUVERQkNDkZ+fr7+2tEKhgEKhgFarNZh7o2vXaDSo+tKaa1cqlRAEAWq12qAPujM6NRpNndpVKhVEUTRoFwQBSqXSqI/m2jkmjolj4pg4Jo6JY+KY6jOmCROA//5XKsATErTo2dN6Y7p69Sp8fX1RWFior9fMUdX4aDMqLy/HkSNHsGDBAn2bQqHAkCFDsH//fpPP+fnnn9G3b1/MnDkTP/30E/z9/TFu3Dg8//zzUCqVFu0TAJYuXYolS5YYtScmJsLDwwMA4O/vj4iICFy4cAG5ubn6bUJCQhASEoJz586hsLBQ3x4eHo6AgACcOHECJSUl+vaoqCj4+PggMTHRIKDdu3eHs7Mz4uPjDfoQGxuL8vJyHD9+HABw48YNtGjRAr1790ZhYSHOnDmj39bNzQ3R0dHIy8tDSkqKvt3b2xudO3dGRkYG0tPT9e22MiZASua4uDiOqYYxpaSkIC0tDe7u7g4zJkeMU1OOSaVSYe/evfoccIQxOWKcmmpMXl5ecHFxgZOTEzIyMhxiTI4Yp6YeU4sWLdClSxerjcnbWwugLQBg585c9OwZaLU4JSYmoq5s5ghwRkYGgoODsW/fPvTt21ffPm/ePOzatQsHDx40ek5UVBRSU1Px8MMP44knnsD58+fxxBNP4KmnnsLixYst2idgP0eANRoNEhISEBMTAxcXF34aldmYdB/wYmJioFQqHWJMjhinphyTWq1GfHy8PgccYUym+s4xme67RqNBYmIiYmJiDL4Ct+cxOWKcmnJMujogLi4O1TXXmH7+WcSoUdI+FywQ8frrAo8ANzWtVouAgAB8/vnnUCqV6NWrFy5fvoy3334bixcvtni/Li4ucHFxMWpXqVRQqQxfMl3wqtMFo67t1fdb13ZdEurum9reXB/r295cY6qKY6q5XRf/qvuz9zE5YpyaakyCIJjMgZq2t/Ux1bedY5La67O9vYzJEePUFGPSXQXOWmPq3r3y51OnhBq3t0aczLGZAtjPzw9KpRLZ2dkG7dnZ2QgKCjL5nNatW8PJycnghevcuTOysrJQXl5u0T6JiIiIqG7CwgB3d+DGDftaCs1mTh11dnZGr169sGPHDn2bVqvFjh07DKYvVNWvXz+cP3/e4DD7uXPn0Lp1azg7O1u0T3uiUCgQEhJi8lMWOT7Gn5gD8sb4ky3kgKLKShDJyUCVqbw2zab+aubMmYOVK1di3bp1OH36NGbMmIHi4mJMnjwZADBhwgSDE9pmzJiBK1euYPbs2Th37hy2bNmC119/HTNnzqzzPu2ZLSQ+WQ/jT8wBeWP8yVZyQHdBDFEEqpxDZ9NsZgoEAIwePRq5ublYtGgRsrKy0KNHD2zbtg2BgYEAgLS0NIMgh4aG4rfffsMzzzyD7t27Izg4GLNnz8bzzz9f533aM41Gg3PnzqFTp05m58+Q42L8iTkgb4w/2UoOVL0i3KlTQM+eVutKndlUAQwAs2bNwqxZs0w+tnPnTqO2vn374sCBAxbv056JoojCwkKDMydJPhh/Yg7IG+NPtpID9nhJZH5vQkREREQWYwFMRERERLLSti3w73XCWABT01MoFAgPD7f65HeyDsafmAPyxviTreSAQgF06SLdT0mRlkSzdfyrsWMKhQIBAQFWT3yyDsafmAPyxviTLeWArgC2l5UgrP+KkcU0Gg2OHTtmdElAkgfGn5gD8sb4ky3lgL3NA2YBbMdEUcT/t3fvQVGd5x/Av4cFdinKpXK/yFVFWq8QvOHUGhoSYxuriZc0sWjEdmpmMjqN2kS0oJV2TFI6jRadcnGqE5sItkziSFJamjgSjWhiIBHlJhKFsCjXymV3z++P/bGyAsoueznL+X5mdtx9993leXkemYeXc87eu3fP7md/kn0w/8QakDfmn6RUA2yAiYiIiEhWRtUAX78OLFwITJ0KPPbYyBNzcoApU4CoKCA1Fejv14+XlgJubsDs2fdvZn70HBtgIiIiIhqTyZOBCRP090dsgH/xC2DzZuDaNWDHDiAlZeicujogLQ345BOguhpobgaOHLn//LRpwOef37+5uZkVLxtgB6ZQKBATE8NPAJIp5p9YA/LG/JOUakAQ7p8IV18PdHc/MOHbb4GLF4EXXtA/XrUKuHlT3+QOdvIk8JOfAAEB+jf95S+Bd96xeLxsgB2YIAjw8vKCIAj2DoXsgPkn1oC8Mf8ktRoYOAxi2CtB3LwJBAYCzv//IcSCoN82bmgwntfQAISF3X8cHm48p6YGmDtXfwjFoUNmx8oG2IFpNBp89tln0Gg09g6F7ID5J9aAvDH/JLUasPqJcHPnAo2NwKVLwKlTQHY28O67Zr0VG2AHJ4VLn5D9MP/EGpA35p+kVAMPbYBDQ4Hbt4GBZl0U9Tu7kycbz5s8Gbhx4/7j+vr7czw8AE9P/f2QEGDdOv2xwmZgA0xEREREY/bQBtjPT7+De+yY/nFBgb6JjY42nrdqFVBUBDQ16Zvk7Gxg7Vr9c7dvAzqd/n5nJ/D++8CcOWbFygaYiIiIiMYsJASYOFF/f9hDIA4f1t+mTgV+/3sgL08/vmmTvukFgMhIID0dWLRI3xz7+uqvHgHom+YZM4BZs4D584Ef/QjYsMGsWAVRCldPlriOjg54enqivb0dHh4e9g7HYOAC2G5ubpI5AJ5sh/kn1oC8Mf8kxRqYPx84f15/v7Pz/qXRbMGUfo07wA7O1dXV3iGQHTH/xBqQN+afpFYDgw+D+Ppr+8XxKGyAHZhWq8XFixcldQA82Q7zT6wBeWP+SYo14CgficwGmIiIiIgsgg0wEREREcnK4Ab4q6+Mn+vr64NUTj1jA0xEREREFhEcrL9cL2C8A6zRaJCVlYXr16/bJ7AHsAF2YAqFAvHx8ZL4DHCyPeafWAPyxvyTFGtAEO7vAt+4AXR16e/funUL9+7dQ39/P44cOYKOjg77BQk2wA6vr6/P3iGQHTH/xBqQN+afpFgDwx0GcfPmTbi4uOCjjz6CTqdDb28v7ty5Y58AwQbYoWm1Wly5ckVSZ3+S7TD/xBqQN+afpFoDsbH37w8cBtHQ0ACFQoGenh5MmDABhw4dQklJiX0CBOBst69MREREROPOg1eCEEURtbW10Gg0AID29nYsX74cM2fOtFOEbICJiIiIyIIGN8DHjwMuLhqoVBr4+PjgiSeeQHR0tN0/uY4NsIOT0oHvZHvMP7EG5I35JynWQHHx/ftNTcCBAy4QxTTk5DhhyhT7xTWYIErlgmwSZspnSxMRERHJ1fXrQEwMoNMNfc7JCaiqAqKjrfO1TenXeBKcAxNFEW1tbZK5qDTZFvNPrAF5Y/5JijWQm6u/FNpwBAHIybFtPCNhA+zAtFotrl69KrmzP8k2mH9iDcgb809SrIH6emCkflwU9c9LARtgIiIiIrKI8PCH7wCHh9sympGxASYiIiIii9i48eE7wC+9ZNt4RsIG2IEJggA3Nze7X0qE7IP5J9aAvDH/JMUamDJFf5yvkxOgUBj/m5NjvRPgTMWrQIwCrwJBRERENHrV1fqGt75ef9jDSy9Zv/k1pV/jdYAdmE6ng1qtho+PD5ycuJkvN8w/sQbkjfknKddAdDSQmWnvKEYmre8WmUSn06G2tha64S62R+Me80+sAXlj/ok1YD42wEREREQkK2yAiYiIiEhW2AA7MEEQ4OnpKamzP8l2mH9iDcgb80+sAfPxKhCjwKtAEBEREUmbKf0ad4AdmE6nQ2NjIw9+lynmn1gD8sb8E2vAfJJsgA8ePIjw8HCoVCrMmzcPFy5cGHFufn4+BEEwuqlUKqM5KSkpQ+Y8+eST1l6G1bHw5Y35J9aAvDH/xBown+SuA/z3v/8d27ZtQ3Z2NubNm4esrCwkJyejqqoKfn5+w77Gw8MDVVVVhsfDHQvz5JNPIi8vz/BYqVRaPngiIiIikjzJ7QC/9dZbSE1NxYYNGxAbG4vs7Gx85zvfQW5u7oivEQQBAQEBhpu/v/+QOUql0miOt7e3NZdBRERERBIlqR3gvr4+lJeX4ze/+Y1hzMnJCUlJSSgrKxvxdV1dXQgLC4NOp8PcuXOxf/9+fO973zOaU1paCj8/P3h7e2Pp0qXYt28fJk2aNOz79fb2ore31/C4o6MDAKDRaKDRaAxxOTk5QafTGf3pYWBcq9Vi8PmFI40rFAoIgmB438HjAKDVakcc1+l0mDRpkuHri6JoNF8QBCgUiiExjjQuhTUN5uzszDU9ZE0ADPnXaDTjYk3jMU/WXJMgCEY1MB7WNFzsXNPwsYuiCF9fXwAw+rqOvKbxmCdrrkmn0xk+BW68rGkgRnPy9OD8h5FUA6xWq6HVaofs4Pr7++Pq1avDvmbatGnIzc3FzJkz0d7ejjfeeAMLFy5EZWUlQkJCAOgPf1i5ciUiIiJQU1OD1157DU899RTKysoM37TBMjMzkZ6ePmT88uXLcHd3BwD4+voiKioKdXV1aGlpMcwJCQlBSEgIrl27hvb2dsN4ZGQk/Pz8UFFRgXv37hnGY2Ji4OXlhcuXLxsldObMmXB1dcXFixeNYoiPj0dfXx+uXLliGGtra8Njjz2G9vZ2o++Tm5sbZs2aBbVajdraWsO4p6cnpk+fjlu3bqGxsdEwLqU1KRQKrukRa7px4wZaW1vR2to6btY0HvNk7TUNroHxsqbxmCdrrqmxsXHcrWk85smaa3JyckJ5efm4WpM5ebp8+TJGS1KXQbt16xaCg4Nx7tw5LFiwwDC+fft2/Pe//8X58+cf+R79/f2YPn061q1bh7179w47p7a2FlFRUfjXv/6Fxx9/fMjzw+0Ah4aGorW11XBZDXv/ljOwA3zjxg2EhYXB1dXV4X9zG4+/jVpzTRqNBnV1dQgLCzOMOfqaxmOerLmmgY9BHaiB8bCm4WLnmkbeAW5oaEBYWJjRezjymsZjnqy9A9zQ0IDIyEij93DkNQ3EaE6e7t69i0mTJo3qMmiS2gH28fGBQqFAc3Oz0XhzczMCAgJG9R4uLi6YM2cOqqurR5wTGRkJHx8fVFdXD9sAK5XKYU+Sc3Z2hrOz8bdsIHkPGm5n+WHjD77vaMY1Gg1aW1sREREBQF+Qw80fKUZTx22xpgdxTSOPAzDkf/D7OfKaxmOerLkmURSHrYGR5jvCmkwdl/OaNBoNWlpaEBYWZtL3QMprMndcrmvSaDRQq9UIDw8fN2t6VIzmjA9HUifBubq6Ii4uDiUlJYYxnU6HkpISox3hh9Fqtfjyyy8RGBg44pzGxka0trY+dA4RERERjU+S2gEGgG3btuHnP/854uPjkZCQgKysLHR3d2PDhg0AgPXr1yM4OBiZmZkAgIyMDMyfPx/R0dFoa2vDgQMHcOPGDWzatAmA/gS59PR0rFq1CgEBAaipqcH27dsRHR2N5OTkUcU0sC0/cDKcVGg0GnR3d6Ojo8Ok33pofGD+iTUgb8w/sQaMDfRpozm6V3LfrTVr1qClpQW7d+9GU1MTZs+ejTNnzhhOjGtoaDDaVr979y5SU1PR1NQEb29vxMXF4dy5c4iNjQWg31a/cuUKjh49ira2NgQFBeGJJ57A3r17R30t4M7OTgBAaGiohVdLRERERJbU2dkJT0/Ph86R1ElwUqXT6XDr1i1MnDhx2A/ZsJeBk/Nu3rz5yIO9afxh/ok1IG/MP7EGjImiiM7OTgQFBY147swAye0AS5GTk5PhkmpS5OHhwcKXMeafWAPyxvwTa+C+R+38DpDUSXBERERERNbGBpiIiIiIZIUNsANTKpXYs2fPqE/mo/GF+SfWgLwx/8QaMB9PgiMiIiIiWeEOMBERERHJChtgIiIiIpIVNsBEREREJCtsgImIiIhIVtgAS9zBgwcRHh4OlUqFefPm4cKFCyPOzc/PhyAIRjeVSmXDaMnSTMk/ALS1tWHLli0IDAyEUqnE1KlTcfr0aRtFS9ZgSg0sWbJkyM8AQRDw9NNP2zBisiRTfwZkZWVh2rRpcHNzQ2hoKLZu3Yqenh4bRUuWZkr++/v7kZGRgaioKKhUKsyaNQtnzpyxYbQORiTJOnHihOjq6irm5uaKlZWVYmpqqujl5SU2NzcPOz8vL0/08PAQb9++bbg1NTXZOGqyFFPz39vbK8bHx4vLli0Tz549K9bV1YmlpaXi559/buPIyVJMrYHW1laj//8VFRWiQqEQ8/LybBs4WYSp+T9+/LioVCrF48ePi3V1dWJxcbEYGBgobt261caRkyWYmv/t27eLQUFB4gcffCDW1NSIhw4dElUqlXjp0iUbR+4Y2ABLWEJCgrhlyxbDY61WKwYFBYmZmZnDzs/LyxM9PT1tFB1Zm6n5/8tf/iJGRkaKfX19tgqRrMzUGnjQH//4R3HixIliV1eXtUIkKzI1/1u2bBGXLl1qNLZt2zZx0aJFVo2TrMPU/AcGBopvv/220djKlSvFn/3sZ1aN01HxEAiJ6uvrQ3l5OZKSkgxjTk5OSEpKQllZ2Yiv6+rqQlhYGEJDQ/HMM8+gsrLSFuGShZmT/6KiIixYsABbtmyBv78/vv/972P//v3QarW2CpssyNyfAYPl5ORg7dq1cHd3t1aYZCXm5H/hwoUoLy83/Jm8trYWp0+fxrJly2wSM1mOOfnv7e0dctijm5sbzp49a9VYHRUbYIlSq9XQarXw9/c3Gvf390dTU9Owr5k2bRpyc3Pxz3/+E8eOHYNOp8PChQvR2Nhoi5DJgszJf21tLU6ePAmtVovTp08jLS0Nb775Jvbt22eLkMnCzKmBwS5cuICKigps2rTJWiGSFZmT/+effx4ZGRlITEyEi4sLoqKisGTJErz22mu2CJksyJz8Jycn46233sL169eh0+nw0UcfobCwELdv37ZFyA6HDfA4smDBAqxfvx6zZ8/GD37wAxQWFsLX1xeHDx+2d2hkAzqdDn5+fjhy5Aji4uKwZs0avP7668jOzrZ3aGQHOTk5mDFjBhISEuwdCtlIaWkp9u/fj0OHDuHSpUsoLCzEBx98gL1799o7NLKBP/3pT5gyZQpiYmLg6uqKl19+GRs2bICTE1u94TjbOwAano+PDxQKBZqbm43Gm5ubERAQMKr3cHFxwZw5c1BdXW2NEMmKzMl/YGAgXFxcoFAoDGPTp09HU1MT+vr64OrqatWYybLG8jOgu7sbJ06cQEZGhjVDJCsyJ/9paWl48cUXDbv+M2bMQHd3NzZv3ozXX3+djZADMSf/vr6++Mc//oGenh60trYiKCgIO3fuRGRkpC1Cdjj83yBRrq6uiIuLQ0lJiWFMp9OhpKQECxYsGNV7aLVafPnllwgMDLRWmGQl5uR/0aJFqK6uhk6nM4xdu3YNgYGBbH4d0Fh+Brz33nvo7e3FCy+8YO0wyUrMyf///ve/IU3uwC/EoihaL1iyuLH8/1epVAgODoZGo0FBQQGeeeYZa4frmOx9Fh6N7MSJE6JSqRTz8/PFr776Sty8ebPo5eVluLTZiy++KO7cudMwPz09XSwuLhZramrE8vJyce3ataJKpRIrKyvttQQaA1Pz39DQIE6cOFF8+eWXxaqqKvH9998X/fz8xH379tlrCTRGptbAgMTERHHNmjW2DpcszNT879mzR5w4caL4zjvviLW1teKHH34oRkVFiatXr7bXEmgMTM3/p59+KhYUFIg1NTXixx9/LC5dulSMiIgQ7969a6cVSBsPgZCwNWvWoKWlBbt370ZTUxNmz56NM2fOGA6Kb2hoMPpt/+7du0hNTUVTUxO8vb0RFxeHc+fOITY21l5LoDEwNf+hoaEoLi7G1q1bMXPmTAQHB+OVV17Bjh077LUEGiNTawAAqqqqcPbsWXz44Yf2CJksyNT879q1C4IgYNeuXfjmm2/g6+uLH//4x/jd735nryXQGJia/56eHuzatQu1tbWYMGECli1bhr/97W/w8vKy0wqkTRBF/l2EiIiIiOSDxwATERERkaywASYiIiIiWWEDTERERESywgaYiIiIiGSFDTARERERyQobYCIiIiKSFTbARERERCQrbICJiIiISFbYABMRkdkEQcBvf/tbw+P8/HwIgoD6+nq7xURE9ChsgImIJGygoRy4OTs7Izg4GCkpKfjmm2/sHR4RkUNytncARET0aBkZGYiIiEBPTw8+/fRT5Ofn4+zZs6ioqIBKpbJ3eEREDoUNMBGRA3jqqacQHx8PANi0aRN8fHzwhz/8AUVFRVi9erWdoyMiciw8BIKIyAEtXrwYAFBTU2MYu3r1Kp599ll897vfhUqlQnx8PIqKioa8tq2tDVu3bkV4eDiUSiVCQkKwfv16qNVqAEBfXx92796NuLg4eHp6wt3dHYsXL8Z//vMf2yyOiMjKuANMROSABk4y8/b2BgBUVlZi0aJFCA4Oxs6dO+Hu7o53330XK1asQEFBAX76058CALq6urB48WJ8/fXX2LhxI+bOnQu1Wo2ioiI0NjbCx8cHHR0d+Otf/4p169YhNTUVnZ2dyMnJQXJyMi5cuIDZs2fbadVERJbBBpiIyAG0t7dDrVajp6cH58+fR3p6OpRKJZYvXw4AeOWVVzB58mR89tlnUCqVAIBf/epXSExMxI4dOwwN8IEDB1BRUYHCwkLDGADs2rULoigC0DfV9fX1cHV1NTyfmpqKmJgY/PnPf0ZOTo6tlk1EZBU8BIKIyAEkJSXB19cXoaGhePbZZ+Hu7o6ioiKEhITgzp07+Pe//43Vq1ejs7MTarUaarUara2tSE5OxvXr1w1XjCgoKMCsWbOMmt8BgiAAABQKhaH51el0uHPnDjQaDeLj43Hp0iXbLZqIyEq4A0xE5AAOHjyIqVOnor29Hbm5ufj4448NO73V1dUQRRFpaWlIS0sb9vXffvstgoODUVNTg1WrVj3y6x09ehRvvvkmrl69iv7+fsN4RESEZRZERGRHbICJiBxAQkKC4SoQK1asQGJiIp5//nlUVVVBp9MBAH79618jOTl52NdHR0eP+msdO3YMKSkpWLFiBV599VX4+flBoVAgMzPT6KQ7IiJHxQaYiMjBDDSjP/zhD/H2229j48aNAAAXFxckJSU99LVRUVGoqKh46JyTJ08iMjIShYWFhsMiAGDPnj1jD56ISAJ4DDARkQNasmQJEhISkJWVBQ8PDyxZsgSHDx/G7du3h8xtaWkx3F+1ahW++OILnDp1asi8gZPgFAqF0WMAOH/+PMrKyiy9DCIiu+AOMBGRg3r11Vfx3HPPIT8/HwcPHkRiYiJmzJiB1NRUREZGorm5GWVlZWhsbMQXX3xheM3Jkyfx3HPPYePGjYiLi8OdO3dQVFSE7OxszJo1C8uXLzdcJeLpp59GXV0dsrOzERsbi66uLjuvmoho7NgAExE5qJUrVyIqKgpvvPEGUlNTcfHiRaSnpyM/Px+tra3w8/PDnDlzsHv3bsNrJkyYgE8++QR79uzBqVOncPToUfj5+eHxxx9HSEgIACAlJQVNTU04fPgwiouLERsbi2PHjuG9995DaWmpnVZLRGQ5gjj4b1xEREREROMcjwEmIiIiIllhA0xEREREssIGmIiIiIhkhQ0wEREREckKG2AiIiIikhU2wEREREQkK2yAiYiIiEhW2AATERERkaywASYiIiIiWWEDTERERESywgaYiIiIiGSFDTARERERycr/AZaNBUYRaVrUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure consistent data shapes\n",
    "y_true = decoder_target_data_val.flatten()\n",
    "y_pred_prob = predictions.flatten()\n",
    "\n",
    "def evaluate_threshold(y_true, y_pred_prob, threshold):\n",
    "    y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    return precision, recall\n",
    "\n",
    "# Threshold testing excluding 0 and 1, with larger increments\n",
    "thresholds = np.arange(0.05, 1.0, 0.05)\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    precision, recall = evaluate_threshold(y_true, y_pred_prob, threshold)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Plotting Precision vs. Recall with enhanced aesthetics\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_list, precision_list, marker='o', color='b', linestyle='-', linewidth=2, markersize=5)\n",
    "\n",
    "# Adding threshold annotations with arrows\n",
    "for i, threshold in enumerate(thresholds):\n",
    "    if i % 2 == 0:  # Annotate every other point to reduce clutter\n",
    "        plt.annotate(\n",
    "            f'{threshold:.2f}', \n",
    "            (recall_list[i], precision_list[i]), \n",
    "            textcoords=\"offset points\", \n",
    "            xytext=(10,10), \n",
    "            ha='center',\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3\", color='gray'),\n",
    "            fontsize=8, color='red'\n",
    "        )\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision vs. Recall Curve for Best Model', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.savefig('Precision_vs_Recall_Curve_Enhanced.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ec183-8d0c-4c0b-9c21-e93a544fd642",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12cc3b61-ac17-43b5-9f65-310c65bf893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "model = load_model(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6027713f-295e-4b79-869f-8592ae118242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate prediction\n",
    "def generate_prediction(model, input_seq, output_seq_length, output_features):\n",
    "    # Create encoder model for prediction\n",
    "    encoder_inputs = model.input[0]  # Encoder input from the trained model\n",
    "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer('encoder_lstm').output\n",
    "    encoder_states = [state_h_enc, state_c_enc]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # Create decoder model for prediction\n",
    "    decoder_inputs = model.input[1]  # Decoder input from the trained model\n",
    "    decoder_state_input_h = Input(shape=(256,), name='decoder_state_input_h')\n",
    "    decoder_state_input_c = Input(shape=(256,), name='decoder_state_input_c')\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_lstm = model.get_layer('decoder_lstm')\n",
    "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h_dec, state_c_dec]\n",
    "    decoder_batch_norm = model.get_layer('decoder_batch_norm')\n",
    "    decoder_outputs = decoder_batch_norm(decoder_outputs)\n",
    "    decoder_dense = model.get_layer('decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    # Encode the input as state vectors\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Initialize target sequence with all zeros\n",
    "    target_seq = np.zeros((1, 1, output_features))\n",
    "    \n",
    "    output_sequence = []\n",
    "\n",
    "    # Generate sequence to complete the input sequence\n",
    "    for _ in range(output_seq_length):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        output_sequence.append(output_tokens[0, -1, :])\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        # Update target sequence with the predicted step\n",
    "        target_seq = np.zeros((1, 1, output_features))\n",
    "        target_seq[0, 0, :] = output_tokens[0, -1, :]\n",
    "\n",
    "    output_sequence = np.array(output_sequence)\n",
    "    return np.vstack((input_seq.squeeze(), output_sequence.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11b25217-7ef8-450d-b319-0646d5062dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to re-include filtered notes\n",
    "def restore_removed_notes(predicted_sequences, played_notes, total_notes=128):\n",
    "    restored_sequences = []\n",
    "    for sequence in predicted_sequences:\n",
    "        restored_sequence = np.zeros((sequence.shape[0], total_notes))\n",
    "        restored_sequence[:, played_notes] = sequence\n",
    "        restored_sequences.append(restored_sequence)\n",
    "    return np.array(restored_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8d68086-824b-4a0f-927b-96ef6af26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert piano roll to MIDI\n",
    "def piano_roll_to_midi(piano_roll, fs=8, velocity=80, threshold=0.5):\n",
    "    \"\"\"Convert a Piano Roll array into a PrettyMIDI object with one instrument.\"\"\"\n",
    "    piano_roll = piano_roll.T\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=0)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge changes at the first and last time step\n",
    "    piano_roll = np.pad(piano_roll, ((0, 0), (1, 1)), 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        int_time = int(time)  # Ensure time is an integer\n",
    "        if piano_roll[note, int_time + 1] > threshold:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time / fs  # Convert time to seconds\n",
    "            prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time / fs)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7feb1519-1e4c-4feb-b2df-d0ced62c1137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_midi(path, midi_data):\n",
    "    \"\"\" Save a PrettyMIDI object to a MIDI file.\n",
    "        :param path: str, path to save the MIDI file\n",
    "        :param midi_data: pretty_midi.PrettyMIDI, the MIDI data to save\n",
    "    \"\"\"\n",
    "    midi_data.write(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8cdf76a-537c-4830-a630-075bd48cf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the LSTM model\n",
    "def build_simple_lstm_model(input_features, output_features, latent_dim, dropout_rate=0.5, learning_rate=0.001):\n",
    "    # Define encoder\n",
    "    encoder_inputs = Input(shape=(None, input_features), name='encoder_inputs')\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "    encoder_outputs = BatchNormalization(name='encoder_batch_norm')(encoder_outputs)\n",
    "    encoder_outputs = Dropout(dropout_rate, name='encoder_dropout')(encoder_outputs)\n",
    "    \n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Define decoder\n",
    "    decoder_inputs = Input(shape=(None, output_features), name='decoder_inputs')\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_outputs = BatchNormalization(name='decoder_batch_norm')(decoder_outputs)\n",
    "    decoder_outputs = Dropout(dropout_rate, name='decoder_dropout')(decoder_outputs)\n",
    "    \n",
    "    decoder_dense = TimeDistributed(Dense(output_features, activation='sigmoid'), name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e71a0431-85cd-4fd1-bf2d-e42385e730f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Generated Output Shape: (64, 82)\n",
      "Predicted output MIDI saved as 'predicted_output.mid'.\n",
      "Original output MIDI saved as 'original_output.mid'.\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main(input_seq, true_output_seq, model_path, played_notes, threshold):\n",
    "    input_features = input_seq.shape[2]\n",
    "    output_features = true_output_seq.shape[1]\n",
    "    output_seq_length = true_output_seq.shape[0]\n",
    "\n",
    "    # Load the trained model\n",
    "    model = build_simple_lstm_model(input_features, output_features, latent_dim=256)\n",
    "    model.load_weights(model_path)\n",
    "\n",
    "    # Generate output sequence\n",
    "    output_seq = generate_prediction(model, input_seq, output_seq_length, output_features)\n",
    "    print(\"Generated Output Shape:\", output_seq.shape)\n",
    "\n",
    "    # Re-include filtered notes for predicted sequence\n",
    "    output_seq = restore_removed_notes([output_seq], played_notes)[0]\n",
    "    \n",
    "    # Re-include filtered notes for true output sequence\n",
    "    true_output_seq_full = restore_removed_notes([np.vstack((input_seq.squeeze(), true_output_seq))], played_notes)[0]\n",
    "\n",
    "    # Convert predicted output back to MIDI and save\n",
    "    output_midi = piano_roll_to_midi(output_seq, fs=8, threshold=threshold)\n",
    "    save_midi('predicted_output.mid', output_midi)\n",
    "    print(\"Predicted output MIDI saved as 'predicted_output.mid'.\")\n",
    "\n",
    "    # Convert original output back to MIDI and save\n",
    "    original_midi = piano_roll_to_midi(true_output_seq_full, fs=8, threshold=threshold)\n",
    "    save_midi('original_output.mid', original_midi)\n",
    "    print(\"Original output MIDI saved as 'original_output.mid'.\")\n",
    "\n",
    "# Example usage\n",
    "sample_index = 11  # Change this to select a different sample\n",
    "input_seq = all_data[62]['encoder_input_data_test'][sample_index:sample_index+1]  # Test input sequence\n",
    "true_output_seq = all_data[62]['decoder_target_data_test'][sample_index]  # True output sequence\n",
    "played_notes = all_data[62]['played_notes']\n",
    "\n",
    "model_path = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "main(input_seq, true_output_seq, model_path, played_notes, threshold=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5c9cb-adba-43e3-8dad-86280a1ad26d",
   "metadata": {},
   "source": [
    "## Precision and Recall Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d78cfc-23fe-4410-b0d2-b2a3b5481a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485422ad-df28-4d89-9b7a-a290f9c0af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall_over_time(true_sequences, predicted_sequences, threshold=0.5):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Iterate over each timestep\n",
    "    for t in range(true_sequences.shape[1]):\n",
    "        true_timestep = true_sequences[:, t, :]\n",
    "        predicted_timestep = (predicted_sequences[:, t, :] > threshold).astype(int)\n",
    "        \n",
    "        precision = precision_score(true_timestep.reshape(-1), predicted_timestep.reshape(-1), average='binary', zero_division=0)\n",
    "        recall = recall_score(true_timestep.reshape(-1), predicted_timestep.reshape(-1), average='binary', zero_division=0)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c766f53-9290-4e14-ba40-401e7823c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Function to calculate precision and recall over time\n",
    "def calculate_precision_recall_over_time(true_sequences, predicted_sequences, threshold=0.5):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Iterate over each timestep\n",
    "    for t in range(true_sequences.shape[1]):\n",
    "        true_timestep = true_sequences[:, t, :]\n",
    "        predicted_timestep = (predicted_sequences[:, t, :] > threshold).astype(int)\n",
    "        \n",
    "        precision = precision_score(true_timestep.reshape(-1), predicted_timestep.reshape(-1), average='binary', zero_division=0)\n",
    "        recall = recall_score(true_timestep.reshape(-1), predicted_timestep.reshape(-1), average='binary', zero_division=0)\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return precisions, recalls\n",
    "\n",
    "# Load the model\n",
    "model_path = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Predict the output sequences for the test set\n",
    "encoder_input_data_test = all_data[62]['encoder_input_data_test']\n",
    "decoder_input_data_test = all_data[62]['decoder_input_data_test']\n",
    "decoder_target_data_test = all_data[62]['decoder_target_data_test']\n",
    "\n",
    "predictions = model.predict([encoder_input_data_test, decoder_input_data_test])\n",
    "\n",
    "# Calculate precision and recall over time for both thresholds\n",
    "thresholds = [0.85, 0.15]\n",
    "avg_precisions_075, avg_recalls_075 = calculate_precision_recall_over_time(decoder_target_data_test, predictions, threshold=thresholds[0])\n",
    "avg_precisions_025, avg_recalls_025 = calculate_precision_recall_over_time(decoder_target_data_test, predictions, threshold=thresholds[1])\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot for threshold 0.85\n",
    "plt.plot(range(1, len(avg_precisions_075) + 1), avg_precisions_075, label='Precision (Threshold = 0.85)', marker='o', color='navy')\n",
    "plt.plot(range(1, len(avg_recalls_075) + 1), avg_recalls_075, label='Recall (Threshold = 0.85)', marker='o', color='darkred')\n",
    "\n",
    "# Plot for threshold 0.15\n",
    "plt.plot(range(1, len(avg_precisions_025) + 1), avg_precisions_025, label='Precision (Threshold = 0.15)', marker='o', color='blue')\n",
    "plt.plot(range(1, len(avg_recalls_025) + 1), avg_recalls_025, label='Recall (Threshold = 0.15)', marker='o', color='red')\n",
    "\n",
    "plt.xticks(range(1, len(avg_precisions_075) + 1))\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall Over Time for Different Thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('PrecisionRecallOverTime_Thresholds_075_025.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6410e73b-4043-4919-8094-02ce67ff2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_avg_notes_per_timestep(sequences):\n",
    "    \"\"\" Calculate the average number of notes per timestep. \"\"\"\n",
    "    return np.mean(np.sum(sequences, axis=-1), axis=0)\n",
    "\n",
    "def apply_threshold(sequences, threshold):\n",
    "    \"\"\" Apply threshold to the predicted sequences. \"\"\"\n",
    "    return (sequences > threshold).astype(int)\n",
    "\n",
    "# Load the model\n",
    "model_path = 'Models/EncDecLSTM/62sec_1layer_256units_0.6dropout_Adam_lr0.001_batch16.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Predict the output sequences for the test set\n",
    "encoder_input_data_test = all_data[62]['encoder_input_data_test']\n",
    "decoder_input_data_test = all_data[62]['decoder_input_data_test']\n",
    "decoder_target_data_test = all_data[62]['decoder_target_data_test']\n",
    "\n",
    "predictions = model.predict([encoder_input_data_test, decoder_input_data_test])\n",
    "\n",
    "# Apply thresholds to the predictions\n",
    "thresholds = [0.85, 0.15]\n",
    "predictions_thresholded_075 = apply_threshold(predictions, thresholds[0])\n",
    "predictions_thresholded_025 = apply_threshold(predictions, thresholds[1])\n",
    "\n",
    "# Calculate average number of notes per timestep for true and predicted sequences\n",
    "avg_notes_true = calculate_avg_notes_per_timestep(decoder_target_data_test)\n",
    "avg_notes_pred_075 = calculate_avg_notes_per_timestep(predictions_thresholded_075)\n",
    "avg_notes_pred_025 = calculate_avg_notes_per_timestep(predictions_thresholded_025)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "timesteps = range(1, len(avg_notes_true) + 1)\n",
    "plt.plot(timesteps, avg_notes_true, label='True Average Notes', marker='o', color='green')\n",
    "plt.plot(timesteps, avg_notes_pred_075, label='Predicted Average Notes (Threshold = 0.85)', marker='o', color='purple')\n",
    "plt.plot(timesteps, avg_notes_pred_025, label='Predicted Average Notes (Threshold = 0.15)', marker='o', color='brown')\n",
    "plt.xticks(timesteps)  # Set x-ticks to 1 through the number of timesteps\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Average Number of Notes')\n",
    "plt.title('Average Number of Notes Per Timestep for Different Thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('AvgNotesPlayedatThresholds_075_025.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74871924-a0bc-4c32-bd5f-a43dcc069d32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convolutional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db0fccb4-3944-44ca-96af-c3a51c26445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_lstm_model(input_shape, output_shape, filters=64, kernel_size=(3, 3), dropout_rate=0.5, learning_rate=0.001):\n",
    "    # Define encoder\n",
    "    encoder_inputs = Input(shape=input_shape)\n",
    "    encoder_conv_lstm = ConvLSTM2D(filters=filters, kernel_size=kernel_size, return_state=True, return_sequences=True, padding='same')\n",
    "    encoder_outputs, state_h, state_c = encoder_conv_lstm(encoder_inputs)\n",
    "    encoder_outputs = BatchNormalization()(encoder_outputs)\n",
    "    encoder_outputs = Dropout(dropout_rate)(encoder_outputs)\n",
    "    \n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Define decoder\n",
    "    decoder_inputs = Input(shape=output_shape)\n",
    "    decoder_conv_lstm = ConvLSTM2D(filters=filters, kernel_size=kernel_size, return_sequences=True, return_state=True, padding='same')\n",
    "    decoder_outputs, _, _ = decoder_conv_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_outputs = BatchNormalization()(decoder_outputs)\n",
    "    decoder_outputs = Dropout(dropout_rate)(decoder_outputs)\n",
    "    \n",
    "    decoder_dense = TimeDistributed(Dense(output_shape[-1], activation='sigmoid'))\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[Precision(), Recall()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_conv_lstm_model(model, train_data, val_data, model_name, epochs=50, batch_size=32):\n",
    "    encoder_input_data_train, decoder_input_data_train, decoder_target_data_train = train_data\n",
    "    encoder_input_data_val, decoder_input_data_val, decoder_target_data_val = val_data\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(f'{model_name}.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    csv_logger = CSVLogger(f'{model_name}_log.csv', append=True, separator=',')\n",
    "    \n",
    "    history = model.fit(\n",
    "        [encoder_input_data_train, decoder_input_data_train], decoder_target_data_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=([encoder_input_data_val, decoder_input_data_val], decoder_target_data_val),\n",
    "        callbacks=[checkpoint, early_stopping, csv_logger]\n",
    "    )\n",
    "\n",
    "    epochs_taken = len(history.history['loss'])\n",
    "    \n",
    "    return epochs_taken, history\n",
    "\n",
    "def evaluate_lstm_model(model, data):\n",
    "    encoder_input_data, decoder_input_data, decoder_target_data = data\n",
    "    results = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca919059-6ba6-46c1-b79b-10a299601700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder_input_data_train: (464, 48, 82, 1, 1)\n",
      "Shape of decoder_input_data_train: (464, 16, 82, 1, 1)\n",
      "Shape of decoder_target_data_train: (464, 16, 82, 1)\n",
      "Input shape for ConvLSTM model: (48, 82, 1, 1)\n",
      "Output shape for ConvLSTM model: (16, 82, 1, 1)\n",
      "Training model: conv_lstm_64filters_3x3kernel_0.5dropout_0.003lr_16batch_1x1strides\n",
      "Epoch 1/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - loss: 0.5214 - precision: 0.2639 - recall: 0.7680\n",
      "Epoch 1: val_loss improved from inf to 0.31456, saving model to conv_lstm_64filters_3x3kernel_0.5dropout_0.003lr_16batch_1x1strides.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 430ms/step - loss: 0.5171 - precision: 0.2681 - recall: 0.7694 - val_loss: 0.3146 - val_precision: 0.8023 - val_recall: 0.5853\n",
      "Epoch 2/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 0.1858 - precision: 0.7252 - recall: 0.7453\n",
      "Epoch 2: val_loss improved from 0.31456 to 0.17541, saving model to conv_lstm_64filters_3x3kernel_0.5dropout_0.003lr_16batch_1x1strides.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 417ms/step - loss: 0.1850 - precision: 0.7258 - recall: 0.7448 - val_loss: 0.1754 - val_precision: 0.8969 - val_recall: 0.3362\n",
      "Epoch 3/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: 0.1336 - precision: 0.7884 - recall: 0.6971\n",
      "Epoch 3: val_loss improved from 0.17541 to 0.14621, saving model to conv_lstm_64filters_3x3kernel_0.5dropout_0.003lr_16batch_1x1strides.keras\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 419ms/step - loss: 0.1333 - precision: 0.7888 - recall: 0.6969 - val_loss: 0.1462 - val_precision: 0.8955 - val_recall: 0.2571\n",
      "Epoch 4/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: 0.0971 - precision: 0.8415 - recall: 0.7354\n",
      "Epoch 4: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 423ms/step - loss: 0.0969 - precision: 0.8417 - recall: 0.7368 - val_loss: 0.1832 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - loss: 0.0705 - precision: 0.8715 - recall: 0.8349\n",
      "Epoch 5: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 424ms/step - loss: 0.0703 - precision: 0.8717 - recall: 0.8348 - val_loss: 0.2071 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - loss: 0.0572 - precision: 0.8806 - recall: 0.8114\n",
      "Epoch 6: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 414ms/step - loss: 0.0571 - precision: 0.8806 - recall: 0.8114 - val_loss: 0.2168 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.0554 - precision: 0.8818 - recall: 0.8175\n",
      "Epoch 7: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 434ms/step - loss: 0.0554 - precision: 0.8818 - recall: 0.8177 - val_loss: 0.2167 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - loss: 0.0544 - precision: 0.8819 - recall: 0.8254\n",
      "Epoch 8: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 418ms/step - loss: 0.0544 - precision: 0.8820 - recall: 0.8255 - val_loss: 0.2133 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - loss: 0.0536 - precision: 0.8859 - recall: 0.8247\n",
      "Epoch 9: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 414ms/step - loss: 0.0536 - precision: 0.8860 - recall: 0.8247 - val_loss: 0.2086 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - loss: 0.0529 - precision: 0.8920 - recall: 0.8241\n",
      "Epoch 10: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 431ms/step - loss: 0.0529 - precision: 0.8920 - recall: 0.8241 - val_loss: 0.2021 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 0.0525 - precision: 0.8930 - recall: 0.8240\n",
      "Epoch 11: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 422ms/step - loss: 0.0525 - precision: 0.8931 - recall: 0.8240 - val_loss: 0.1931 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - loss: 0.0524 - precision: 0.8935 - recall: 0.8240\n",
      "Epoch 12: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 437ms/step - loss: 0.0524 - precision: 0.8936 - recall: 0.8240 - val_loss: 0.1840 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/500\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - loss: 0.0522 - precision: 0.8942 - recall: 0.8224\n",
      "Epoch 13: val_loss did not improve from 0.14621\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 435ms/step - loss: 0.0521 - precision: 0.8942 - recall: 0.8224 - val_loss: 0.1720 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 230ms/step - loss: 0.1576 - precision: 0.8647 - recall: 0.2372\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - loss: 0.1434 - precision: 0.8984 - recall: 0.2642\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - loss: 0.1592 - precision: 0.8655 - recall: 0.2441\n",
      "                                               Model  Filters  Kernel Size 1  \\\n",
      "0  conv_lstm_64filters_3x3kernel_0.5dropout_0.003...       64              3   \n",
      "\n",
      "   Kernel Size 2  Dropout Rate  Learning Rate  Batch Size  Strides 1  \\\n",
      "0              3           0.5          0.003          16          1   \n",
      "\n",
      "   Strides 2  Epochs Taken  Train Loss  Train Precision  Train Recall  \\\n",
      "0          1            13    0.156631         0.862875      0.232931   \n",
      "\n",
      "   Val Loss  Val Precision  Val Recall  Test Precision  Test Recall  \n",
      "0  0.146211       0.895497    0.257086        0.846281     0.234432  \n"
     ]
    }
   ],
   "source": [
    "filters_list = [64, 128]\n",
    "kernel_sizes = [(3, 3)]\n",
    "dropout_rates = [0.5]\n",
    "learning_rates = [0.001]\n",
    "batch_sizes = [16]\n",
    "\n",
    "\n",
    "sequence_length = 62  # Example sequence length\n",
    "train_data = (\n",
    "    all_data[sequence_length]['encoder_input_data_train'].reshape((-1, 48, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_input_data_train'].reshape((-1, 16, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_target_data_train'].reshape((-1, 16, 82, 1))  # Add time steps and channel dimensions\n",
    ")\n",
    "val_data = (\n",
    "    all_data[sequence_length]['encoder_input_data_val'].reshape((-1, 48, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_input_data_val'].reshape((-1, 16, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_target_data_val'].reshape((-1, 16, 82, 1))  # Add time steps and channel dimensions\n",
    ")\n",
    "test_data = (\n",
    "    all_data[sequence_length]['encoder_input_data_test'].reshape((-1, 48, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_input_data_test'].reshape((-1, 16, 82, 1, 1)),  # Add time steps and channel dimensions\n",
    "    all_data[sequence_length]['decoder_target_data_test'].reshape((-1, 16, 82, 1))  # Add time steps and channel dimensions\n",
    ")\n",
    "input_shape = (48, 82, 1, 1)  # Update input shape with time steps and channel dimension\n",
    "output_shape = (16, 82, 1, 1)  # Update output shape with time steps and channel dimension\n",
    "\n",
    "# Check the shapes of the training data\n",
    "print(\"Shape of encoder_input_data_train:\", train_data[0].shape)\n",
    "print(\"Shape of decoder_input_data_train:\", train_data[1].shape)\n",
    "print(\"Shape of decoder_target_data_train:\", train_data[2].shape)\n",
    "print(\"Input shape for ConvLSTM model:\", input_shape)\n",
    "print(\"Output shape for ConvLSTM model:\", output_shape)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "results_path = 'conv_lstm_hyperparameter_tuning_results2.csv'\n",
    "with open(results_path, 'w') as f:\n",
    "    f.write('Model,Filters,Kernel Size 1,Kernel Size 2,Dropout Rate,Learning Rate,Batch Size,Epochs Taken,Train Loss,Train Precision,Train Recall,Val Loss,Val Precision,Val Recall,Test Precision,Test Recall\\n')\n",
    "\n",
    "\n",
    "for filters in filters_list:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for learning_rate in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    \n",
    "                    model_name = f'conv_lstm_{filters}filters_{kernel_size[0]}x{kernel_size[1]}kernel_{dropout_rate}dropout_{learning_rate}lr_{batch_size}batch'\n",
    "                    print(f'Training model: {model_name}')\n",
    "                    \n",
    "                    model = build_conv_lstm_model(input_shape, output_shape, filters, kernel_size, dropout_rate, learning_rate)\n",
    "                    epochs_taken, history = train_conv_lstm_model(model, train_data, val_data, model_name, epochs=500, batch_size=batch_size)\n",
    "                    \n",
    "                    train_results = evaluate_lstm_model(model, train_data)\n",
    "                    val_results = evaluate_lstm_model(model, val_data)\n",
    "                    test_results = evaluate_lstm_model(model, test_data)  # Evaluate on test data\n",
    "                    \n",
    "                    # Append the results incrementally to the CSV file\n",
    "                    with open(results_path, 'a') as f:\n",
    "                        f.write(f'{model_name},{filters},{kernel_size[0]},{kernel_size[1]},{dropout_rate},{learning_rate},{batch_size},{epochs_taken},{train_results[0]},{train_results[1]},{train_results[2]},{val_results[0]},{val_results[1]},{val_results[2]},{test_results[1]},{test_results[2]}\\n')\n",
    "                    \n",
    "                    # Clear session to free up memory\n",
    "                    K.clear_session()\n",
    "\n",
    "# Save all results to a CSV file\n",
    "results_df = pd.read_csv(results_path)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f573526-8539-4aab-8a0b-f44f56989d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated data with 10 timesteps and 10 notes\n",
    "timesteps = 10\n",
    "notes = 10\n",
    "features_per_note = 1  # Single feature per note\n",
    "\n",
    "# Generate random data for visualization\n",
    "data = np.random.rand(timesteps, notes, features_per_note).squeeze()\n",
    "\n",
    "# Plot the simulated data\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(data, aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Feature Intensity')\n",
    "plt.xlabel('Notes')\n",
    "plt.ylabel('Timesteps')\n",
    "plt.title('Simulated Music Data (Timesteps x Notes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff547599-1313-465c-b576-16a5035b48e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "# Function to apply kernel and visualize\n",
    "def apply_kernel(data, kernel_size):\n",
    "    timesteps, notes = data.shape\n",
    "    kt, kn = kernel_size\n",
    "    output = np.zeros((timesteps - kt + 1, notes - kn + 1))\n",
    "    \n",
    "    for i in range(output.shape[0]):\n",
    "        for j in range(output.shape[1]):\n",
    "            block = data[i:i+kt, j:j+kn]\n",
    "            output[i, j] = np.sum(block)  # Simplified kernel operation (sum of block)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply kernel\n",
    "output_data = apply_kernel(data, kernel_size)\n",
    "\n",
    "# Plot the output data\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(output_data, aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Feature Intensity')\n",
    "plt.xlabel('Notes (Kernel Output)')\n",
    "plt.ylabel('Timesteps (Kernel Output)')\n",
    "plt.title('Output Data After Kernel Application')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a23a21-6b91-4d95-9b95-5bb10268c02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
